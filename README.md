<p align="center">
  <a href="https://github.com/trimstray/test-your-sysadmin-skills">
    <img src="https://github.com/trimstray/test-your-sysadmin-skills/blob/master/static/img/sysadmin_preview.png" alt="マスター">
  </a>
</p>

<br>

<p align="center">:star:</p>

<p align="center">"<i>優れた管理者はすべてを知る必要はないが、不可能なプロジェクトに対して驚くべき解決策を考え出すことができるべきだ。</i>" - cwheeler33 (ServerFault)</p>

<p align="center">:star:</p>

<p align="center">"<i>私のスキルは物事を動かすことであり、無数の事実を知っていることではありません。[…] システムを修正する必要がある場合は、問題を特定し、ログを確認し、エラーを調べます。解決策を実装する必要がある場合は、正しい解決策を調査し、それを実装し、文書化します。その後、それに頻繁に触れることがなければ、大まかな理解にとどまることが多いですが、それゆえに文書化されているのです。</i>" - Sparcrypt (Reddit)</p>

<br>

<p align="center">
  <a href="https://github.com/trimstray/test-your-sysadmin-skills/pulls">
    <img src="https://img.shields.io/badge/PRs-welcome-brightgreen.svg?longCache=true" alt="プルリクエスト歓迎">
  </a>
  <a href="LICENSE.md">
    <img src="https://img.shields.io/badge/License-MIT-lightgrey.svg?longCache=true" alt="MITライセンス">
  </a>
</p>

<p align="center">
  <a href="https://twitter.com/trimstray" target="_blank">
    <img src="https://img.shields.io/twitter/follow/trimstray.svg?logo=twitter" alt="Twitterフォロー">
  </a>
</p>

<div align="center">
  <sub>作成者: <a href="https://twitter.com/trimstray">trimstray</a> と <a href="https://github.com/trimstray/test-your-sysadmin-skills/graphs/contributors">コントリビューター</a>
</div>

<br>

****

<br>

:information_source: &nbsp;このプロジェクトには、**Linux (\*nix) システム管理者**のポジションに関する知識をテストしたり、面接や試験で使用できる**284**のテスト問題と回答が含まれています。

:heavy_check_mark: &nbsp;回答はあくまで**一例**であり、全てのトピックを網羅しているわけではありません。ほとんどの回答には、より深い理解のための**有用なリソース**が含まれています。

:warning: &nbsp;**`***`**でマークされた質問にはまだ回答がないか、回答が不完全です。**プルリクエストを送って追加してください**！

:traffic_light: &nbsp;何かおかしい点があったり、何かが正しくないように見える場合は、**ぜひプルリクエストを送ってください**。変更やコメントについて、正当でよく考えられた説明を追加してください。

:books: &nbsp;知識やスキルを向上させるために、[devops-interview-questions](https://github.com/bregman-arie/devops-interview-questions)を参照してください。とても興味深い内容です。

<br>

<p align="center">
  » <b><code><a href="https://github.com/trimstray/test-your-sysadmin-skills/issues">すべての提案を歓迎します</a></code></b> «
</p>

<br>

## 目次

| <b><u>チャプターの種類</u></b> | <b><u>質問数</u></b> | <b><u>簡単な説明</u></b> |
| :---         | :---         | :---         |
| <b>[はじめに](#introduction)</b> |||
| :small_orange_diamond: [シンプルな質問](#simple-questions) | 14の質問 | リラックスした、楽しい、そしてシンプルな質問です。すべてを始めるのに最適です。 |
| <b>[一般的な知識](#general-knowledge)</b> |||
| :small_orange_diamond: [ジュニアシステム管理者](#junior-sysadmin) | 65の質問 | 基本的な知識に基づいた比較的簡単でストレートな質問です。 |
| :small_orange_diamond: [レギュラーシステム管理者](#regular-sysadmin) | 94の質問 | しっかりとした知識があれば解ける中級レベルの質問です。 |
| :small_orange_diamond: [シニアシステム管理者](#senior-sysadmin) | 99の質問 | 難しい質問や謎解きです。良くなりたいなら挑戦してください。 |
| <b>[秘密の知識](#secret-knowledge)</b> ||
| :small_orange_diamond: [グルシステム管理者](#guru-sysadmin) | 12の質問 | 本当に深い質問です。グルシステム管理者になるための知識を得るためのものです。 |

<br>

## <a name="introduction">はじめに</a>

### :diamond_shape_with_a_dot_inside: <a name="simple-questions">シンプルな質問</a>

- <b>今週学んだことは何ですか？</b>
- <b>システム管理の世界で何に興奮や興味を感じますか？</b>
- <b>最近経験した技術的な課題とその解決方法を教えてください。</b>
- <b>最後に完了した大きなプロジェクトについて教えてください。</b>
- <b>オープンソースプロジェクトに貢献していますか？</b>
- <b>自分のホームラボのセットアップについて説明してください。</b>
- <b>最も誇りに思っている個人的な達成は何ですか？</b>
- <b>これまでに犯した最大のミスは何ですか？今ならどのように対処しますか？</b>
- <b>新しい仕事の初日にインストールするソフトウェアツールは何ですか？</b>
- <b>自分の知識データベース（例：ウィキ、ファイル、ポータル）の管理方法について教えてください。</b>
- <b>毎日確認するニュースソースは何ですか？（システム管理、セキュリティ関連、その他）</b>
- <b>NOCチームがシステム管理者の認証のための新しい予算を持っています。どの認証を取得したいですか、そしてその理由は何ですか？</b>
- <b>開発者とのやり取りはどうしていますか？「彼ら対私たち」か、それとも「異なるアプローチで協力し合う」？</b>
- <b>もし私が面接をしていて、非標準的な状況に対する私の能力を知るためにどの質問をしますか？</b>

## <a name="general-knowledge">一般的な知識</a>

### :diamond_shape_with_a_dot_inside: <a name="junior-sysadmin">ジュニアシステム管理者</a>

###### システムに関する質問 (37)

<details>
<summary><b>Linuxディストリビューションの例をいくつか挙げてください。あなたのお気に入りのディストリビューションは何ですか？その理由は？</b></summary><br>
- Red Hat Enterprise Linux
- Fedora
- CentOS
- Debian
- Ubuntu
- Mint
- SUSE Linux Enterprise Server (SLES)
- SUSE Linux Enterprise Desktop (SLED)
- Slackware
- Arch
- Kali
- Backbox

私のお気に入りのLinuxディストリビューション:

- **Arch Linux** は、カスタムオペレーティングシステムを構築するための最小限の基本システムを提供します。また、公式のバイナリリポジトリと組み合わせると、おそらくすべてのディストリビューションの中で最大のリポジトリを持つ可能性があるArchユーザーリポジトリ（AUR）も持っています。パッケージングプロセスも非常に簡単で、公式リポジトリやAURにないパッケージが欲しい場合、自分で作成するのも容易です。
- **Linux Mint** は、Ubuntu LTSリリースから派生しており、Cinnamon、MATE、Xfceなど、いくつかの異なるデスクトップ環境を特徴としています。Mintは非常に洗練されており、その美学は非常に魅力的です。特に新しいアイコンテーマが気に入っていますが、GTK+テーマは私の好みに合わないのであまり好きではありません。最新リリースのMint 19ではバグがあり、約2週間前にフォーラムで質問しましたが、まだ返信がなく、そのバグは私の生活を少し不便にしています。
- **Kali Linux** は、上級のペネトレーションテストやセキュリティ監査を目的としたDebianベースのLinuxディストリビューションです。Kaliには、ペネトレーションテスト、セキュリティリサーチ、コンピューターフォレンジクス、リバースエンジニアリングなど、さまざまな情報セキュリティタスクに向けた数百のツールが含まれています。

役立つリソース:

- [Linuxディストリビューションの一覧](https://en.wikipedia.org/wiki/List_of_Linux_distributions)
- [あなたのお気に入りのLinuxディストリビューションは何ですか？その理由は？](https://www.quora.com/What-is-your-favorite-Linux-distro-and-why)

</details>

<details>
<summary><b>Unix、Linux、BSD、GNUの違いは何ですか？</b></summary><br>

**GNU** は実際にはOSではありません。むしろ、自由ソフトウェアを統治する一連のルールや哲学であり、同時にOSを作成しようとする過程で多くのツールを生み出しました。つまり、**GNU**ツールは、すでに存在していたツールのオープンバージョンであり、オープンソフトウェアの原則に従って再実装されたものです。**GNU/Linux** は、これらのツールと **Linuxカーネル** を組み合わせた完全なOSですが、他にも**GNU/Hurd**のようなGNUが存在します。

**Unix** と **BSD** は、さまざまなレベルの「クローズドソース」であるPOSIXの「古い」実装です。**Unix** は通常、完全にクローズドソースですが、**Unix**のフレーバーは **Linux** のフレーバーと同じくらい多いかもしれません。**BSD** は通常「オープン」とは見なされませんが、リリースされた当時は非常にオープンだと考えられていました。ライセンスも、当時の「よりオープン」なライセンスよりも、商業利用に対してはるかに少ない制約を持っていました。

**Linux** はこの4つの中で最も新しいです。厳密には「カーネルのみ」です。しかし、一般的には、GNUツールやその他のコアコンポーネントと組み合わせることで、完全なOSと見なされます。

これらの主な違いは、その理想にあります。**Unix**、**Linux**、**BSD** は、それぞれ異なる理想を実装しています。すべてPOSIXに準拠しており、基本的に互換性があります。彼らは同じ問題を異なる方法で解決することもあります。そのため、理想とPOSIX標準の実装方法以外には、大きな違いはほとんどありません。

詳細については、**GNU**、**OSS**、**Linux**、**BSD**、**UNIX** の作成に関する簡単な記事を読むことをお勧めします。それらは個々の理想に傾倒していますが、これらの記事を読むことで、違いをよりよく理解できるでしょう。

役立つリソース:

- [Unix、Linux、BSD、GNUの違いは何ですか？ (オリジナル)](https://unix.stackexchange.com/questions/104714/what-is-the-difference-between-unix-linux-bsd-and-gnu)
- [大論争: それはLinuxか、GNU/Linuxか？](https://www.howtogeek.com/139287/the-great-debate-is-it-linux-or-gnulinux/)

</details>

<details>
<summary><b>CLIとは何ですか？お気に入りのCLIツール、ヒント、ハックについて教えてください。</b></summary><br>

**CLI** はコマンドラインインターフェースまたはコマンド言語インタープリタの略です。コマンドラインはシステムやコンピュータを制御するための最も強力な方法の一つです。

Unixのようなシステムでは、**CLI** はユーザーがシステムに実行させるコマンドを入力できるインターフェースです。**CLI** は非常に強力ですが、エラーに対して寛容ではありません。

**CLI** を使用すると、システムの内部やコードを非常に細かく操作できます。どのOSを使用していても、GUIよりも柔軟性とコントロールを提供します。Githubにホストされているソフトウェアを使用する場合、**CLI** でいくつかのコマンドを実行して動作させる必要があることが多いです。

**お気に入りのツール**

- `screen` - 無料のターミナルマルチプレクサーで、セッションを開始すると、接続が切断されてもターミナルが保存されるので、後で再開したり、自宅から再開できます。
- `ssh` - 学ぶべき最も価値のあるコマンドで、次のような驚くべきことができます:
  * `sshfs` を使用してインターネット経由でファイルシステムをマウント
  * コマンドを転送：`rsync` デーモンがないサーバーで、ssh経由で自分で開始して実行
  * バッチファイルで実行：リモートコマンドの出力をリダイレクトしてローカルバッチファイル内で使用
- `vi/vim` - 最も人気があり強力なテキストエディタで、汎用性が高く、大きなファイルでも非常に高速に動作します。
- `bash-completion` - シェルのためのいくつかの事前定義された補完ルールを含んでいます。

**ヒント & ハック**

- `CTRL + R` でコマンド履歴を検索
- ディレクトリスタックを操作できる `popd/pushd` などのシェル組み込みコマンド
- `CTRL + U`、`CTRL + E` などの編集キーボードショートカット
- 組み合わせが自動展開されます:
  * `!*` - 最後のコマンドのすべての引数
  * `!!` - 最後のコマンド全体
  * `!ssh` - sshで始まる最後のコマンド

役立つリソース:

- [コマンドラインインターフェースの定義](http://www.linfo.org/command_line_interface.html)
- [Bashを使用したお気に入りのコマンドライントリックは何ですか？](https://stackoverflow.com/questions/68372/what-is-your-single-most-favorite-command-line-trick-using-bash/69716)
- [お気に入りのコマンドライン機能やトリックは何ですか？](https://unix.stackexchange.com/questions/6/what-are-your-favorite-command-line-features-or-tricks)

</details>

<details>
<summary><b>お気に入りのシェルは何ですか？その理由は？</b></summary><br>

**BASH** が私のお気に入りです。これは個人的な好みの問題で、シンタックスが好きで、自分にとってしっくりくるからです。入力/出力のリダイレクトシンタックス（`>>`、`<< 2>&1`、`2>`、`1>` など）はC++に似ているので、認識しやすいです。

また、**ZSH** シェルも好きです。**BASH** よりもはるかにカスタマイズ性が高いからです。Oh-My-Zshフレームワーク、強力なコンテキストベースのタブ補完、パターンマッチング/グロービングの強化、ロード可能なモジュールなどがあります。

役立つリソース:

- [コマンドシェルの比較](https://en.wikipedia.org/wiki/Comparison_of_command_shells)

</details>


<details>
<summary><b>コマンドラインでヘルプを得るにはどうすればよいですか？***</b></summary><br>

- `man` [コマンド名] を使用して、コマンドの説明を見ることができます（例: `man less`、`man cat`）

- `-h` または `--help` 一部のプログラムでは、このパラメータを渡すと使い方の説明が表示されます（例: `python -h` や `python --help`）

</details>

<details>
<summary><b>ログイン後に*nixサーバーで最初に実行する5つのコマンド</b></summary><br>

- `w` - サーバーの稼働時間などの多くの有用な情報が表示されます
- `top` - 実行中のすべてのプロセスを確認し、CPUやメモリの使用量などで並べ替えることができます
- `netstat` - サーバーがどのポートとIPでリッスンしているか、およびそれを使用しているプロセスを確認できます
- `df` - ファイルシステムによって使用されているディスクスペースの利用状況を報告します
- `history` - 現在接続しているユーザーが以前に実行したコマンドを表示します

役立つリソース:

- [Linuxサーバーに接続した際の最初の5つのコマンド (オリジナル)](https://www.linux.com/blog/first-5-commands-when-i-connect-linux-server)

</details>

<details>
<summary><b><code>ls -al</code>の出力におけるフィールドの意味は何ですか？</b></summary><br>

出力の順序は以下の通りです:

```bash
-rwxrw-r--    1    root   root 2048    Jan 13 07:11 db.dump
```

- ファイルのアクセス権限、
- リンクの数、
- 所有者の名前、
- 所有者のグループ、
- ファイルサイズ、
- 最終更新時刻、
- ファイル/ディレクトリ名

ファイルのアクセス権限は以下のように表示されます:

- 最初の文字は `-`、`l`、または `d` で、`d` はディレクトリ、`-` はファイル、`l` はシンボリックリンク（またはソフトリンク） - 特殊なファイルタイプを示します
- 3セットの文字が3回表示され、所有者、グループ、その他のアクセス権限を示します:
  - `r` = 読み取り可能
  - `w` = 書き込み可能
  - `x` = 実行可能

あなたの例では `-rwxrw-r--` は以下を意味します:

- 通常のファイル（`-` と表示される）
- 所有者によって読み取り、書き込み、実行が可能 (`rwx`)
- グループによって読み取り、書き込みが可能、実行は不可 (`rw-`)
- その他のユーザーによって読み取り可能で、書き込みや実行は不可 (`r--`)

役立つリソース:

- [<code>ls -al</code>の出力におけるフィールドの意味は何ですか？（オリジナル）](https://unix.stackexchange.com/questions/103114/what-do-the-fields-in-ls-al-output-mean)

</details>

<details>
<summary><b>ログインしているユーザーのリストを取得するにはどうすればよいですか？</b></summary><br>

ログインしているユーザーの概要、各ユーザーのログイン、端末、ログイン日時、および接続元のコンピュータ（可能な場合）を含む情報を表示するには、次のコマンドを入力します：

```bash
# これには、/var/run/utmp および /var/log/wtmp ファイルを使用して詳細情報を取得します。
who
```

より詳細な情報、例えばユーザー名、端末、ソースコンピュータのIP番号、ログインが開始された時間、アイドル時間、プロセスのCPUサイクル、ジョブのCPUサイクル、現在実行中のコマンドなどを含む情報を取得するには、次のコマンドを入力します：

```bash
# それには、/var/run/utmp および /proc のプロセスが使用されます。
w
```

最後にログインしたユーザーのリストを表示するには、次のコマンドを入力します：

```bash
# /var/log/wtmpを使用します。
last
```

役立つリソース：

- [4 Ways to Identify Who is Logged-In on Your Linux System](https://www.thegeekstuff.com/2009/03/4-ways-to-identify-who-is-logged-in-on-your-linux-system/)

</details>

<details>
<summary><b>バックグラウンドでプロセスを実行する利点は何ですか？どうやってそれを行うことができますか？</b></summary><br>

バックグラウンドでプロセスを実行する最も大きな利点は、他のプロセスがバックグラウンドで実行されている間に、同時に他のタスクを実行できることです。これにより、他のプロセスを作業しながらバックグラウンドでより多くのプロセスを完了できます。これは、コマンドの最後に特別な文字 `&` を追加することで実現できます。

一般的に、実行に時間がかかり、ユーザーの操作を必要としないアプリケーションは、バックグラウンドに送信され、ターミナルでの作業を続けることができます。

たとえば、バックグラウンドで何かをダウンロードしたい場合、次のように実行できます：

```bash
wget https://url-to-download.com/download.tar.gz &
```


コマンドを実行すると、次のような出力が得られます：

```bash
[1] 2203
```

ここで、1はジョブのシリアル番号で、2203はジョブのPIDです。

バックグラウンドで実行中のジョブを確認するには、次のコマンドを使用します：

```bash
jobs
```

バックグラウンドで実行中のジョブに対してPIDが表示され、ジョブを終了するには次のコマンドを使用します：

```bash
kill PID
```

PIDはジョブのPIDに置き換えてください。バックグラウンドで1つのジョブのみが実行されている場合、次のコマンドでそれを前面に持ってくることができます：

```bash
fg
```

バックグラウンドで複数のジョブが実行されている場合、次のコマンドを使用して任意のジョブを前面に持ってくることができます：

```bash
fg %#
```

ジョブのシリアル番号を `#` に置き換えてください。

有用なリソース：

- [How do I run a Unix process in the background?](https://kb.iu.edu/d/afnz)
- [Job Control Commands](http://tldp.org/LDP/abs/html/x9644.html)
- [What is/are the advantage(s) of running applications in background?](https://unix.stackexchange.com/questions/162186/what-is-are-the-advantages-of-running-applications-in-backgound)

</details>

<details>
<summary><b>プロセスを管理する前に、それらを識別できる必要があります。どのツールを使用しますか？ ***</b></summary><br>

未完成です。

</details>

<details>
<summary><b>rootユーザーとしてコマンドを実行することは良い習慣ですか、それとも悪い習慣ですか？</b></summary><br>

すべてをrootとして実行することは悪い習慣です。その理由は以下の通りです：

- **愚かさ**: 不注意なミスを防ぐものがありません。システムに潜在的に危害を加える変更を試みる場合は、`sudo` を使用する必要があります。これにより、パスワードを入力する際に一時停止があり、ミスを犯す可能性がないことを確認できます。

- **セキュリティ**: 管理者ユーザーのログインアカウントを知らなければ、ハッキングが難しくなります。rootはすでに管理者の認証情報の半分を持っていることになります。

- **本当に必要ない**: 複数のコマンドをrootとして実行する必要があり、`sudo` が期限切れになるたびにパスワードを何度も入力するのが面倒な場合は、`sudo -i` を実行すればrootになります。パイプを使ってコマンドを実行したい場合は、`sudo sh -c "command1 | command2"` を使用してください。

- **リカバリコンソールで使用することができます**: リカバリコンソールを使用すると、大きなミスから回復することができるほか、アプリケーション（`sudo` として実行する必要があったもの）によって引き起こされた問題を修正できます。Ubuntuでは、rootアカウントにパスワードは設定されていませんが、変更方法をオンラインで検索することができます。これにより、物理的にアクセスできる人が損害を与えるのが難しくなります。

有用なリソース：

- [Why is it bad to log in as root? (original)](https://askubuntu.com/questions/16178/why-is-it-bad-to-log-in-as-root)
- [What's wrong with always being root?](https://serverfault.com/questions/57962/whats-wrong-with-always-being-root)
- [Why you should avoid running applications as root](https://bencane.com/2012/02/20/why-you-should-avoid-running-applications-as-root/)

</details>

<details>
<summary><b>メモリ統計とCPU統計を確認するにはどうすればよいですか？</b></summary><br>

どちらも `top/htop` を使用します。物理メモリと仮想メモリの統計を表示するには、`free` と `vmstat` コマンドを使用します。CPUの使用率やその他の統計を確認するには、`sar` コマンドを使用します（ただし、`sar` は多くのシステムにはインストールされていません）。

有用なリソース：

- [How do I Find Out Linux CPU Utilization?](https://www.cyberciti.biz/tips/how-do-i-find-out-linux-cpu-utilization.html)
- [16 Linux server monitoring commands you really need to know](https://www.hpe.com/us/en/insights/articles/16-linux-server-monitoring-commands-you-really-need-to-know-1703.html)

</details>

<details>
<summary><b>ロードアベレージとは何ですか？</b></summary><br>

Linuxの**ロードアベレージ**は、「システムロードアベレージ」を示し、システム上の実行中のスレッド（タスク）の要求を、実行中および待機中のスレッドの平均数として表示します。これは、システムが現在処理している以上の要求を測定します。ほとんどのツールでは、1分、5分、15分の3つの平均が表示されます。

これらの3つの数字は、異なるCPUの数字ではありません。これらの数字は、指定された期間（直近の1分、5分、15分）のロード数の平均値です。

**ロードアベレージ**は通常「実行キューの平均長さ」として説明されます。したがって、少数のCPU消費プロセスやスレッドが**ロードアベレージ**を1を超えて上昇させる可能性があります。**ロードアベレージ**がCPUコアの総数未満であれば問題はありません。しかし、CPUの数を超えると、いくつかのスレッド/プロセスがキューに留まり、実行の準備が整っているが、空きCPUを待っていることを意味します。

これは、システムの状態をいくつかの期間にわたって平均化したものを示すためのものであり、平均化されているため、システムに重い負荷がかかった後は0に戻るのに時間がかかります。

いくつかの解釈：

- 平均が0.0の場合、システムはアイドル状態です。
- 1分間の平均が5分または15分の平均より高い場合、負荷が増加しています。
- 1分間の平均が5分または15分の平均より低い場合、負荷が減少しています。
- これらの数値がCPUの数を超える場合、パフォーマンスに問題があるかもしれません（依存します）。

有用なリソース：

- [Linux Load Averages: Solving the Mystery (original)](http://www.brendangregg.com/blog/2017-08-08/linux-load-averages.html)
- [Linux load average - the definitive summary](http://blog.angulosolido.pt/2015/04/linux-load-average-definitive-summary.html)
- [How CPU load averages work (and using them to triage webserver performance!)](https://jvns.ca/blog/2016/02/07/cpu-load-averages/)

</details>

<details>
<summary><b>Linux/Unixでは、私のパスワードはどこに保存されていますか？</b></summary><br>

パスワードはシステム上にはどこにも保存されていません。`/etc/shadow` に保存されているのは、いわゆるパスワードのハッシュです。

テキスト（パスワード）のハッシュは、テキストに対していわゆる一方向関数を実行することで作成され、チェック用の文字列が生成されます。設計上、このプロセスを逆にすることは「不可能」（計算上困難）です。

古いUnixのバリアントでは、暗号化されたパスワードが `/etc/passwd` に保存されており、各アカウントに関するその他の情報も含まれていました。

新しいバリアントでは、関連するフィールドに `*` があり、パスワードを保存するために `/etc/shadow` を使用します。これは、他の情報だけが必要な場合にパスワードへの読み取りアクセスを誰も得られないようにするためです（`shadow` は通常、`passwd` よりも強く保護されています）。

詳細については、`man crypt`、`man shadow`、`man passwd` を参照してください。

有用なリソース：

- [Where is my password stored on Linux?](https://security.stackexchange.com/questions/37050/where-is-my-password-stored-on-linux)
- [Where are the passwords of the users located in Linux?](https://www.cyberciti.biz/faq/where-are-the-passwords-of-the-users-located-in-linux/)
- [Linux Password & Shadow File Formats](https://www.tldp.org/LDP/lame/LAME/linux-admin-made-easy/shadow-file-formats.html)

</details>

<details>
<summary><b>すべてのディレクトリのパーミッションを変更するにはどうすればよいですか？ファイルを除いてすべてのディレクトリに、ファイルを除いてすべてのファイルに適用するにはどうすればよいですか？</b></summary><br>

すべてのディレクトリのパーミッションを例えば **755**（`drwxr-xr-x`）に変更するには：

```bash
find /path/to/directory -type d -exec chmod 755 {} +

```bash
find /opt/data -type d -exec chmod 755 {} \;
```

すべてのファイルのパーミッションを例えば **644**（`-rw-r--r--`）に変更するには：

```bash
find /opt/data -type f -exec chmod 644 {} \;
```

役立つリソース：

- [フォルダおよびそのサブフォルダとファイルすべてに対してchmodを設定するには？（原文）](https://stackoverflow.com/questions/3740152/how-do-i-set-chmod-for-a-folder-and-all-of-its-subfolders-and-files?rq=1)

</details>

<details>
<summary><b>すべてのコマンドが <code>command not found</code> で失敗します。エラーの原因を特定して解決するにはどうすればよいですか？</b></summary><br>

この問題は、`PATH` 環境変数がどこかで上書きされていることが原因です。エラーの内容から、`PATH` に `/bin` など、コマンド（bash を含む）が存在するディレクトリが含まれていないことが示唆されます。

デバッグを始める一つの方法は、`-x` オプションを使ってサブシェルを起動することです：

```bash
bash --login -x
```

これにより、そのシェルを起動する際に実行されるすべてのコマンドとその引数が表示されます。

また、`PATH` 変数の値を表示することも非常に役立ちます：

```bash
echo $PATH
```

次のコマンドを実行すると：

```bash
PATH=/bin:/sbin:/usr/bin:/usr/sbin
```

ほとんどのコマンドが動作するようになります。その後、~/.bash_profile を編集し、~/.bashrc ではなく、PATH をリセットしている原因を修正します。root および他のユーザーのデフォルトの PATH 変数の値は /etc/profile ファイルに記載されています。

有用なリソース：

- [PATHにパスを正しく追加するにはどうすればよいですか？](https://unix.stackexchange.com/questions/26047/how-to-correctly-add-a-path-to-path)

</details>

<details>
<summary><b><code>CTRL + C</code> を押してもスクリプトがまだ実行中です。どうやって停止しますか？</b></summary><br>

ほとんどの場合、スクリプトを停止するには `CTRL + C` キーボードコンビネーションを使用します。これにより、スクリプトに中断信号（SIGINT）が送信され、その実行が終了します。これが機能しない場合、スクリプトがまだ実行中である場合は、`CTRL + \` コンビネーションを使用してみてください。これにより、スクリプトに終了信号（SIGQUIT）が送信され、即座に終了する可能性があります。

別の方法として、ターミナルやコマンドラインインターフェースを使用している場合は、`kill` コマンドを使ってスクリプトプロセスに信号を送信することもできます。`ps` または `top` コマンドを使用してスクリプトのプロセスID（PID）を見つけ、`kill` コマンドでそのPIDを指定してスクリプトを停止します。

場合によっては、`kill -9` コマンドを使用してスクリプトを強制的に停止する必要があるかもしれません。通常の `kill` コマンドがスクリプトがスタックしている場合や応答していない場合に機能しないことがあります。`-9` オプションはSIGKILL信号を送信し、プロセスを即座に停止させます。

</details>

<details>
<summary><b><code>grep</code> コマンドとは何ですか？同じ行に複数の文字列を一致させるにはどうすればよいですか？</b></summary><br>

`grep` ユーティリティは、`egrep` や `fgrep` を含むUnixツールのファミリーです。

`grep` はファイルパターンを検索します。他のコマンドの出力の中から特定のパターンを探している場合、`grep` は関連する行を強調表示します。ログファイルや特定のプロセスなどを検索する際にこの `grep` コマンドを使用します。

複数の文字列を一致させるには：

```bash
grep -E "string1|string2" filename
```

または

```bash
grep -e "string1" -e "string2" filename
```

有用なリソース：

- [grepとは何で、どうやって使うのか？](https://kb.iu.edu/d/afiy)

</details>

<details>
<summary><b>ファイルコンテンツコマンドの説明とその説明をしてください。</b></summary><br>

- `head`: ファイルの先頭部分を確認するために使用します。
- `tail`: ファイルの末尾部分を確認するために使用します。`head` コマンドの逆です。
- `cat`: ファイルを表示、作成、結合するために使用します。
- `more`: テキストを端末ウィンドウにページ形式で表示するために使用します。
- `less`: テキストを逆方向に表示し、また単一行の移動も提供します。

有用なリソース：

- [シェルプロンプトからテキストファイルを表示する方法](https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux/4/html/Step_by_Step_Guide/s1-viewingtext-terminal.html)

</details>

<details>
<summary><b>SIGHUP、SIGINT、SIGKILL、および SIGTERM の POSIX シグナルについて説明してください。</b></summary><br>

- **SIGHUP** - 制御端末が閉じられたときにプロセスに送信されます。もともとはシリアルラインの切断（ハングアップ）をプロセスに通知するために設計されました。このシグナルを受け取ると、多くのデーモンは終了する代わりに設定ファイルを再読み込みし、ログファイルを再オープンします。
- **SIGINT** - ユーザーがプロセスを中断したいときに、その制御端末からプロセスに送信されます。通常は `Ctrl+C` を押すことで開始されますが、一部のシステムでは「削除」文字や「ブレーク」キーも使用できます。
- **SIGKILL** - プロセスを即座に終了させるために送信されます（強制終了）。**SIGTERM** や **SIGINT** とは異なり、このシグナルは捕捉または無視することができず、受信したプロセスはクリーンアップを行うことができません。
- **SIGTERM** - プロセスに終了を要求するために送信されます。**SIGKILL** シグナルとは異なり、捕捉して解釈したり無視したりすることができます。これにより、プロセスはリソースを解放し、状態を保存するなどのクリーンな終了を行うことができます。**SIGINT** は **SIGTERM** にほぼ同じです。

有用なリソース：

- [POSIXシグナル](https://dsa.cs.tsinghua.edu.cn/oj/static/unix_signal.html)
- [UNIXシグナルプログラミングの紹介](http://titania.ctie.monash.edu.au/signals/)

</details>

<details>
<summary><b><code>kill</code> コマンドは何をするのですか？</b></summary><br>

UNIX および UNIX 系オペレーティングシステムでは、`kill` はプロセスにシグナルを送信するためのコマンドです。デフォルトでは、送信されるメッセージは終了シグナルであり、プロセスに終了を要求します。しかし、`kill` という名前は誤解を招くことがあり、送信されるシグナルがプロセスの終了に関連していない場合もあります。

有用なリソース：

- [Linuxでの「kill」コマンドの習得](https://www.maketecheasier.com/kill-command-in-linux/)

</details>

<details>
<summary><b><code>rm</code> と <code>rm -rf</code> の違いは何ですか？</b></summary><br>

`rm` は指定されたファイルのみを削除します（ディレクトリは削除しません）。`-rf` を付けると、次のようになります：

- `-r`、`-R`、`--recursive` はディレクトリの内容を再帰的に削除します。これには隠しファイルやサブディレクトリも含まれます。
- `-f`、`--force` は存在しないファイルを無視し、確認を行いません。

有用なリソース：

- [`rm -r` と `rm -f` の違いは何ですか？](https://superuser.com/questions/1126206/what-is-the-difference-between-rm-r-and-rm-f)

</details>

<details>
<summary><b><code>grep</code> を再帰的に実行する方法は？いくつかの例で説明してください。</b></summary>

完了次第追加します。

</details>

<details>
<summary><b><code>archive.tgz</code> は約 30 GB です。このファイルの内容をリスト表示し、特定のファイルだけを抽出するにはどうすればよいですか？</b></summary><br>

```bash
# 内容のリスト表示
tar tf archive.tgz

# ファイルの解凍
tar xf archive.tgz filename
```

有用なリソース：

- [tar または tar.gz ファイルの内容をリストする方法](https://www.cyberciti.biz/faq/list-the-contents-of-a-tar-or-targz-file/)
- [tar.gz から特定のファイルを抽出する方法](https://unix.stackexchange.com/questions/61461/how-to-extract-specific-files-from-tar-gz)

</details>

<details>
<summary><b>複数のシェルコマンドを1行で実行する</b></summary><br>

前のコマンドが成功した場合にのみ次のコマンドを実行したい場合は、`&&`演算子を使用して結合します：

```bash
cd /my_folder && rm *.jar && svn co path to repo && mvn compile package install
```

コマンドのうち1つが失敗すると、それに続く他のすべてのコマンドは実行されません。

前のコマンドが失敗したかどうかに関係なく、すべてのコマンドを実行したい場合は、セミコロンで区切ります：

```bash
cd /my_folder; rm *.jar; svn co path to repo; mvn compile package install
```

この場合、次のコマンドの実行が前のコマンドの成功に依存する最初のケースが望ましいと思われます。

また、すべてのコマンドをスクリプトにまとめて、それを実行することもできます：

```bash
#! /bin/sh
cd /my_folder \
&& rm *.jar \
&& svn co path to repo \
&& mvn compile package install
```

有用なリソース:

- [複数のLinuxコマンドを1行で結合して実行する方法（オリジナル）](https://stackoverflow.com/questions/13077241/execute-combine-multiple-linux-commands-in-one-line)

</details>

<details>
<summary><b>他の権限に影響を与えずに、すべてのユーザーにファイルの実行アクセスを付与するために <code>chmod</code> に渡すことができる記号表現は何ですか？</b></summary><br>

```bash
chmod a+x /path/to/file
```

- `a` - すべてのユーザーに適用
- `x` - 実行権限
- `r` - 読み取り権限
- `w` - 書き込み権限

有用なリソース:
- [chmod を使用してファイル権限を設定する方法](https://www.washington.edu/computing/unix/permissions.html)
- [「chmod +x your_file_name」とは何をするコマンドで、どのように使用するのですか？](https://askubuntu.com/questions/443789/what-does-chmod-x-filename-do-and-how-do-i-use-it)

</details>

<details>
<summary><b>2つのローカルディレクトリを同期するにはどうすればよいですか？</b></summary><br>

同じシステム上で **dir1** の内容を **dir2** に同期するには、次のコマンドを入力します:

```bash
rsync -av --progress --delete dir1/ dir2
```

- `-a`, `--archive` - アーカイブモード
- `--delete` - 余分なファイルを宛先ディレクトリから削除
- `-v`, `--verbose` - 詳細モード（冗長性を高める）
- `--progress` - 転送中に進行状況を表示

参考資料:

- [ローカルディレクトリを同期する方法 (オリジナル)](https://unix.stackexchange.com/questions/392536/how-can-i-sync-two-local-directories)
- [rsyncでフォルダを同期する](https://www.jveweb.net/en/archives/2010/11/synchronizing-folders-with-rsync.html)

</details>

<details>
<summary><b>多くの基本的なメンテナンスタスクでは、設定ファイルの編集が必要です。変更を元に戻す方法を説明してください。</b></summary><br>

- 編集前にファイルを手動でバックアップする（このようにブレース展開を使用: `cp filename{,.orig}`）
- ファイルが保存されているディレクトリ構造を手動でコピーする（例: `cp`、`rsync`、または `tar` を使用）
- 使用しているエディターで元のファイルをバックアップする（例: エディターの設定ファイルにルールを設定する）
- 最良の解決策は、`git`（または他のバージョン管理ツール）を使用して設定ファイルを管理することです（例: `/etc` ディレクトリに `etckeeper` を使用）

参考資料:

- [拡張子の前に .bak でファイルをバックアップする](https://unix.stackexchange.com/questions/66376/backup-file-with-bak-before-filename-extension)
- [設定ファイルのバージョン管理に git を使用するのは良い考えですか？](https://superuser.com/questions/1037211/is-it-a-good-idea-to-use-git-for-configuration-file-version-controlling)

</details>

<details>
<summary><b>20MBを超えるすべてのファイルを見つける必要があります。どうやってやりますか？</b></summary><br>

```bash
find / -type f -size +20M
```

参考資料:

- [xバイトより大きい/小さいファイルを見つけるにはどうすればよいですか？](https://superuser.com/questions/204564/how-can-i-find-files-that-are-bigger-smaller-than-x-bytes)

</details>

<details>
<summary><b>なぜ <code>sudo su -</code> を使うのか、ただの <code>sudo su</code> ではない理由は？</b></summary><br>

`sudo` はほとんどの最新のLinuxディストリビューションで使用されており、（常にではありませんが）rootユーザーが無効化され、パスワードが設定されていません。そのため、`su` でrootユーザーに切り替えることはできません（試してみてもよいでしょう）。root権限で `sudo` を呼び出す必要があります：`sudo su`。

`su` は単にユーザーを切り替えるだけで、通常のシェルが起動し、以前のユーザーとほぼ同じ環境が提供されます。

`su -` は、ユーザーを切り替えた後にログインシェルを起動します。ログインシェルは、ほとんどの環境変数をリセットし、クリーンな状態を提供します。

参考資料:

- [su vs sudo -s vs sudo -i vs sudo bash](https://unix.stackexchange.com/questions/35338/su-vs-sudo-s-vs-sudo-i-vs-sudo-bash)
- [なぜ su - を使い、ただの su を使わないのか？(オリジナル)](https://unix.stackexchange.com/questions/7013/why-do-we-use-su-and-not-just-su)

</details>

<details>
<summary><b>過去60分以内にシステム上で変更されたファイルを見つける方法は？</b></summary><br>

```bash
find / -mmin -60 -type f
```

参考資料:

- [ディレクトリ内で過去30日間に変更されたすべてのファイルを取得する（オリジナル）](https://stackoverflow.com/questions/23070245/get-all-files-modified-in-last-30-days-in-a-directory)

</details>

<details>
<summary><b>古いログファイルを保持する主な理由は何ですか？</b></summary><br>

それらは、システム上の問題を調査するために不可欠です。**ログ管理**は、ITセキュリティにとって非常に重要です。

サーバー、ファイアウォール、その他のIT機器は、重要なイベントや取引を記録するログファイルを保持します。この情報は、内部および外部からのネットワークに影響を与える敵対的な活動に関する重要な手がかりを提供する可能性があります。ログデータは、構成問題やハードウェアの故障などの機器の問題を特定し、トラブルシューティングするための情報も提供できます。

これは、誰があなたのサイトに来て、いつ、そして正確に何を見たかを記録するサーバーの記録です。それは非常に詳細で、以下の内容を示します。

- 訪問者の出身地
- 使用しているブラウザ
- 正確にどのファイルを見たか
- 各ファイルの読み込みにかかった時間
- その他多くの技術的な情報

考慮すべき要素:

- 保持や破棄に関する法的要件
- 会社の保持および破棄に関するポリシー
- ログの有用性の期間
- ログから解決したい質問
- ログが占めるスペースの量

ログを収集して分析することで、ネットワーク内で何が起こっているかを理解できます。各ログファイルには、多くの情報が含まれており、それを読み取り、分析する方法を知っていれば非常に貴重です。

参考資料:

- [ログファイルをどのくらいの期間保持しますか？](https://serverfault.com/questions/135365/how-long-do-you-keep-log-files)

</details>

<details>
<summary><b>増分バックアップとは何ですか？</b></summary><br>

増分バックアップは、前回のバックアップ以降に変更されたファイルのみをコピーするバックアップの一種です。

参考資料:

- [増分バックアップとは？](https://www.nakivo.com/blog/what-is-incremental-backup/)

</details>

<details>
<summary><b>RAIDとは何ですか？RAID0、RAID1、RAID5、RAID6、RAID10とは？</b></summary><br>

**RAID**（Redundant Array of Inexpensive Disks）は、データストレージのパフォーマンスや信頼性を向上させるための技術です。

- **RAID0**: ディスクの**ストライピング**とも呼ばれ、ファイルを分割してRAIDグループ内のすべてのディスクドライブにデータを分散させる技術です。故障に対する保護はありません。
- **RAID1**: 安全性を高めるために、同じデータを2つのドライブに書き込む一般的なディスクサブシステムです。**ミラーリング**とも呼ばれ、書き込みパフォーマンスの向上はありませんが、読み取りパフォーマンスは各ディスクのパフォーマンスの合計に匹敵する場合があります。ただし、1つのドライブが故障した場合、2番目のドライブが使用され、故障したドライブは手動で交換されます。交換後、RAIDコントローラが作業中のドライブの内容を新しいドライブに複製します。
- **RAID5**: パリティデータを計算し、安全性を高めると同時に、データを3つ以上のドライブにインターリーブして速度を向上させるディスクサブシステムです（**ストライピング**）。1つのドライブが故障した場合、分散パリティから計算され、データが失われることはありません。
- **RAID6**: RAID 6は、RAID 5を拡張し、もう1つのパリティブロックを追加します。最小4つのディスクが必要で、2つのディスクが同時に故障しても読み書きが継続できます。RAID 6は、読み取り操作にはパフォーマンスのペナルティがありませんが、パリティ計算に関連するオーバーヘッドのため、書き込み操作にはパフォーマンスのペナルティがあります。
- **RAID10**: **RAID 1+0**とも呼ばれ、ディスクのミラーリングとストライピングを組み合わせてデータを保護するRAID構成です。最小4つのディスクが必要で、ミラーリングされたペアにデータをストライプします。各ミラーリングペアのうち1つのディスクが機能していれば、データを取り出すことができます。ただし、同じミラーリングペアの2つのディスクが故障した場合、ストライプセットにはパリティがないため、すべてのデータが失われます。

参考資料:

- [RAID](https://www.prepressure.com/library/technology/raid)

</details>

<details>
<summary><b>ユーザーのデフォルトグループはどのように決定されますか？また、それをどのように変更しますか？</b></summary><br>

```bash
useradd -m -g initial_group username
```

`-g/--gid`: ユーザーの初期ログイングループのグループ名または番号を定義します。指定されている場合、グループ名は存在する必要があり、グループ番号が提供される場合は、既存のグループを指している必要があります。

指定されていない場合、`useradd`の動作は`/etc/login.defs`に含まれる`USERGROUPS_ENAB`変数に依存します。デフォルトの動作（`USERGROUPS_ENAB yes`）は、ユーザー名と同じ名前のグループを作成し、**GID**を**UID**と同じにします。

参考資料:

- [Linuxでユーザーのデフォルトグループを変更する方法](https://unix.stackexchange.com/questions/26675/how-can-i-change-a-users-default-group-in-linux)

</details>

<details>
<summary><b>日常作業やスクリプト作成に最適なコマンドラインテキストエディタは何ですか？</b></summary><br>

未完成です。

</details>

<details>
<summary><b>サーバーをラックにマウントする理由は何ですか？</b></summary><br>

- ハードウェアの保護
- 適切な冷却
- 整理された作業スペース
- より良い電力管理
- クリーンな環境

参考資料:

- [5 Reasons to Rackmount Your PC](https://www.racksolutions.com/news/custom-projects/5-reasons-to-rackmount-pc/)

</details>

###### ネットワークの質問 (23)

<details>
<summary><b>シンプルなネットワーク図を描いてください: 20台のシステム、1台のルーター、4台のスイッチ、5台のサーバー、小さなIPブロックがあります。</b></summary><br>

未完成です。

</details>

<details>
<summary><b>OSIモデル（または他のモデル）について理解しておくべき最も重要なことは何ですか？</b></summary><br>

**OSI**（または他の）モデルについて理解しておくべき最も重要なことは以下です：

- プロトコルを層に分けることができる
- 層がカプセル化を提供する
- 層が抽象化を提供する
- 層が他の機能からの分離を提供する

参考資料:

- [OSIモデルとネットワーキングプロトコルの関係](https://networkengineering.stackexchange.com/questions/6380/osi-model-and-networking-protocols-relationship)

</details>

<details>
<summary><b>VLANとサブネットの違いは何ですか？サブネットを設定するにはVLANが必要ですか？</b></summary><br>

**VLAN**と**サブネット**は異なる問題を解決します。**VLAN**はレイヤー2で動作し、例えばブロードキャストドメインを変更します。一方、**サブネット**は現在の文脈ではレイヤー3です。

**サブネット** - IPアドレスの範囲で、アドレスの一部（通常「ネットワークアドレス」と呼ばれる）とサブネットマスク（ネットマスク）によって決まります。例えば、ネットマスクが `255.255.255.0`（または短縮形で `/24`）で、ネットワークアドレスが `192.168.10.0` の場合、それはIPアドレスの範囲 `192.168.10.0` から `192.168.10.255` を定義します。これを短縮形で書くと `192.168.10.0/24` です。

**VLAN** - これを「スイッチの分割」と考えると良いでしょう。例えば、VLAN対応の8ポートスイッチがあるとします。4つのポートを1つの**VLAN**（例えば `VLAN 1`）に割り当て、残りの4つのポートを別の**VLAN**（例えば `VLAN 2`）に割り当てます。`VLAN 1`は`VLAN 2`のトラフィックを見ず、逆も同様です。論理的には、2つの別々のスイッチがあります。通常、スイッチがMACアドレスを見ていない場合、そのトラフィックは他のすべてのポートに「フラッディング」されます。**VLAN**はこれを防ぎます。

サブネットは、レイヤー2とレイヤー3でホストが通信するのを助けるIPアドレスの範囲に過ぎません。各サブネットは独自の**VLAN**を必要としません。**VLAN**は隔離（レイヤー2通信のサンドボックスであり、異なる**VLAN**の2つのシステムが通信できないが、**インターヴィLANルーティング**を通じて通信できる）、管理の容易さ、セキュリティのために実装されます。

参考資料:

- [VLANとサブネットの違いは何ですか？](https://superuser.com/questions/353664/what-is-the-difference-between-a-vlan-and-a-subnet)
- [ネットワークセキュリティとセグメンテーションのためのVLANSとサブネット](https://networkengineering.stackexchange.com/questions/46899/vlans-vs-subnets-for-network-security-and-segmentation)

</details>

<details>
<summary><b>知っておくべき一般的なネットワークポートを5つ挙げてください。</b></summary><br>

<table style="width:100%">
  <tr>
    <th>サービス</th>
    <th>ポート</th>
  </tr>
  <tr>
    <td>SMTP</td>
    <td>25</td>
  </tr>
  <tr>
    <td>FTP</td>
    <td>データ転送用が20、接続確立用が21</td>
  </tr>
  <tr>
    <td>DNS</td>
    <td>53</td>
  </tr>
  <tr>
    <td>DHCP</td>
    <td>DHCPサーバー用が67/UDP、DHCPクライアント用が68/UDP</td>
  </tr>
  <tr>
    <td>SSH</td>
    <td>22</td>
  </tr>
</table>

参考資料:

- [Red Hat Enterprise Linux 4: セキュリティガイド - 一般的なポート](https://web.mit.edu/rhel-doc/4/RH-DOCS/rhel-sg-en-4/ch-ports.html)

</details>

<details>
<summary><b>POPとIMAPとは何ですか？また、どちらを実装すべきかの選び方は？</b></summary><br>

POPとIMAPは、メールサーバーからメールクライアントにメッセージを取得するためのプロトコルです。

**POP** (_Post Office Protocol_) は、メールサーバーからクライアントへの一方向のプッシュを使用します。デフォルトでは、メッセージはPOPメールクライアントに送信され、メールサーバーからは削除されますが、メールサーバーがすべてのメッセージを保持するように設定することも可能です。メールクライアントでメッセージに対して行った操作（ラベル付け、削除、フォルダへの移動）は、メールサーバーには反映されず、他のメールクライアントからはアクセスできません。POPはメールサーバーのストレージスペースをほとんど使用せず、メッセージがメールサーバーや複数のクライアントではなく、1つのメールクライアントにのみ存在するため、より安全と見なされることがあります。

**IMAP** (_Internet Message Access Protocol_) は、メールサーバーとクライアント間で双方向の通信を使用します。IMAPで設定されたメールクライアントでメッセージを削除またはラベル付けすると、その操作はメールサーバーにも反映されます。IMAPは、メッセージが複数のデバイスで同じ状態で存在できるため、異なるクライアントやデバイスでのメールアクセス時に似たような体験を提供します。また、IMAPはメッセージを選択的に同期させることができ、クライアントから古いメッセージを削除し、必要に応じてメールサーバーから再同期できます。

複数のデバイスでメッセージにアクセスする必要があり、クライアントデバイスのディスクスペースを節約したい場合はIMAPを選択してください。メールサーバーのディスクスペースを節約し、1つのクライアントデバイスからのみメッセージにアクセスし、メッセージが複数のシステムに存在しないことを確認したい場合はPOPを選択してください。

</details>

<details>
<summary><b>デフォルトルートとルーティングテーブルを確認する方法は？</b></summary><br>

`netstat -nr`、`route -n`、または `ip route show` コマンドを使用することで、デフォルトルートとルーティングテーブルを確認できます。

参考資料:

- [Linuxでのルート（ルーティングテーブル）の確認方法](https://howto.lintel.in/how-to-check-routes-routing-table-in-linux/)
- [FreeBSDのデフォルトルート/ゲートウェイの設定](https://www.cyberciti.biz/faq/freebsd-setup-default-routing-with-route-command/)

</details>

<details>
<summary><b>127.0.0.1とlocalhostの違いは何ですか？</b></summary><br>

最も可能性の高い違いは、`localhost` の実際のルックアップがどこかで行われる必要があるということです。

`127.0.0.1` を使用する場合、（知能を持った）ソフトウェアはそれを直接IPアドレスに変換して使用します。`gethostbyname` の実装によっては、ドット形式（およびおそらく同等のIPv6形式）を検出し、ルックアップを行わないこともあります。

それ以外の場合、名前の解決が必要です。そして、ホストファイルがその解決に実際に使用される保証はありません（最初に、またはまったく）。そのため、`localhost` がまったく異なるIPアドレスになる可能性があります。

つまり、いくつかのシステムでは、ローカルホストファイルがバイパスされることがあります。Linuxでは、`host.conf` ファイルがこれを制御します（および多くの他のUnix系システムでも）。

Unixドメインソケットを使用すると、TCP/IPを使用するよりもわずかに高速になります（オーバーヘッドが少ないため）。WindowsはデフォルトでTCP/IPを使用しますが、Linuxは `localhost` を選択した場合にUnixドメインソケットを使用し、`127.0.0.1` を選択した場合にTCP/IPを使用しようとします。

参考資料:

- [127.0.0.1とlocalhostの違いは？](https://stackoverflow.com/questions/7382602/what-is-the-difference-between-127-0-0-1-and-localhost)
- [localhostと127.0.0.1](https://stackoverflow.com/questions/3715925/localhost-vs-127-0-0-1)

</details>

<details>
<summary><b><code>ping</code> コマンドに使用されるポートはどれですか？</b></summary><br>

`ping` は **ICMP** を使用します。具体的には **ICMPエコーリクエスト** と **ICMPエコーリプライ** パケットです。**ICMP** にはポートが関連付けられていません。ポートは、TCP と UDP という二つの IP トランスポート層プロトコルに関連しています。**ICMP**、TCP、UDP は「兄弟」であり、互いに基づいているわけではなく、IP の上で動作する三つの異なるプロトコルです。

**ICMP** パケットは、IP データグラムヘッダー内の「プロトコル」フィールドによって識別されます。**ICMP** は UDP や TCP の通信サービスを使用せず、生の IP 通信サービスを使用します。これは、**ICMP** メッセージが IP データグラムのデータフィールド内に直接運ばれることを意味します。`raw` という用語は、この処理がソフトウェアでどのように実装されているかに由来します。**ICMP** メッセージを作成して送信するためには、`raw` ソケットを開き、**ICMP** メッセージを含むバッファを構築し、そのバッファを `raw` ソケットに書き込みます。

**ICMP** の IP プロトコル値は 1 です。プロトコルフィールドは IP ヘッダーの一部で、IP データグラムのデータ部分に何が含まれているかを識別します。

ただし、ポートが開いているかどうかを確認するには、`nmap` を使用することができます：

```bash
nmap -p 80 example.com
```

参考資料:

- [Pingのポート番号](https://networkengineering.stackexchange.com/questions/42463/ping-port-number)
- [アドレス:ポートをpingすることは可能か？](https://superuser.com/questions/769541/is-it-possible-to-ping-an-addressport)

</details>

<details>
<summary><b>サーバーAがサーバーBと通信できない場合、考えられる原因をいくつかのステップで説明してください。</b></summary><br>

サーバー間の通信問題をトラブルシューティングするためには、TCP/IPスタックに従うのが理想的です：

1. **アプリケーション層**: 両方のサーバーでサービスは稼働していますか？サービスは正しく設定されていますか（例: 正しいIPアドレスとポートにバインドされているか）？アプリケーションおよびシステムログに意味のあるエラーが表示されていますか？

2. **トランスポート層**: アプリケーションが使用しているポートは開いていますか（telnetで確認してみてください）？サーバーにpingを送ることは可能ですか？

3. **ネットワーク層**: ネットワークまたはOSにファイアウォールが適切に設定されていますか？IPスタックが正しく設定されていますか（IPアドレス、ルート、DNSなど）？スイッチやルーターは正常に動作していますか（ARPテーブルを確認してください）？

4. **物理層**: サーバーはネットワークに接続されていますか？パケットが失われていませんか？

</details>

<details>
<summary><b>ホスト名がサーバー上で解決されないのはなぜですか？この問題を解決してください。***</b></summary><br>

詳細は未完成です。

</details>

<details>
<summary><b>ドメイン名をCLIで解決する方法（外部DNSを使用）と、IPアドレスをドメイン名に解決できるかどうか？</b></summary><br>

IPアドレスをドメイン名に解決する例:

```bash
# host コマンドを使用する場合:
host domain.com 8.8.8.8

# dig コマンドを使用する場合:
dig @9.9.9.9 google.com

# nslookup コマンドを使用する場合:
nslookup domain.com 8.8.8.8
```

IPアドレスをホスト名に解決できる場合があります。IPアドレスは**PTR**レコードに格納されていることがあります。その場合、次のコマンドを使用できます:

```bash
dig A <hostname>
```

ホストのIPv4アドレスを調べるには、次のコマンドを使用します:

```bash
dig AAAA <hostname>
```

ホストのIPv6アドレスを調べるには、次のコマンドを使用します:

```bash
dig PTR ZZZ.YYY.XXX.WWW.in-addr.arpa.
```

IPv4アドレス WWW.XXX.YYY.ZZZ のホスト名を調べるには（オクテットが逆順になっている点に注意）、次のようにします:

```bash
dig PTR b.a.9.8.7.6.5.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.8.b.d.0.1.0.0.2.ip6.arpa.
```

役立つリソース

- [Bashスクリプトでホスト名をIPアドレスに解決する方法](https://unix.stackexchange.com/questions/20784/how-can-i-resolve-a-hostname-to-an-ip-address-in-a-bash-script)
- [IPアドレスをドメイン名に解決する方法](https://superuser.com/questions/315687/how-to-resolve-ip-addresses-to-domain-names)

</details>

<details>
<summary><b>ポートの接続性を<code>telnet</code>または<code>nc</code>でテストする方法は？</b></summary><br>

```bash
# telnetコマンドを使用する場合：
telnet code42.example.com 5432

# nc (netcat)コマンドを使用する場合：
nc -vz code42.example.com 5432
```
</details>

<details>
<summary><b>なぜリモートでシステムを管理する際に<code>telnet</code>を避けるべきですか？</b></summary><br>

現代のオペレーティングシステムは、デフォルトで潜在的に安全でないサービスをすべてオフにしています。一方で、ネットワーク機器の一部のベンダーは、telnetプロトコルを使用して通信を確立することを許可しています。

**Telnet** は、最も安全でない通信方法を使用します。ネットワーク上でデータをプレーンテキスト形式で送信し、誰でもネットワークツールを使ってパスワードを簡単に見つけることができます。

**Telnet** の場合、ログイン認証情報がプレーンテキストで送信されるため、ネットワーク上でスニファーを実行している誰でも、**Telnet** のログインセッションを傍受することで数秒でデバイスを制御するために必要な情報を見つけることができます。

有用なリソース：

- [TelnetとSSHのセキュアな代替手段](https://www.ssh.com/ssh/telnet)
- [特定のポートでIPアドレスにtelnetする方法](https://superuser.com/questions/339107/how-to-telnet-to-an-ip-address-on-a-specific-port)

</details>

<details>
<summary><b><code>wget</code>と<code>curl</code>の違いは何ですか？</b></summary><br>

主な違いは次の通りです：`wget` の大きな強みは、再帰的にダウンロードできることです。`wget` はコマンドライン専用です。`curl` はFTP、FTPS、HTTP、HTTPS、SCP、SFTP、TFTP、TELNET、DICT、LDAP、LDAPS、FILE、POP3、IMAP、SMTP、RTMP、RTSPをサポートしています。

有用なリソース：

- [curlとwgetの違いは？ (原文)](https://unix.stackexchange.com/questions/47434/what-is-the-difference-between-curl-and-wget)

</details>

<details>
<summary><b>SSHとは何ですか？どのように動作しますか？</b></summary><br>

**SSH** は **Secure Shell** の略です。サーバー「A」からサーバー「B」へのシェルセッションを開始するためのプロトコルです。サーバー「B」と対話することができます。

**SSH** 接続を確立するには、リモートマシン（サーバーA）が **SSH** デーモンというソフトウェアを実行している必要があり、ユーザーのコンピュータ（サーバーB）には **SSH** クライアントが必要です。

**SSH** デーモンと **SSH** クライアントは、特定のネットワークポート（デフォルトは22）で接続を待ち受け、接続要求を認証し、ユーザーが正しい認証情報を提供した場合に適切な環境を生成します。

有用なリソース：

- [SSHの暗号化と接続プロセスの理解](https://www.digitalocean.com/community/tutorials/understanding-the-ssh-encryption-and-connection-process)

</details>

<details>
<summary><b>ほとんどのチュートリアルは、パスワード認証よりもSSHキー認証を使用することを推奨しています。なぜそれがより安全とされるのでしょうか？</b></summary><br>

**SSHキー** は、SSHプロトコルでのアクセス認証情報です。その機能はユーザー名やパスワードに似ていますが、キーは主に自動化プロセスやシステム管理者、パワーユーザーによるシングルサインオンの実装に使用されます。

ユーザーのパスワードを要求する代わりに、公開鍵と秘密鍵を使用して非対称暗号化アルゴリズムでクライアントの識別を確認することができます。

SSHサービスが公開鍵認証のみを許可する場合、攻撃者はサーバーに保存されている公開鍵に対応する秘密鍵のコピーが必要です。

SSHサービスがパスワードベースの認証を許可する場合、インターネットに接続されたSSHサーバーは、ユーザー名やパスワードを推測しようとするボットネットに昼夜問わず攻撃されます。ボットネットは情報を必要とせず、人気のある名前やパスワードを試すだけで済みます。これにより、ログが詰まることもあります。

有用なリソース：

- [鍵ベース認証（公開鍵認証）](http://www.crypto-it.net/eng/tools/key-based-authentication.html)
- [SSHのパスワード認証と鍵認証](https://security.stackexchange.com/questions/33381/ssh-password-vs-key-authentication)

</details>

<details>
<summary><b>パケットフィルタとは何ですか？どのように機能しますか？</b></summary><br>

**パケットフィルタリング** は、ネットワークアクセスを制御するためのファイアウォール技術で、送信および受信するパケットを監視し、ソースおよびデスティネーションのインターネットプロトコル（IP）アドレス、プロトコル、ポートに基づいて通過させるか停止させるかを決定します。

パケットフィルタリングは、セキュリティ要件がそれほど高くない場合に適しています。多くの組織の内部（プライベート）ネットワークは、あまりセグメント化されていません。一部の組織から他の部分を分離するために高度に洗練されたファイアウォールは必要ありません。

ただし、実験ネットワークやラボから本番ネットワークを保護するために、何らかの保護手段を講じることは賢明です。パケットフィルタリングデバイスは、一つのサブネットから別のサブネットを分離するための非常に適切な手段です。

TCP/IPプロトコルスタックのネットワーク層およびトランスポート層で動作し、すべてのパケットがプロトコルスタックに入る際に検査されます。ネットワークおよびトランスポートヘッダーは、次の情報が含まれているかを詳しく調べます：

- **プロトコル（IPヘッダー、ネットワーク層）** - IPヘッダーのバイト9（バイトカウントは0から始まる）でパケットのプロトコルが識別されます。ほとんどのフィルターデバイスは、TCP、UDP、ICMPを区別する機能があります。
- **ソースアドレス（IPヘッダー、ネットワーク層）** - ソースアドレスは、パケットを生成したホストの32ビットIPアドレスです。
- **デスティネーションアドレス（IPヘッダー、ネットワーク層）** - デスティネーションアドレスは、パケットが送信されるホストの32ビットIPアドレスです。
- **ソースポート（TCPまたはUDPヘッダー、トランスポート層）** - TCPまたはUDPネットワーク接続の各端はポートにバインドされています。TCPポートはUDPポートとは異なります。ポート番号が1024未満のものは予約されており、特定の用途が定義されています。ポート番号が1024以上（含む）のものはエフェメラルポートとして知られており、ベンダーが自由に使用できます。「Well known」ポートのリストについては、RFP1700を参照してください。ソースポートは疑似ランダムに割り当てられたエフェメラルポート番号です。そのため、ソースポートでフィルタリングすることはあまり有用ではありません。
- **デスティネーションポート（TCPまたはUDPヘッダー、トランスポート層）** - デスティネーションポート番号は、パケットが送信されるポートを示します。デスティネーションホストの各サービスはポートをリッスンしています。フィルタリングされる可能性がある一般的なポートには、20/TCPおよび21/TCP（ftp接続/データ）、23/TCP（telnet）、80/TCP（http）、53/TCP（DNSゾーントランスファー）があります。
- **接続状態（TCPヘッダー、トランスポート層）** - 接続状態は、パケットがネットワークセッションの最初のパケットであるかどうかを示します。TCPヘッダーのACKビットが「false」または0に設定されている場合、これはセッションの最初のパケットです。ACKビットが「false」または0に設定されているパケットを拒否または破棄することで、ホストが接続を確立することを防ぐのは簡単です。

有用なリソース：

- [インターネットファイアウォールの構築 - パケットフィルタリング](http://web.deu.edu.tr/static/oreily/networking/firewall/ch06_01.htm)

</details>

<details>
<summary><b>リバースプロキシサーバーを使用する利点は何ですか？</b></summary><br>

**バックエンドサーバーのトポロジーと特性を隠す**

**リバースプロキシサーバー** は、オリジンサーバーの存在と特性を隠すことができます。インターネットクラウドとWebサーバーの間に中間者として機能します。特にWebホスティングサービスを使用している場合には、セキュリティ上の理由で良い選択です。

**バックエンドサーバーの透過的なメンテナンスを許可**

リバースプロキシの背後で動作するサーバーに対して行う変更は、エンドユーザーには完全に透過的です。

**ロードバランシング**

リバースプロキシは、ラウンドロビン、ウェイテッドラウンドロビン、最小接続数、ウェイテッド最小接続数、またはランダムなどのロードバランシングアルゴリズムを強制し、クラスタ内のサーバー間で負荷を分散します。

サーバーがダウンすると、システムは自動的に次のサーバーにフェイルオーバーし、ユーザーはセキュアなファイル転送活動を続けることができます。

**SSLオフロード/終了**

HTTPS接続を処理し、リクエストを復号化して、暗号化されていないリクエストをWebサーバーに渡します。

**IPマスキング**

単一のIPを使用して、異なるURLを異なるバックエンドサーバーにルーティングします。

有用なリソース：

- [リバースプロキシの利点](https://dzone.com/articles/benefits-reverse-proxy)

</details>

<details>
<summary><b>ルーターとゲートウェイの違いは何ですか？デフォルトゲートウェイとは何ですか？</b></summary><br>

**ルーター** は、一般的な技術機能（レイヤー3のフォワーディング）やその目的のために設計されたハードウェアデバイスを説明します。一方、ゲートウェイはローカルセグメントの機能（他の場所への接続を提供）を説明します。"_ルーターをゲートウェイとして設定する_" とも言えます。別の用語として、サブネット間のフォワーディングを説明する「ホップ」があります。

**デフォルトゲートウェイ** という用語は、LAN内でのルーターで、LANの外のコンピュータへのトラフィックの最初の接点としての責任を持つルーターを意味します。

これは視点の問題であり、デバイスは同じです。

有用なリソース：

- [ルーターとゲートウェイの違い (原文)](https://networkengineering.stackexchange.com/questions/51426/difference-between-router-and-gateway)

</details>

<details>
<summary><b>次のDNSレコードの機能を説明してください：SOA、PTR、A、MX、CNAME。</b></summary><br>

**DNSレコード** は基本的にマッピングファイルで、DNSサーバーにどのIPアドレスが各ドメインに関連付けられているか、各ドメインに送信されたリクエストをどのように処理するかを伝えます。よく使用される**DNSレコード** の構文には、`A`、`AAAA`、`CNAME`、`MX`、`PTR`、`NS`、`SOA`、`SRV`、`TXT`、`NAPTR` があります。

- **SOA** - 権威の開始
- **A** - アドレスマッピングレコード
- **AAAA** - IPバージョン6アドレスレコード
- **CNAME** - 正規名レコード
- **MX** - メール交換レコード
- **NS** - ネームサーバーレコード
- **PTR** - 逆引きポインターレコード

有用なリソース：

- [DNSレコードタイプのリスト](https://en.wikipedia.org/wiki/List_of_DNS_record_types)

</details>

<details>
<summary><b>なぜMACアドレスをIPv4/6の代わりにネットワーキングに使用できないのですか？</b></summary><br>

**OSI** モデルは、ルーティング（**レイヤー3** の概念）を物理的な**レイヤー2** メカニズムに基づいて決定するのがなぜ意味がないのかを説明します。

現代のネットワーキングは、エンドツーエンドの通信を達成するために多くの異なるレイヤーに分かれています。ネットワークカード（MACアドレス - 物理アドレスでアドレスされる）は、自分の物理ネットワーク上のピアと通信することだけを担当する必要があります。

**MAC** アドレスで達成できる通信は、自分の機械と物理的に接触している他のデバイスに制限されます。例えば、インターネットでは、各マシンと物理的に接続されているわけではありません。だからこそ、物理的に接続されていないマシンと通信する必要があるときには、**TCP/IP**（**レイヤー3** の論理アドレス）メカニズムを使用します。

**IP** は、コンピュータのグループに階層的に課された任意の番号付けスキームで、グループとして論理的に区別します（これがサブネットです）。これらのグループ間でメッセージを送信するのは、ルーティングテーブルを使用し、それ自体が複数のレベルに分かれているため、すべてのサブネットを追跡する必要がありません。

これを別のペアのシステムに関連付けるのは簡単です。あなたには州発行のID番号がありますが、そのID番号がすでにあなたに固有であるなら、なぜ郵送先住所が必要でしょうか？郵送先住所が必要なのは、唯一の通信先がどこにあるかを説明するための任意のシステムだからです。

一方、ネットワーク全体にわたる**MAC** アドレスの配布はランダムで、トポロジーとは完全に無関係です。ルートグルーピングは不可能で、すべてのルーターが通過するトラフィックのためにすべてのデバイスのルートを追跡する必要があります。これが**レイヤー2** スイッチの役割で、一定のホスト数を超えるとスケールしません。

有用なリソース：

- [なぜMACアドレスをIPv4|6の代わりにネットワーキングに使用できないのか？ (原文)](https://serverfault.com/questions/410626/why-couldnt-mac-addresses-be-used-instead-of-ipv46-for-networking)

</details>

<details>
<summary><b>最大30デバイスを含むネットワークに適用できる最小のIPv4サブネットマスクは何ですか？</b></summary><br>

標準の `/24` VLANをエンドユーザー用に使用するか、`/30` をポイントツーポイントリンク用に使用するか、またはその間のサブネットが最大30デバイスを含む必要がある場合、`/27`（またはサブネットマスク `255.255.255.224`）が適切です。

有用なリソース：

- [プレフィックス、ネットワーク、サブネット、ホスト番号をどのように計算しますか？](https://networkengineering.stackexchange.com/questions/7106/how-do-you-calculate-the-prefix-network-subnet-and-host-numbers)
- [IPアドレスの後のスラッシュ - CIDR表記](https://networkengineering.stackexchange.com/questions/3697/the-slash-after-an-ip-address-cidr-notation)
- [なぜ3つのプライベートIPv4アドレス範囲があるのか？](https://networkengineering.stackexchange.com/questions/32119/why-are-there-3-ranges-of-private-ipv4-addresses)
- [IP計算機](http://jodies.de/ipcalc)

</details>

<details>
<summary><b>一般的なHTTPステータスコードにはどのようなものがありますか？</b></summary><br>

- **1xx** - 情報レスポンス - 転送プロトコルレベルの情報を伝えます
- **2xx** - 成功 - クライアントのリクエストが正常に受け入れられたことを示します
- **3xx** - リダイレクション - クライアントがリクエストを完了するために追加のアクションを取る必要があることを示します
- **4xx** - クライアント側のエラー - このカテゴリのエラー状態コードは、クライアントに問題があることを示します
- **5xx** - サーバー側のエラー - サーバーがこれらのエラー状態コードの責任を負います

有用なリソース：

- [HTTPステータスコード](https://httpstatuses.com/)

</details>

###### Devops Questions (5)

<details>
<summary><b>DevOpsとは何ですか？DevOpsコミュニティの成功において、コミュニケーションの取り方とツールの選択のどちらが重要ですか？***</b></summary><br>

**DevOps** とは、開発と運用のタスクを両方行う統合チームのことを指します。または、非常に密接に協力して働く個々の運用チームと開発チームのことを指します。これは、共通の目標を達成するために他の部門と協力して作業する「方法」に近いです。

</details>

<details>
<summary><b>バージョン管理とは何ですか？あなたのコミットメッセージは見栄えが良いですか？</b></summary><br>

バージョン管理とは、ファイルまたはファイルのセットに対する変更を時間とともに記録するシステムであり、後で特定のバージョンを再呼び出すことができます。バージョン管理システムは、チームメイトがファイルやファイルのセットに変更をコミットできる中央共有リポジトリで構成されます。その後、バージョン管理の使用方法について説明します。

バージョン管理により、以下のことが可能になります：

- ファイルを以前の状態に戻す
- プロジェクト全体を以前の状態に戻す
- 時間の経過に伴う変更を比較する
- 問題を引き起こしている可能性のあるものを最後に修正した人を見る
- 課題を導入した人とその時期を見る

優れたコミットメッセージの七つのルール：

- 本文とタイトルを空行で区切る
- タイトル行を50文字以内に制限する
- タイトル行を大文字にする
- タイトル行をピリオドで終わらせない
- タイトル行で命令形を使用する
- 本文は72文字で折り返す
- 本文を使って「何を」「なぜ」説明し、「どうやって」は避ける

有用なリソース：

- [はじめに - バージョン管理について (原文)](https://git-scm.com/book/en/v2/Getting-Started-About-Version-Control)

</details>

<details>
<summary><b>基本的な <code>git</code> コマンドを説明してください。</b></summary><br>

- `git init` - 新しいローカルリポジトリを作成する
- `git commit -m "message"` - 変更をヘッドにコミットする
- `git status` - `git add` で追加したファイルと、それ以降に変更したファイルをリスト表示する
- `git push origin master` - リモートリポジトリのマスターブランチに変更を送信する

</details>

<details>
<summary><b>簡単な継続的インテグレーションパイプラインを説明してください。</b></summary><br>

- リポジトリをクローンする
- デプロイステージ（QA）
- テスト環境（QA）
- デプロイステージ（PROD）

</details>

<details>
<summary><b>基本的な <code>docker</code> コマンドを説明してください。</b></summary><br>

- `docker ps` - 実行中のコンテナを表示する
- `docker ps -a` - すべてのコンテナを表示する
- `docker images` - Dockerイメージを表示する
- `docker logs <container-id|container-name>` - コンテナからログを取得する
- `docker network ls` - すべてのDockerネットワークを表示する
- `docker volumes ls` - すべてのDockerボリュームを表示する
- `docker exec -it <container-id|container-name> bash` - インタラクティブシェルでコンテナ内でbashを実行する

</details>

###### Cyber Security Questions (1)

<details>
<summary><b>セキュリティの誤設定とは何ですか？</b></summary><br>

**セキュリティの誤設定** とは、デバイス、アプリケーション、ネットワークが攻撃者によって悪用される可能性がある方法で構成されている脆弱性です。例えば、デフォルトのユーザー名やパスワードが変更されていない、またはデバイスアカウントのパスワードが簡単すぎるなどのケースが考えられます。

</details>

### :diamond_shape_with_a_dot_inside: <a name="regular-sysadmin">一般的なシステム管理者</a>

###### System Questions (60)

<details>
<summary><b>本番環境での経験について教えてください。***</b></summary><br>

未完了です。

</details>

<details>
<summary><b>主要なウェブサーバーを運用するためにどのディストリビューションを選びますか？***</b></summary><br>

未完了です。

</details>

<details>
<summary><b>Linuxシステムのブートプロセスをいくつかのポイントで説明してください。</b></summary><br>

**BIOS**: BIOSのフルフォームは「Basic Input or Output System」で、整合性チェックを実行し、ブートローダーを検索してロードし、その後実行します。

**ブートローダー**: 初期段階はオペレーティングシステムに特有のものではないため、x86およびx86-64アーキテクチャのBIOSベースのブートプロセスは、マスターブートレコード（MBR）コードがリアルモードで実行され、第一段階のブートローダーがロードされると始まります。UEFIシステムでは、Linuxカーネルなどのペイロードが直接実行されることがあります。そのため、ブートローダーは必要ありません。一般的なブートローダーには、**GRUB**、**Syslinux/Isolinux**、または**Lilo**があります。

**カーネル**: Linuxのカーネルは、メモリ管理、タスクスケジューリング、I/O、プロセス間通信、システム全体の制御など、すべてのオペレーティングシステムのプロセスを処理します。これは2段階でロードされます。最初の段階では、カーネル（圧縮されたイメージファイル）がメモリにロードされ、解凍され、基本的なメモリ管理などのいくつかの基本的な機能が設定されます。

**Init**: システム上のすべてのプロセスの親であり、カーネルによって実行され、他のすべてのプロセスを起動する責任があります。

- `SysV init` - initの役割は「カーネルが完全に動作するようになると、すべてが正しく動作するようにすること」です。基本的には、ユーザー空間全体を確立し運営します。これには、ファイルシステムのチェックとマウント、必要なユーザーサービスの起動、そしてシステム起動が完了した後にユーザー環境に切り替えることが含まれます。
- `systemd` - systemdの開発者は、Unix System Vから受け継いだLinux initシステムを置き換えることを目指しました。initと同様に、systemdも他のデーモンを管理するデーモンです。すべてのデーモン（systemdを含む）はバックグラウンドプロセスです。systemdは最初に起動し（ブート時）、最後に終了します（シャットダウン時）。
- `runinit` - runinitは、Unixライクなオペレーティングシステムのためのinitスキームで、オペレーティングシステム全体でプロセスを初期化、監視、終了させます。これは、Linux、Mac OS X、*BSD、およびSolarisオペレーティングシステムで実行されるdaemontoolsプロセス監視ツールキットの再実装です。

役立つリソース:

- [Linuxブートプロセスの分析](https://opensource.com/article/18/1/analyzing-linux-boot-process)
- [Linuxにおけるsystemdブートプロセスの詳細](https://linoxide.com/linux-how-to/systemd-boot-process/)

</details>

<details>
<summary><b>Linuxデーモンが権限を下げる方法と理由は何ですか？なぜ一部のデーモンは起動するためにroot権限が必要なのですか？説明してください。***</b></summary>

未完了です。

</details>

<details>
<summary><b>なぜシングルコアマシンでの1.00のロードは理想的ではないのですか？</b></summary><br>

1.00のロードの問題は、余裕がないことです。実際には、多くのシステム管理者は0.70を超えた場合に線を引きます。

「調べる必要がある」ルールオブサム: 0.70 ロードアベレージが0.70を超えている場合は、事態が悪化する前に調査する時期です。

「今すぐ修正する」ルールオブサム: 1.00 ロードアベレージが1.00を超えた場合は、問題を見つけて今すぐ修正してください。さもないと、夜中に起こされることになり、それは楽しいことではありません。

ルールオブサム: 5.0 ロードアベレージが5.00を超えると、深刻な問題に直面している可能性があり、マシンがハングするか、非常に遅くなる可能性があります。そして、これが最悪のタイミングで発生します。例えば夜中やカンファレンスでプレゼンをしているときなどです。そこまで行かせないようにしましょう。

役立つリソース:

- [4コア8スレッドプロセッサのシステムロードの正しい解釈方法](https://serverfault.com/questions/618130/proper-way-of-interpreting-system-load-on-a-4-core-8-thread-processor)
- [Linux CPUロードの理解 - いつ心配すべきか？](http://blog.scoutapp.com/articles/2009/07/31/understanding-load-averages)

</details>

<details>
<summary><b>実効ユーザーがrootで、実際のユーザーIDがまだあなたの名前である場合、何を意味しますか？</b></summary><br>

**実際のユーザーID**はあなた自身（プロセスを所有するユーザー）であり、**実効ユーザーID**はオペレーティングシステムがあなたが何かをする権限があるかどうかを決定するために見るものです（通常はそうですが、例外もあります）。

ログインすると、ログインシェルは**実際のユーザーID**と**実効ユーザーID**の両方をパスワードファイルにより提供された同じ値（あなたの**実際のユーザーID**）に設定します。

例えば、setuidを実行し、別のユーザー（例: **root**）として実行する場合、setuidプログラムはあなたの代わりに何かを実行することが想定されています。

setuidを実行した後、そのプロセスはあなたの**実際のID**（プロセスの所有者として）を持ち、ファイル所有者の実効ユーザーID（例えば**root**）を持ちます。これはsetuidによるものです。

`passwd`のケースを考えてみましょう:

```bash
-rwsr-xr-x 1 root root 45396 may 25  2012 /usr/bin/passwd
```

ユーザー2が自分のパスワードを変更したい場合、`/usr/bin/passwd`を実行します。

この場合、**RUID**はユーザー2ですが、そのプロセスの**EUID**はrootになります。

ユーザー2は自分のパスワードを変更するためにのみpasswdを使用できます。なぜなら、内部的にpasswdは**RUID**をチェックし、それがrootでない場合、アクションは実際のユーザーのパスワードに限定されるからです。

passwdのプロセスが`/etc/passwd`および/または`/etc/shadow`に書き込む必要があるため、**EUID**がrootである必要があります。

役立つリソース:

- [Real User ID、Effective User ID、およびSaved User IDの違いは何ですか？（原文）](https://stackoverflow.com/questions/30493424/what-is-the-difference-between-a-process-pid-ppid-uid-euid-gid-and-egid)
- [pid、ppid、uid、euid、gid、egidの違いは何ですか？](https://stackoverflow.com/questions/30493424/what-is-the-difference-between-a-process-pid-ppid-uid-euid-gid-and-egid)

</details>

<details>
<summary><b>開発者が大量のログファイルを生成するcronジョブを追加しました。それらが非常に大きくなるのを防ぐにはどうすればよいですか？</b></summary><br>

ログファイルを扱う一般的な方法は`logrotate`を使用することです。しかし、`/etc/logrotate.conf`に内容を追加する代わりに、`/etc/logrotate.d/`に自分のジョブを追加するべきです。そうしないと、リリースアップグレード時に設定ファイルの差分をより多く確認する必要があります。

ファイルがアクティブに書き込まれている場合、トランケート（切り捨て）による対処はあまりできません。唯一の選択肢は、ファイルをトランケートすることです：

```bash
: >/var/log/massive-logfile
```

これは、プロセスを中断することなくファイルをトランケートできるため、とても役立ちます。

役立つリソース:

- [ログファイルを管理するためのlogrotateの使用方法](https://www.linode.com/docs/uptime/logs/use-logrotate-to-manage-log-files/)
- [システムログ](https://www.ibm.com/developerworks/library/l-lpic1-108-2/index.html)

</details>

<details>
<summary><b>Linuxカーネルはシステム内でプロセスをどのように作成、管理、削除しますか？ ***</b></summary><br>

未完了です。

役立つリソース:

- [Linuxプロセス](https://www.tldp.org/LDP/tlk/kernel/processes.html)

</details>

<details>
<summary><b><code>top</code>や<code>htop</code>で見ることができる選択した情報を説明してください。これらのツールを使ってロード、高いユーザー時間、メモリ不足の問題を診断する方法は？ ***</b></summary><br>

未完了です。

役立つリソース:

- [topを視覚的に説明](https://www.svennd.be/top-explained-visually/)
- [htopを視覚的に説明](https://codeahoy.com/2017/01/20/hhtop-explained-visually/)
- [Linuxにおけるhtop/topのすべての情報の説明](https://peteris.rocks/blog/htop/)

</details>

<details>
<summary><b>リソースを大量に消費しているプロセスをどのように認識しますか？</b></summary><br>

`top`は、正しい数字を見ていればかなり効果的です。
- **M** 現在の常駐メモリ使用量でソート
- **T** 総CPU使用量（または累積CPU使用量）でソート
- **P** 現在のCPU使用量でソート（これがデフォルトのリフレッシュです）
- **?** すべてのtopコマンドの使用概要を表示

これは、コンピュータプロセスが遅く動作している理由を解決し、どのプロセスを終了させるか、またはソフトウェアをアンインストールするかを決定する際に非常に重要な情報です。

役立つリソース:

- [マシンのリソースを大量に消費しているプロセスを見つける方法](https://superuser.com/questions/326300/how-to-find-the-processes-which-are-hogging-the-machine)

</details>

<details>
<summary><b><code>ntpd</code>サービスを200台のサーバーでアップグレードする必要があります。これらすべてを最新にするための最良の方法は何ですか？</b></summary><br>

**Infrastructure as Code**アプローチを使用することで、複数の良い方法があります：

1. **設定同期変更管理モデル**：

Ansible、Chef、Puppet、Saltstackなどの設定管理ツールを使用して、すべてのサーバーで`ntpd`サービスを自動的に更新できます。システムの安定性を保つために、サーバー上のシステムパッケージは通常、セキュリティ更新のみが自動的に行われます。パッケージのメジャーまたはマイナーなバージョンは、サービスの誤設定を防ぐために通常、設定定義でバージョンがロックされています。そのため、`ntpd`のバージョンを設定定義で変更することで、変更が展開されます。

このアプローチでは、大規模にインフラストラクチャに変更を展開する際に注意が必要です。展開のパイプラインには、ユニットテスト、統合テスト、システムテストが含まれ、最初にステージング環境に展開して設定を確認する必要があります。テストで設定の正確性が確認された場合は、エラーや失敗の際にロールバック可能なインクリメンタルローアウトで展開を行います。

2. **イミュータブルサーバーモデル**：

イミュータブルサーバーモデルでは、実行中のサーバーに変更を加える代わりに、新しい更新済みイメージで全体のユニット（サーバー、コンテナ）を置き換えます（これにより設定のドリフトが排除されます）。このアプローチでは、通常、PackerやDockerといったツールを使ってサーバーイメージを作成します。このイメージはテストされ、上記のオプション（1.）と同様に展開されますが、Canary Releaseなどの技術を使用して、インクリメンタルローアウトとロールバックが可能です。

役立つリソース:

- [Infrastructure as Code - 第8章: サーバーの更新と変更のパターン](http://shop.oreilly.com/product/0636920039297.do)

</details>

<details>
<summary><b><code>$PATH</code>をLinux/Unixで永続的に設定する方法は？この変数はなぜ重要なのですか？ ***</b></summary>

未完了です。

</details>

<details>
<summary><b>サーバーが起動する際にコンソールにエラーが表示されます。ブートメッセージを調べる方法と、それらがどこに保存されているかは？</b></summary><br>

コンソールには2種類のメッセージがあります：

- **カーネルによって生成されたもの**（`printk`を通じて）
- **ユーザー空間によって生成されたもの**（通常はinitシステム）

カーネルメッセージは常に**kmsg**バッファに保存され、`dmesg`コマンドで表示できます。また、しばしば**syslog**にもコピーされます。これは、`/dev/kmsg`に書き込まれるユーザー空間のメッセージにも適用されますが、これらは比較的まれです。

一方で、ユーザー空間が`/dev/console`や`/dev/tty1`に fancyなブートステータステキストを書き込むと、それはどこにも保存されません。単に画面に表示されるだけです。

`dmesg`はカーネルリングバッファに含まれるブートメッセージを確認するために使用されます。リングバッファは固定サイズのバッファで、新しいデータが追加されると古いデータが上書きされます。

ブートプロセスが完了すると、カーネルに渡されたコマンドラインオプション、検出されたハードウェアコンポーネント、新しいUSBデバイスが追加されたイベント、NIC（ネットワークインターフェースカード）障害やネットワーク上でリンクアクティビティが検出されないなどのエラーが表示されます。

システムログがジャーナルコンポーネントを介して行われている場合は、`journalctl`を使用するべきです。これにはカーネルメッセージやブートメッセージ、syslogやさまざまなサービスからのメッセージが含まれます。

ブートの問題やエラーには、システム管理者が特定の重要なファイルとコマンド（Linuxの異なるバージョンで異なる方法で扱われます）を確認する必要があります：

- `/var/log/boot.log` - システムブートログで、システムブート中に展開されたすべての内容が含まれています。
- `/var/log/messages` - システムブート中にログされたメッセージを含むグローバルなシステムメッセージを保存します。
- `/var/log/dmesg` - カーネルリングバッファの情報を含みます。

役立つリソース:

- [Linuxブート後のすべてのブートメッセージを表示する方法（原文）](https://superuser.com/questions/1188407/how-to-view-all-boot-messages-in-linux-after-booting)
- [/var/log/{syslog,dmesg,messages}ログファイルの違い](https://superuser.com/questions/565927/differences-in-var-log-syslog-dmesg-messages-log-files)
- [Debianシステムをブートするときにスクロールするメッセージを後で確認する方法は？](https://serverfault.com/questions/516411/all-debian-boot-messages)

</details>

<details>
<summary><b>スワップ使用量が高すぎる。これにはどのような理由があり、スワッピングの問題を解決するにはどうすればよいですか？</b></summary><br>

**スワップ**領域は、利用可能なメモリが完全に使用されたときにオペレーティングシステムによって使用される制限された物理メモリの量です。これは、メモリのセクションを物理ストレージにスワップするメモリ管理です。

システムがより多くのメモリリソースを必要とし、RAMが満杯の場合、メモリ内の非アクティブなページがスワップ領域に移動されます。スワップ領域はRAMが少ないマシンに役立ちますが、より多くのRAMの代わりとして考えるべきではありません。**スワップ**領域はハードドライブに存在し、物理メモリよりもアクセス時間が遅いです。

ワークロードがRAMの需要を増加させます。より多くのメモリを必要とするワークロードを実行しています。全スワップ使用量はそれを示しています。また、`swappiness`を**1**に変更するのは賢明な決定ではないかもしれません。`swappiness`を**1**に設定しても、スワッピングが行われないわけではありません。それはカーネルがスワッピングに対してどれほど攻撃的になるかを示すだけで、スワッピングを排除するわけではありません。必要があればスワッピングは行われます。

- **スワップ領域のサイズを増やす** - まず、ディスクの使用量が増加します。ディスクが十分に速くない場合、システムがスラッシングを起こす可能性があり、メモリ内のデータがスワップインおよびスワップアウトされる際に遅延を経験するでしょう。これがボトルネックを引き起こします。

- **RAMを追加する** - 真の解決策はメモリを追加することです。RAMの代替はありません。十分なメモリがあれば、スワップは少なくなります。

スワップ領域の使用状況を監視するためには：

- `cat /proc/swaps` - 総スワップサイズと使用量を確認する
- `grep SwapTotal /proc/meminfo` - 総スワップ領域を表示する
- `free` - システムメモリの使用可能量と使用量を表示する（スワップも含む）
- `vmstat` - スワッピング統計を確認する
- `top`, `htop` - スワップ領域の使用状況を確認する
- `atop` - システムがメモリを過剰にコミットしているかどうかを示す
- または、スワップ領域を使用しているアプリケーションをキロバイト単位でリストするワンライナーシェルコマンドを使用する：
```bash
for _fd in /proc/*/status ; do
  awk '/VmSwap|Name/{printf $2 " " $3}END{ print ""}' $_fd
done | sort -k 2 -n -r | less
```

役立つリソース:

- [Linuxは私のRAMを食べました！](https://www.linuxatemyram.com/)
- [Linuxでどのプロセスがスワップ領域を使用しているかを確認する方法](https://stackoverflow.com/questions/479953/how-to-find-out-which-processes-are-using-swap-space-in-linux)
- [Linuxでスワップ領域の使用状況を監視するための8つの有用なコマンド](https://www.tecmint.com/commands-to-monitor-swap-space-usage-in-linux/)
- [Ubuntuサーバーでスワップが完全に使用されている場合の危険性は？](https://serverfault.com/questions/499301/what-is-the-danger-in-having-a-fully-used-swap-in-an-ubuntu-server)
- [無料のRAMがある場合にスワップを空にする方法](https://askubuntu.com/questions/1357/how-to-empty-swap-if-there-is-free-ram)

</details>

<details>
<summary><b>umaskとは何ですか？ユーザーのために永続的に設定するにはどうすればよいですか？</b></summary><br>

Linuxやその他のUnix系オペレーティングシステムでは、新しいファイルがデフォルトのパーミッションセットで作成されます。具体的には、新しいファイルのパーミッションは、`umask`というパーミッション「マスク」を適用することで特定の方法で制限されることがあります。`umask`コマンドは、このマスクを設定するために使用されるか、現在の値を表示するために使用されます。

永続的に変更するには（例: `umask 02`）:

- `~/.profile`
- `~/.bashrc`
- `~/.zshrc`
- `~/.cshrc`

役立つリソース:

- [Umaskとは何か、およびLinuxでのデフォルトumaskの設定方法](https://www.cyberciti.biz/tips/understanding-linux-unix-umask-value-usage.html)

</details>

<details>
<summary><b>以下のumask値の違いを説明してください: 000, 002, 022, 027, 077, および 277。</b></summary><br>

<table style="width:100%">
  <tr>
    <th>Umask</th>
    <th>ファイルの結果</th>
    <th>ディレクトリの結果</th>
  </tr>
  <tr>
    <td>000</td>
    <td>666 rw- rw- rw-</td>
    <td>777 rwx rwx rwx</td>
  </tr>
 <tr>
    <td>002</td>
    <td>664 rw- rw- r--</td>
    <td>775 rwx rwx r-x</td>
  </tr>
  <tr>
    <td>022</td>
    <td>644 rw- r-- r--</td>
    <td>755 rwx r-x r-x</td>
  </tr>
<tr>
    <td>027</td>
    <td>640 rw- r-- ---</td>
    <td>750 rwx r-x ---</td>
  </tr>
<tr>
    <td>077</td>
    <td>600 rw---- ---</td>
    <td>700 rwx --- ---</td>
  </tr>
<tr>
    <td>277</td>
    <td>400 r-- --- ---</td>
    <td>500 r-x --- ---</td>
  </tr>
</table>

役立つリソース:

- [Umaskとは何か、およびLinuxでのデフォルトumaskの設定方法](https://www.cyberciti.biz/tips/understanding-linux-unix-umask-value-usage.html)

</details>

<details>
<summary><b>シンボリックリンクとハードリンクの違いは何ですか？</b></summary><br>

ファイルシステムの下では、ファイルはinodeによって表されます（複数のinodeかもしれませんが、確かではありません）。

- ファイルシステム内のファイルは基本的にinodeへのリンクです。
- ハードリンクは、同じ基盤となるinodeへのリンクを持つ別のファイルを作成します。

ファイルを削除すると、基盤となるinodeへのリンクの1つが削除されます。inodeは、すべてのリンクが削除されるまで削除（または削除可能/上書き可能）されません。

- シンボリックリンクは、ファイルシステム内の別の名前へのリンクです。

ハードリンクが作成されると、そのリンクはinodeに対するものです。元のファイルを削除、名前変更、または移動しても、ハードリンクには影響しません。ハードリンクは基盤となるinodeにリンクしているためです。inode上のデータに対する変更は、そのinodeを参照するすべてのファイルに反映されます。

注意: ハードリンクは同じファイルシステム内でのみ有効です。シンボリックリンクは、ファイルシステムを跨ることができるため、単に別のファイルの名前です。

違い:

- **ハードリンク**はディレクトリに対して作成することはできません。ハードリンクはファイルに対してのみ作成できます。
- **ソフトリンク**（シンボリックリンクまたはsymlinkとも呼ばれる）はディレクトリにリンクすることができます。

役立つリソース:

- [ハードリンクとシンボリックリンクの違いは何ですか？](https://medium.com/@wendymayorgasegura/what-is-the-difference-between-a-hard-link-and-a-symbolic-link-8c0493041b62)

</details>

<details>
<summary><b>スティッキービット（sticky bit）はどのように機能しますか？<code>SUID/GUID</code>と同じですか？</b></summary><br>

これは多くの人がしばしば混乱する非常に厄介な問題の1つです。**SUID/GUID**ビットと**スティッキービット**は全く異なるものです。

`man chmod` を実行すれば、**SUID**と**スティッキービット**についての説明を読むことができます。

**SUID/GUID**

上記のマニュアルページが言おうとしているのは、xビットが rwxrwxrwx のユーザーオクタル（最初のrwグループ）およびグループオクタル（2番目のrwグループ）で占める位置が、xがsになる追加の状態を取ることができるということです。これが発生すると、ファイルが実行されると（プログラムであり、単なるシェルスクリプトではない場合）、ファイルの所有者またはグループの権限で実行されます。

したがって、ファイルがrootによって所有されていて、**SUID**ビットがオンになっていると、プログラムはrootとして実行されます。たとえ通常のユーザーとして実行してもです。同様のことが**GUID**ビットにも当てはまります。

例:

**SUID/GUIDなし** - ビット `rwxr-xr-x` が設定されています。

```bash
ls -lt b.pl
-rwxr-xr-x 1 root root 179 Jan  9 01:01 b.pl
```

**SUID & ユーザーの実行ビットが有効（小文字のs）** - ビット `rwsr-xr-x` が設定されています。

```bash
chmod u+s b.pl
ls -lt b.pl
-rwsr-xr-x 1 root root 179 Jan  9 01:01 b.pl
```

**SUID有効 & 実行ビット無効（大文字のS）** - ビット `rwSr-xr-x` が設定されています。

```bash
chmod u-x b.pl
ls -lt b.pl
-rwSr-xr-x 1 root root 179 Jan  9 01:01 b.pl
```

**GUID & グループの実行ビットが有効（小文字のs）** - ビット `rwxr-sr-x` が設定されています。

```bash
chmod g+s b.pl
ls -lt b.pl
-rwxr-sr-x 1 root root 179 Jan  9 01:01 b.pl
```

**GUID有効 & 実行ビット無効（大文字のS）** - ビット `rwxr-Sr-x` が設定されています。

```bash
chmod g-x b.pl
ls -lt b.pl
-rwxr-Sr-x 1 root root 179 Jan  9 01:01 b.pl
```

**スティッキービット**

一方、スティッキービットは `t` で示されます。たとえば `/tmp` ディレクトリで:

```bash
ls -l /|grep tmp
drwxrwxrwt. 168 root root 28672 Jun 14 08:36 tmp
```

このビットは、実際には「制限付き削除ビット」と呼ばれるべきです。スティッキービットが有効になっていると、ユーザーは自分が所有するファイルおよびディレクトリのみを削除できるようになります。

役立つリソース:

- [スティッキービットはどのように機能しますか？（原文）](https://unix.stackexchange.com/questions/79395/how-does-the-sticky-bit-work)

</details>

<details>
<summary><b><code>LC_ALL=C</code> をコマンドの前に置くと何が起こりますか？どのような場合に有用ですか？</b></summary><br>

`LC_ALL` は、他のローカリゼーション設定を上書きする環境変数です。これにより、すべての `LC_` タイプの変数が一度に指定されたロケールに設定されます。

コマンドの前に `LC_ALL=C` を設定する主な理由は、単純に英語の出力を得るためです（コマンドによって使用されるロケールを一般的に変更します）。

一方で、`LC_ALL=C` を使用することでコマンドの実行速度が向上することも重要です。例えば、`grep` や `fgrep` でのパフォーマンスが向上し、コマンドの実行時間が短縮されました。

例えば、`LC_ALL=en_US.utf8` を設定すると、システムは `/usr/lib/locale` ディレクトリから複数のファイルを開きます。しかし、`LC_ALL=C` では最小限のオープンおよび読み取り操作が行われます。

セッションのためにすべての通常の（元の）ロケール設定を復元したい場合は、次のようにします：

```bash
LC_ALL=
```

`LC_ALL` が機能しない場合は、`LANG` を試してみてください（それでも機能しない場合は `LANGUAGE` を試してみてください）：

```bash
LANG=C date +%A
Monday
```

役立つリソース:

- [LC_ALL=C は何をするのか？（原文）](https://unix.stackexchange.com/questions/87745/what-does-lc-all-c-do)
- [LC_ALL=C で grep 検索を高速化する](https://www.inmotionhosting.com/support/website/ssh/speed-up-grep-searches-with-lc-all)

</details>

<details>
<summary><b>ウェブアプリケーションの高可用性を実現するにはどうすればよいですか？ ***</b></summary>

完了予定です。

</details>

<details>
<summary><b>新しいサーバーを設定しています。手順の一つとしてアプリケーションディレクトリの権限設定があります。どのような手順を踏み、どのようなミスを避けるべきですか？</b></summary><br>

**1) 主な要件 - これを覚えておくこと**

- アプリケーションファイルシステムへのアクセス権を持つユーザー
- ウェブサーバー（例：Apache）やアプリサーバー（例：uwsgi）のための権限
- **uploads**、**cache**、および主なアプリディレクトリ（例：`/var/www/app01/html`）のような特定のディレクトリの権限
- ユーザーおよび **suid**/**sgid**（特定の状況のみ）のための正しい `umask` 値
- 将来のファイルおよびディレクトリの権限
- cronジョブおよびスクリプトのための権限

**2) アプリケーションディレクトリ**

`/var/www` には各ウェブサイトのディレクトリが含まれています（アプリの隔離）、例：`/var/www/app01`、`/var/www/app02`

```bash
mkdir /var/www/{app01,app02}
```

**3) アプリケーションの所有者とグループ**

各アプリケーションには、**所有者**（例：**u01-prod**、**u02-prod**）と**グループ**（例：**g01-prod**、**g02-prod**）が指定されており、これらがウェブサイトのディレクトリ内のすべてのファイルとディレクトリの所有者として設定されています。

```bash
chown -R u01-prod:g01-prod /var/www/app01
chown -R u02-prod:g02-prod /var/www/app02
```

**4) 開発者の所有者とグループ**

ウェブサイトを管理するすべてのユーザーは、自分のグループを持っており、それらはアプリケーショングループに関連付けられています：

```bash
id alice
uid=2000(alice) gid=4000(alice) groups=8000(g01-prod)
id bob
uid=2001(bob) gid=4001(bob) groups=8000(g01-prod),8001(g02-prod)
```

例えば、**alice** ユーザーは `/var/www/app01` に対する標準的な権限を持ち、**bob** ユーザーは `/var/www/app01` および `/var/www/app02` に対する標準的な権限を持っています。

**5) ウェブサーバーの所有者とグループ**

ウェブサーバーによって書き込む必要があるファイルやディレクトリには、適切な所有者が設定されています。ウェブサーバーが Apache の場合、デフォルトの所有者/グループは **apache:apache** または **www-data:www-data** であり、Nginx の場合は **nginx:nginx** です。これらの設定は変更しないでください。

アプリケーションが **uwsgi** や **php-fpm** のようなアプリサーバーと連携している場合は、特定の設定ファイルで適切なユーザーとグループ（例：**app01** の場合は **u01-prod:g01-prod**）を設定する必要があります。

**6) 権限**

**アクセス制御リスト**を使用して権限を適切に設定します：

```bash
# For web server
setfacl -Rdm "g:apache:rwx" /var/www/app01
setfacl -Rm "g:apache:rwx" /var/www/app01

# For developers
setfacl -Rdm "g:g01-prod:rwx" /var/www/app01
setfacl -Rm "g:g01-prod:rwx" /var/www/app01
```

**SELinux** を使用する場合は、セキュリティコンテキストについても考慮してください：

```bash
chcon -R system_u:object_r:httpd_sys_content_t /var/www/app01
```

**7) セキュリティの誤り**

- **root** がファイルやディレクトリの所有者である
- **root** はウェブサイトのディレクトリ内のファイルを実行せず、そこにファイルを作成すべきではない
- **777** のような広すぎる権限設定により、重要なファイルが世界中の誰でも書き込みおよび読み取り可能になる
- suid root を持つメンテナンススクリプトやその他の重要なファイルの作成を避ける

サイトのコードを構成するファイルを修正できるようにすると、誰かがサーバーを乗っ取るのを非常に簡単にしてしまいます。

ファイルアップロードツールにより、ユーザーは任意の名前と内容のファイルをアップロードできます。これにより、ユーザーはメールリレーPHPスクリプトをサイトにアップロードし、それを任意の場所に配置してサーバーを商用メールの中継機にすることができます。このスクリプトは、データベースからすべてのメールアドレスやその他の個人情報を読み取るためにも使用される可能性があります。

もし悪意のあるユーザーが任意の名前でファイルをアップロードできるが、内容を制御できない場合、`index.php`（または他の重要なファイル）を上書きするファイルを簡単にアップロードし、サイトを壊す可能性があります。

有用なリソース：

- [LinuxのWWWフォルダの権限を設定する方法](https://serverfault.com/questions/124800/how-to-setup-linux-permissions-for-the-www-folder)
- [Linuxウェブサーバーでのウェブサイトファイル/フォルダーに必要な権限は何ですか？](https://serverfault.com/questions/357108/what-permissions-should-my-website-files-folders-have-on-a-linux-webserver)
- [setgidプログラムのセキュリティの落とし穴](https://www.agwa.name/blog/post/security_pitfalls_of_setgid_programs)

</details>

<details>
<summary><b>`telinit 3`から`telinit 1`を実行すると、initはどのような手順を踏みますか？最終的にどのような結果になりますか？`reboot`コマンドの代わりに`telinit 6`を使用するとサーバーは再起動しますか？***</b></summary><br>

未完了です。

有用なリソース：

- [コンピュータを再起動するために「telinit 6」を使用した場合と「reboot」コマンドを使用した場合の違いは何ですか？](https://unix.stackexchange.com/questions/434560/what-differences-it-will-make-if-i-use-telinit-6-instead-of-reboot-command)

</details>

<details>
<summary><b>rootパスワードを忘れてしまいました！BSDでどうすればいいですか？シングルユーザーモードで起動する目的は何ですか？</b></summary><br>

システムを再起動し、`Boot:`プロンプトで`boot -s`と入力して**シングルユーザーモード**に入ります。

使用するシェルを尋ねられたら、`Enter`キーを押して`#`プロンプトを表示します。

`mount -urw /`と入力してルートファイルシステムを読み書きモードで再マウントし、次に`mount -a`を実行してすべてのファイルシステムを再マウントします。

`passwd root`を実行してrootパスワードを変更し、`exit`を実行してブートを続行します。

**シングルユーザーモード**では、基本的にrootアクセスでログインし、ほぼすべての設定を変更できるようになります。例えば、破損したマスターデータベースやシステムデータベースの修復、サーバー設定オプションの変更（例：パスワードリカバリー）などの際にシングルユーザーモードを使用します。

有用なリソース：

- [FreeBSDでのrootパスワードのリセットまたは回復](https://www.cyberciti.biz/tips/howto-freebsd-reset-recover-root-password.html)
- [シングルユーザーモードの定義](http://www.linfo.org/single_user_mode.html)

</details>

<details>
<summary><b>テキストエディタを使用せずにテキストファイルを修正するにはどうすればよいですか？</b></summary><br>

例:<br>

```bash
# cat  >filename ... - overwrite file
# cat >>filename ... - append to file
cat > filename << __EOF__
data
__EOF__
```

</details>

<details>
<summary><b>カーネルパラメータを変更するにはどうすればよいですか？調整が必要なカーネルオプションにはどのようなものがありますか？***</b></summary><br>

Unix系システムでカーネルパラメータを設定するには、まず`/etc/sysctl.conf`ファイルを編集します。変更を保存した後、`sysctl -p`コマンドを実行すると、再起動せずに変更が永続的に適用されます。

有用なリソース：

- [カーネルランタイムパラメータを永続的かつ非永続的に変更する方法](https://www.tecmint.com/change-modify-linux-kernel-runtime-parameters/)

</details>

<details>
<summary><b>`/proc`ファイルシステムについて説明してください。</b></summary><br>

`/proc`は、カーネル、ハードウェア、実行中のプロセスに関する詳細情報を提供する仮想ファイルシステムです。

`/proc`には仮想ファイルが含まれているため、仮想ファイルシステムと呼ばれます。これらの仮想ファイルは独自の特性を持ち、ほとんどのファイルはサイズがゼロバイトとして表示されます。

`/proc/interrupts`、`/proc/meminfo`、`/proc/mounts`、`/proc/partitions`などの仮想ファイルは、システムのハードウェアの瞬時の状態を提供します。他には、`/proc/filesystems`ファイルや`/proc/sys/`ディレクトリが、システムの設定情報やインターフェースを提供します。

有用なリソース：

- [Linuxファイルシステム階層 - /proc](https://www.tldp.org/LDP/Linux-Filesystem-Hierarchy/html/proc.html)

</details>

<details>
<summary><b>データバックアッププロセスについて説明してください。バックアップをテストする頻度はどのくらいが理想ですか？***</b></summary><br>

未完了です。

</details>

<details>
<summary><b>ext3/ext4のジャーナリングの3つのタイプを説明してください。</b></summary><br>

**ext3/ext4**ファイルシステムには、3つのジャーナリングタイプがあります：

- **ジャーナル** - メタデータとコンテンツがジャーナルに保存されます
- **オーダー** - メタデータのみがジャーナルに保存されます。メタデータは、コンテンツがディスクに書き込まれた後にジャーナルされます。これがデフォルトです
- **ライトバック** - メタデータのみがジャーナルに保存されます。メタデータは、コンテンツがディスクに書き込まれる前または後にジャーナルされる場合があります

</details>

<details>
<summary><b>inodeとは何ですか？ファイルのinode番号をどうやって調べ、どのように使用しますか？</b></summary><br>

**inode**は、Linuxやその他のUnix系オペレーティングシステムのファイルシステム上にあるデータ構造で、ファイルの名前と実際のデータを除くすべての情報を保存します。データ構造とは、データを効率的に使用できるように保存する方法です。

Unixファイルは、ディスクの2つの異なる部分に保存されます - データブロックとinodeです。スーパーブロックや他の難解な情報については触れません。データブロックにはファイルの「内容」が含まれています。ファイルに関する情報は別の場所、すなわちinodeに保存されます。

ファイルのinode番号は、`ls`コマンドを使用して簡単に見つけることができます。`-i`オプションを使用することで、現在のディレクトリ内の各オブジェクト（ファイル、リンク、ディレクトリ）の名前とinode番号を表示できます。例えば、次のコマンドは現在のディレクトリ内の各オブジェクトの名前とinode番号を表示します：

```bash
ls -i
```

`df`の`-i`オプションは、使用可能なスペースではなく、各ファイルシステムのinodeに関する情報を提供するように指示します。具体的には、dfに対してマウントされた各ファイルシステムについて、inodeの総数、空きinodeの数、使用中のinodeの数、および使用されているinodeの割合を返すように指示します。このオプションは、出力を見やすくするために`-h`オプションと一緒に使用できます。

```bash
df -hi
```

**inodeによるファイルの検索**

inodeがわかっている場合は、findコマンドを使用して検索できます。

```bash
find . -inum 435304 -print
```

**奇妙な名前のファイルの削除**

時には、ファイル名に奇妙な文字が含まれることがあります。Unixファイルシステムでは、ファイル名の一部として許可される文字は、ヌル文字（ASCII 000）や「/」以外のすべての文字です。他のすべての文字は許可されています。

ユーザーは、ディレクトリやファイルの表示が難しくなるような文字を使ってファイルを作成することがあります。たとえば、末尾に空白を付けた「.. 」というディレクトリを作成したり、名前にバックスペースを含むファイルを作成することができます。

```bash
touch `printf "aa\bb"`
```

さて、`ls`コマンドを使用するとどうなるでしょうか：

```bash
ls
aa?b
ls | grep 'a'
ab
```

`ls`が結果をターミナルに送信するとき、印刷できない文字を示すためにファイル名に「**?**」を表示することに注意してください。

このファイルを削除するには、`rm -i *`を使用すると、各ファイルを削除する前に確認を求められます。ただし、inode番号がわかっていれば、`find`を使ってファイルを削除することもできます。

```bash
ls -i
435304 aa?b
find . -inum 435304 -delete
```

役立つリソース：

- [UNIX/Linuxのinodeの基本を例を使って理解する](https://www.thegeekstuff.com/2012/01/linux-inodes/)
- [POSIXで定義されているinodeとは？](https://unix.stackexchange.com/questions/387087/what-is-an-inode-as-defined-by-posix/387093)

</details>

<details>
<summary><b><code>ls -l</code> コマンドがファイル属性をクエスチョンマークとして表示します。これは何を意味し、不要な「ゾンビ」ファイルを削除するためにどのような手順を取りますか？</b></summary><br>

この問題は解決が難しい場合があり、いくつかの手順が必要になることがあります。時には `test/file: Permission denied`、`test/file: No such file or directory`、または `test/file: Input/output error` のエラーメッセージが表示されることがあります。

これは、ユーザーがファイルに対して `stat()` を実行できない（実行権限が必要）が、ディレクトリエントリを読み取ることができる（ディレクトリに対する読み取りアクセスが必要）場合に発生します。そのため、ディレクトリ内のファイルのリストは取得できても、ファイルの情報を取得できません。ディレクトリに読み取り権限はあっても実行権限がない場合にこの現象が見られます。

`rsync` のようなプロセスは、作成と削除が非常に速い一時ファイルを生成することがあり、これが原因で `rm`、`mv` などの簡単なファイル管理コマンドでエラーが発生することがあります。

出力の例：

```bash
?????????? ? ?        ?               ?            ? sess_kee6fu9ag7tiph2jae
```

1) パーミッションを変更する: `chmod 0777 sess_kee6fu9ag7tiph2jae` して削除を試みる
2) 所有者を変更する: `chown root:root sess_kee6fu9ag7tiph2jae` して削除を試みる
3) ディレクトリのパーミッションと所有者を変更する: `chmod -R 0777 dir/ && chown -R root:root dir/` して削除を試みる
4) ファイルを再作成する: `touch sess_kee6fu9ag7tiph2jae` して削除を試みる
5) サーバー上の他の実行中のプロセスに注意する。例えば `rsync`。NFSサーバーが過負荷になっているときに一時的なエラーとして表示されることがあります
6) ファイルのiノードを見つける: `ls -i` し、削除を試みる: `find . -inum <inode_num> -delete`
7) （可能であれば）ファイルシステムを再マウントする
8) シングルユーザーモードでシステムを起動し、`fsck` でファイルシステムを修復する

有用なリソース:

- [ls コマンドでディレクトリにクエスチョンマークが表示される。IOエラーも発生する。](https://serverfault.com/questions/65616/question-marks-showing-in-ls-of-directory-io-errors-too)

</details>

<details>
<summary><b>LVM（論理ボリュームマネージャ）を使用するべきか、それとも使用しないべきか。LVMが提供する利点は何ですか？</b></summary><br>

- LVMを使うことでファイルシステムの移動が非常に簡単になります
- 新しい物理ボリュームにボリュームグループを拡張することができます
- 古い物理ボリュームから任意の数の論理ボリュームを移動することができます
- パーティションをアンマウントすることなく、そのボリュームをボリュームグループから削除することができます
- 論理ボリュームのスナップショットを作成してバックアップを作成することもできます
- LVMにはミラーリング機能が組み込まれており、複数の物理ボリュームにわたって論理ボリュームをミラーリングすることができます
- LVMはTRIMにも対応しています

有用なリソース:

- [LVMとは何か、何に使われるのか？](https://askubuntu.com/questions/3596/what-is-lvm-and-what-is-it-used-for)

</details>

<details>
<summary><b>LVMパーティションのサイズを増やす方法</b></summary><br>

LVMパーティションをリサイズするには、`lvextend` コマンドを使用します。

- サイズを500MB拡張する場合:

```bash
lvextend -L +500M /dev/vgroup/lvolume
```

- すべての利用可能な空きスペースを拡張する場合:

```bash
lvextend -l +100%FREE /dev/vgroup/lvolume
```

次に、`resize2fs` または `xfs_growfs` を使用してファイルシステムをリサイズします。

- extファイルシステムの場合:

```bash
resize2fs /dev/vgroup/lvolume
```

- xfsファイルシステムの場合:

```bash
xfs_growfs mountpoint_for_/dev/vgroup/lvolume
```

有用なリソース:

- [論理ボリュームの拡張](https://www.tldp.org/HOWTO/LVM-HOWTO/extendlv.html)

</details>

<details>
<summary><b>ゾンビ/デファンクトプロセスとは何ですか？</b></summary><br>

ゾンビプロセスとは、実行が完了した（`exit` システムコールによって）にもかかわらず、プロセステーブルにエントリが残っているプロセスです。これは「**終了状態**」のプロセスです。

**defunct** とマークされたプロセスは、親プロセスが適切に処理していないために残っている死んだプロセス（いわゆる「ゾンビ」）です。これらのプロセスは、親プロセスが終了すると init によって破棄されます。

有用なリソース:

- [defunct プロセスとは何か、それはなぜ終了しないのか？](https://askubuntu.com/questions/201303/what-is-a-defunct-process-and-why-doesnt-it-get-killed)

</details>

<details>
<summary><b>本番環境でシステムをアップグレード/更新する適切な方法は何ですか？これらのプロセスを自動化していますか？それらのためにダウンタイムを設定していますか？おすすめの方法を書いてください。</b></summary><br>

作成中です。

</details>

<details>
<summary><b>友人がMySQLサーバーの設定中に「MySQLをインストールした後に <code>sudo mysql_secure_installation</code> を実行するべきか？」と尋ねました。あなたはどう思いますか？</b></summary><br>

このコマンドを実行するのが良いでしょう。以下のような多くのセキュリティオプションを提供してくれます：

- ルートアカウントにパスワードを設定できる
- ローカルホスト外からアクセス可能なルートアカウントを削除できる
- 匿名ユーザーアカウントを削除できる
- デフォルトで匿名ユーザーがアクセスできるテストデータベースを削除できる

有用なリソース:

- [mysql_secure_installation を使う目的は何ですか？](https://stackoverflow.com/questions/20760908/what-is-purpose-of-using-mysql-secure-installation)

</details>

<details>
<summary><b><code>kill</code> コマンドの適切な使い方を説明してください。</b></summary><br>

プロセスを終了させる場合、絶対に必要な場合を除いて `kill -9/SIGKILL` を使わないでください。この強制終了は問題を引き起こす可能性があります。

以下の手順を試すことをお勧めします：

- まず **SIGTERM** (`kill -15`) シグナルを送信します。これはプロセスにシャットダウンを指示し、通常、正常にシャットダウンするためのシグナルと見なされています（ただし、このシグナルは無視されることがあります）。
- 次に **SIGHUP** (`kill -1`) シグナルを送信してみてください。これはプロセスにシャットダウンと再起動を指示するためによく使われますが、これもプロセスによって無視されることがあります。

ほとんどの場合、これだけで十分であり、よりクリーンな方法です。

有用なリソース:

- [いつ kill -9 を使わないほうがいいのか？](https://unix.stackexchange.com/questions/8916/when-should-i-not-kill-9-a-process)
- [SIGTERM vs. SIGKILL](https://major.io/2010/03/18/sigterm-vs-sigkill/)

</details>

<details>
<summary><b><code>strace</code> コマンドとは何か、それをどのように使うべきかを説明してください。既に実行中のプロセスに接続する例を挙げてください。</b></summary><br>

`strace` は、LinuxのようなUnix系オペレーティングシステムでプログラムのデバッグやトラブルシューティングに使用される強力なコマンドラインツールです。プロセスが行うすべてのシステムコールと、プロセスが受け取るシグナルをキャプチャして記録します。

**Strace の概要**

`strace` は軽量なデバッガーと見なすことができます。プログラマーやユーザーがプログラムがOSとどのように相互作用しているかを迅速に把握するのに役立ちます。これを行うために、システムコールとシグナルを監視します。

**使用例**

ソースコードがない場合や、それを詳しく調べるのが面倒な場合に役立ちます。自分のコードでも、**GDB** を開きたくない場合や、外部との相互作用を理解したいだけの場合にも便利です。

**プロセスに接続する例**

`strace -p <PID>` - 既に実行中のプロセスに strace を接続します。

`strace -e trace=read,write -p <PID>` - これにより、特定のイベント（この例では読み取りと書き込み）を追跡することができます。これにより、プロセスによって行われる読み取りおよび書き込みのすべてのシステムコールが表示されます。

その他の例

- `-e trace=network` - ネットワーク関連のすべてのシステムコールを追跡します。
- `-e trace=signal` - シグナル関連のすべてのシステムコールを追跡します。
- `-e trace=ipc` - IPC関連のすべてのシステムコールを追跡します。
- `-e trace=desc` - ファイルディスクリプタ関連のすべてのシステムコールを追跡します。
- `-e trace=memory` - メモリマッピング関連のすべてのシステムコールを追跡します。

有用なリソース:

- [strace はどのように使用すべきか？（元記事）](https://stackoverflow.com/questions/174942/how-should-strace-be-used)
- [strace は既に実行中のプロセスにどのように接続するのか？（元記事）](https://stackoverflow.com/questions/7482076/how-does-strace-connect-to-an-already-running-process)
- [strace: 楽しみ、利益、デバッグのために](http://timetobleed.com/hello-world/)

</details>

<details>
<summary><b>いつ <code>chmod</code> コマンドの代わりに、または併用してアクセス制御リストを使用しますか？ ***</b></summary><br>

作成中です。

</details>

<details>
<summary><b><code>/etc/shadow</code> ファイルでサポートされているアルゴリズムはどれですか？</b></summary><br>

一般的な現在のアルゴリズムは以下の通りです：

- MD5
- SHA-1（SHAとも呼ばれます）

どちらも暗号化やセキュリティ目的での使用は推奨されません!!

- SHA-256
- SHA-512
- SHA-3（KECCAKは2012年10月に新しい連邦承認のハッシュアルゴリズムとしてコンペティションで優勝しました）

有用なリソース:

- [Linuxのパスワードを暗号化するために使用されるアルゴリズムは何ですか？](https://crypto.stackexchange.com/questions/40841/what-is-the-algorithm-used-to-encrypt-linux-passwords)
- [パスワードを隠すために使用されるハッシュアルゴリズムを見つける方法は？](https://unix.stackexchange.com/questions/430141/how-to-find-the-hashing-algorithm-used-to-obfuscate-passwords)

</details>

<details>
<summary><b>Unix系システムでのulimitの使用目的は何ですか？</b></summary><br>

LinuxやBSDを含むほとんどのUnix系オペレーティングシステムは、スレッド、ファイル、ネットワーク接続などのシステムリソースの使用をプロセスごとおよびユーザーごとに制限・管理する方法を提供しています。これらの「**ulimits**」は、単一のユーザーが過剰にシステムリソースを使用するのを防ぎます。

</details>

<details>
<summary><b>ソフトリミットとハードリミットとは何ですか？</b></summary><br>

**ハードリミット**は、スーパーユーザーまたはrootによって設定されたユーザーに許可される最大値です。この値は `/etc/security/limits.conf` ファイルに設定されています。ユーザーは必要に応じて**ソフトリミット**を増やすことができますが、**ソフトリミット**を**ハードリミット**より高く設定することはできません。

</details>

<details>
<summary><b>Redisと連携するためにHAProxyを設定している際に、ログから <code>General socket error (Permission denied)</code> エラーが発生しました。SELinuxが有効です。CLIでの基本的なSELinuxトラブルシューティングを説明してください。 ***</b></summary><br>

有用なリソース:

- [CLIでの基本的なSELinuxトラブルシューティング](https://access.redhat.com/articles/2191331)

</details>

<details>
<summary><b>RSAキー認証を設定しましたが、サーバーが予想通り「Server refused our key」と表示されます。この問題の原因をどこで探しますか？</b></summary><br>

**サーバー側**

ファイル `/etc/ssh/sshd_config` に `LogLevel VERBOSE` を設定することが必要でしょう。さらに高いレベルも設定できます。

SSH認証の失敗は、`/var/log/auth.log`、`/var/log/secure`、または `/var/log/audit/audit.log` に記録されます。

以下のコマンドを使用すると、SSHに関連するログ行のみを表示できます（例）:

```bash
grep 'sshd' /var/log/auth.log
```

次に、すべての失敗したSSHログインを一覧表示する最も簡単なコマンドは以下の通りです:

```bash
grep "Failed password" /var/log/auth.log
```

また、以下のコマンドも有用です:

```bash
grep "Failed\|Failure" /var/log/auth.log
```

新しいLinuxディストリビューションでは、Systemdデーモンが管理するランタイムログファイルを `journalctl` コマンド（`ssh.service` または `sshd.service`）でクエリできます。例えば:

```bash
journalctl _SYSTEMD_UNIT=ssh.service | egrep "Failed|Failure"
```

**クライアント側**

また、SSHクライアントを `-v|--verbose` オプションで実行することをお勧めします。これは最初のレベルの詳細表示です。次に、さらに多くのデバッグメッセージを表示するために、レベル2および3の詳細表示を有効にすることができます。例として `-vv` などです。

有用なリソース:

- [SSHのデバッグモードを有効にして接続の問題をトラブルシューティングする](https://www.tecmint.com/enable-debugging-mode-in-ssh/)

</details>

<details>
<summary><b>なぜほとんどのディストリビューションはXFSや他のファイルシステムではなく、ext4を使用しているのでしょうか？なぜファイルシステムがこれほど多いのでしょうか？ ***</b></summary><br>

未完成。

</details>

<details>
<summary><b>プロジェクトマネージャーが新しいSQLサーバーを必要としています。彼女/彼に何を質問しますか？ ***</b></summary><br>

DBAに以下のような質問をしてほしいです:

- データベースの大きさはどのくらいですか？（既存のサーバーにデータベースを追加できるかどうか）
- データベースの重要度はどのくらいですか？（クラスタリング、災害復旧、高可用性について）

</details>

<details>
<summary><b>ランダムな値で100行のファイルを作成します。</b></summary><br>

例えば:

```bash
cat /dev/urandom | tr -dc 'a-zA-Z0-9' | fold -w 32 | head -n 100 > /path/to/file
```

</details>

<details>
<summary><b>パスワードなしで別のユーザーとしてスクリプトを実行するにはどうすればよいですか？</b></summary><br>

例えば (`visudo` コマンドを使用して):

```bash
user1 ALL=(user2) NOPASSWD: /opt/scripts/bin/generate.sh
```

コマンドのパスは絶対パスで指定する必要があります。その後、user1のシェルから `sudo -u user2 /opt/scripts/bin/generate.sh` を実行します。

</details>

<details>
<summary><b>bashスクリプトでrootとして実行しているかを確認するにはどうすればよいですか？注意すべき点は何ですか？</b></summary><br>

bashスクリプトでは、実行中のユーザーがrootかどうかを確認する方法がいくつかあります。

注意点として、rootユーザー名を使用してユーザーがrootかどうかを確認しないでください。IDが0のユーザーがrootと呼ばれる保証はありません。それは広く守られている非常に強力な慣例ですが、誰でもスーパーユーザーの名前を別のものに変更することができます。

bashを使用する場合、`$UID`は変更されて実際にスクリプトを実行しているユーザーを反映しない可能性があるため、`$EUID`を使用するのが最善だと思います。

```bash
if (( $EUID != 0 )); then
  echo "Please run as root"
  exit
fi
```
</details>

<details>
<summary><b><code>nobody</code>アカウントを使用する特定の例を教えてください。また、<code>nobody</code>アカウントと<code>www-data</code>アカウントでhttpdサービスを実行する場合の違いは何ですか？</b></summary><br>

多くのUnix系システムでは、`nobody`は特定のファイルを所有せず、特権グループにも属さず、他のユーザーと同じ権限しか持たないユーザーアカウントの一般的な名称です。

悪意のあるユーザーが制御を奪った場合の被害を限定するために、特にサーバーなどのデーモンを`nobody`として実行することが一般的です。

ただし、この手法の有用性は、複数のデーモンが同じ方法で実行される場合には低下します。なぜなら、`nobody`が所有するプロセスは互いに信号を送ったり、さらにはデバッグし合うことができるため、他のデーモンの制御も可能になってしまうからです。

**`nobody`アカウントを使用するのはいつですか？**

プログラムの操作に特別な権限が必要ない場合に使用します。特にディスク操作が不要な場合に適しています。

現実の例として、**memcached**（キー値のインメモリキャッシュ/データベース/ツール）があります。これは、私のコンピュータやサーバーで`nobody`アカウントで実行されています。なぜなら、このプログラムには特別な権限が必要ないからです。書き込みアクセス権を持つアカウントを与えることは、不要なリスクとなるでしょう。

良い例としては、ウェブサーバーも挙げられます。例えば、Apacheがrootとして実行されていて、誰かがApacheを通じてカスタムコマンドを送信できる方法を見つけた場合、システム全体にアクセスできてしまいます。

`nobody`アカウントは、bashのような実際のシェルを持たずにファイルシステムへのアクセスをユーザーに提供するための制限付きシェルとしても使用されます。これにより、ユーザーが他のプログラムを実行することを防ぐことができます。

**httpd（Apache）における`nobody`と`www-data`の違い**

Apacheは起動時にrootアクセスが必要ですが、すぐに特権のないユーザーの権限に切り替えます。このユーザーは、`nobody`、`apache`、または`www-data`のいずれかになります。

いくつかのアプリケーションでは、`nobody`ユーザーがデフォルトとして使用されます。例えば、Apacheサービスがbindに属するファイルを上書きしないようにすることが望ましいです。サービスごとに専用のアカウントを持つことは、非常に良いアイデアです。

Apacheを`nobody:nobody`として実行するのは比較的簡単で、ユーザーとグループの設定を更新するだけです。しかし、先に述べたように、特定のユーザー/グループを推奨しない理由があります。将来的に別のサービスを追加する際に、それも`nobody`として実行することになり、ファイルシステムに対する書き込みアクセス権を`nobody`ユーザーに与えたことを忘れてしまうかもしれません。

もし、`nobody`が何らかの形で危険にさらされた場合、`www-data`のようなアプリケーション固有のユーザーよりも影響が大きくなる可能性があります。もちろん、これらはファイルやグループの権限に大きく依存します。`nobody`は他のユーザーと同じ権限を使用しますが、アプリケーション固有のユーザーはファイルの読み取りアクセスを許可しつつ、他のユーザーからのアクセスを拒否するように設定できる場合があります。

役立つリソース:

- [What is nobody user and group?](https://unix.stackexchange.com/questions/186568/what-is-nobody-user-and-group)
- [The Linux and Unix Nobody User](http://linuxg.net/the-linux-and-unix-nobody-user/)
- [What is the purpose of the 'nobody' user?](https://askubuntu.com/questions/329714/what-is-the-purpose-of-the-nobody-user)

</details>

<details>
<summary><b>出力をファイルにリダイレクトしつつ、stdoutに表示させる方法はありますか？</b></summary><br>

必要なコマンドは`tee`です。

`foo | tee output.file`

例えば、stdoutのみに関心がある場合:

`ls -a | tee output.file`

stderrを含めたい場合は、次のようにします。

`program [arguments...] 2>&1 | tee outfile`

`2>&1`はチャネル2（stderr/標準エラー）をチャネル1（stdout/標準出力）にリダイレクトし、両方をstdoutとして出力します。また、`tee`コマンドを使用して指定された出力ファイルにも書き込まれます。

さらに、ログファイルに追加書き込みを行いたい場合は、`tee -a`を使用します。

`program [arguments...] 2>&1 | tee -a outfile`

</details>

<details>
<summary><b>推奨されるbashのshebangは何ですか？また、<code>./script</code>でファイルを実行するのと<code>bash script</code>で実行するのとの違いは何ですか？</b></summary><br>

移植性を考慮して、`#!/usr/bin/env bash`を使用するべきです。異なる*Unix系OSではbashが異なる場所に配置されており、`/usr/bin/env`を使用することで`PATH`上で最初に見つかったbashを実行する回避策となります。

`./script`を実行する場合、そのファイルに実行権限が必要ですが、プログラムの種類には関係なく実行されます。それは**bashスクリプト**、**shスクリプト**、**Perl**、**Python**、**awk**、**expectスクリプト**、または実際の**バイナリエグゼキュタブル**である可能性があります。一方、`bash script`を実行すると、そのファイルが他の何かではなく`sh`で実行されることになります。

役立つリソース:

- [What is the preferred Bash shebang? (original)](https://stackoverflow.com/questions/10376206/what-is-the-preferred-bash-shebang)

</details>

<details>
<summary><b>非常に長い時間実行されるコマンドを実行する必要があります。SSHセッションが切断された後にこのプロセスが終了するのを防ぐにはどうすればよいですか？</b></summary><br>

`nohup` を使ってプロセスがハングアップシグナルを無視するようにします。

```bash
nohup long-running-process &
exit
```

または **GNU Screen** を使用することもできます：

```bash
screen -d -m long-running-process
exit
```

役立つリソース：

- [リモートSSHセッションとプロセスを切断後も実行し続ける5つの方法](https://www.tecmint.com/keep-remote-ssh-sessions-running-after-disconnection/)

</details>

<details>
<summary><b>中間認証機関の主な目的は何ですか？</b></summary><br>

中間CAの主な目的を理解するには、まず **ルートCA**、**中間CA**、および **SSL証明書チェーンの信頼** について学ぶ必要があります。

**ルートCA** は通常、エンドエンティティ/サーバー証明書を直接署名することはありません。ルート証明書を発行し、これらの証明書は通常、すべてのブラウザ、モバイル、およびアプリケーションに事前にインストールされています。これらの証明書の秘密鍵は、後に発行される中間証明書を署名するために使用されます。ルートCAは通常「オフライン」で、アクセスが厳しく制限された非常に安全な環境に保管されています。

**中間CA** は、ルートCAの下に1つまたは複数のレベルで従属しているCAであり、ルートCAから委任を受けて証明書に署名します。中間CAを作成し使用する主な目的はセキュリティであり、中間秘密鍵が侵害された場合、ルートCAは中間証明書を取り消し、新しい暗号鍵ペアで新しい証明書を作成できます。

**SSL証明書チェーンの信頼** は、ルート証明書からエンドエンティティ/サーバー証明書までのSSL証明書のリストです。SSL証明書が信頼されるためには、接続デバイス（ブラウザ、モバイル、アプリケーション）の信頼できるCAリストに含まれている信頼されたCAによって発行される必要があります。そのため、接続デバイスは、信頼できるCAによって発行された証明書と一致するまで、チェーン内の各SSL証明書の信頼性を検証します。

**ルート-中間CA** 構造は、ルートキーの侵害による破滅的な影響から保護するために、各主要CAによって作成されます。ルートキーが侵害されると、ルートおよびすべての従属証明書が信頼できなくなります。このため、主要なルートキーを厳格に保護するために中間CAを作成することは最良の方法です。

役立つリソース：

- [証明書チェーンの仕組み](https://knowledge.digicert.com/solution/SO16297.html)

</details>

<details>
<summary><b>設定変更後にPostgreSQLを再読み込みするには？</b></summary><br>

解決策 1:

```bash
systemctl reload postgresql
```

解決策 2:

```
su - postgres
/usr/bin/pg_ctl reload
```

解決策 3:

```
SELECT pg_reload_conf();
```

</details>

<details>
<summary><b>いくつかのエイリアスを <code>.profile</code> に追加しました。シェルを終了せずに再読み込みするにはどうすればよいですか？</b></summary><br>

最適な方法は `exec $SHELL -l` です。`exec` は現在のプロセスを新しいプロセスで置き換えます。また、別の良い方法は `. ~/.profile` です。

役立つリソース：

- [コマンドラインから .bash_profile を再読み込みするには？](https://stackoverflow.com/questions/4608187/how-to-reload-bash-profile-from-the-command-line)

</details>

<details>
<summary><b>シェルの履歴を保存せずに終了するには？</b></summary><br>

```bash
kill -9 $$
```

または

```bash
unset HISTFILE && exit
```

役立つリソース：

- [履歴を保存せずにターミナルを閉じるには？](https://unix.stackexchange.com/questions/25049/how-do-i-close-a-terminal-without-saving-the-history)

</details>

<details>
<summary><b>このUID 0のtoorアカウントは何ですか？自分が侵害されたのでしょうか？</b></summary><br>

**toor** は代替のスーパーユーザーアカウントで、toor は root を逆さにしたものです。これは、root のデフォルトシェルを変更する必要がないように、標準外のシェルと一緒に使用するために意図されています。

これは重要です。なぜなら、基本のディストリビューションに含まれていないシェルは、`/usr/local/bin` にインストールされるため、デフォルトでは異なるファイルシステムに存在します。もし root のシェルが `/usr/local/bin` にあり、`/usr/local/bin` を含むファイルシステムがマウントされていない場合、root は問題を修正するためにログインできず、シングルユーザーモードに再起動してシェルのパスを入力する必要があります。

一部の人は、標準外のシェルを使用して日常的な root タスクに toor を使用し、root（標準シェルを持つ）はシングルユーザーモードや緊急時に使用します。デフォルトでは、toor にはパスワードがないためログインできないので、root としてログインし、toor にパスワードを設定してから使用してください。

役立つリソース：

- [root アカウント（と toor）](https://administratosphere.wordpress.com/2007/10/04/the-root-account-and-toor/)

</details>

<details>
<summary><b>複雑なディレクトリ構造内の何千ものファイルから特定の文字列を含むファイルを簡単に検索する方法はありますか？</b></summary><br>

例えば、`fgrep` を使用します：

```bash
fgrep * -R "string"
```

または

```bash
grep -insr "pattern" *
```

- `-i` **PATTERN** と入力ファイルの両方で大文字と小文字の区別を無視します
- `-n` 各出力行にその入力ファイル内の1ベースの行番号をプレフィックスとして付けます
- `-s` 存在しないまたは読み取れないファイルに関するエラーメッセージを抑制します
- `-r` 各ディレクトリ下のすべてのファイルを再帰的に読み取ります

役立つリソース：

- [LINUXでディレクトリおよびそのサブディレクトリ内のファイルに文字列をgrepする方法](https://stackoverflow.com/questions/15622328/how-to-grep-a-string-in-a-directory-and-all-its-subdirectories-files-in-linux)

</details>

<details>
<summary><b>実行時に実行ファイルがロードする動的ライブラリを調べるには？</b></summary><br>

`ldd` コマンドを使用して調べることができます：

```bash
ldd /bin/ls
```

</details>

<details>
<summary><b>テスト環境と本番環境の同期作業があります。どのような手順を踏むべきですか？</b></summary><br>

環境のクローンについて細かいことにこだわると、重要な点を見失うことがあります：

- 本番環境だけが本番環境である

そして、デプロイのたびに、デプロイコード + ソフトウェア + 環境のユニークな組み合わせをテストしていることになります。

時々、良い解決策は本番サーバーを定期的にクローンしてテストサーバーを作成することです。例えば、スナップショットを使って本番環境の正確なコピーを持つインスタンスを作成することができます：

- 本番環境のスナップショットを生成する
- スナップショットをステージング（または他の場所）にコピーする
- このスナップショットを使って新しいディスクを作成する

もちろん、さまざまなシステムコンポーネントや全体のシステムのクローンを作成し、実際のトラフィックをキャプチャしてオフラインで再生することもできます（システムテストのゴールドスタンダード）。しかし、多くのシステムは大きすぎ、複雑すぎて、クローン作成がコスト的に難しい場合があります。

環境同期の前には、テスト環境で行ったすべての変更を追跡し、それを本番環境に伝播する方法を提供することが良い方法です。これにより、どのステップもスキップすることなく、できるだけスムーズに行うことができます。

また、環境を本番環境からテスト環境に更新するための構造比較ツールやデプロイスクリプトも良い解決策です。

**プレシンク作業**

まず最初に、テスト環境での変更を行わないように開発者やクライアントに通知します（可能であれば、この環境をターゲットにしたテストドメインを無効化するか、同期に関する情報を表示する静的ページを設定します）。

両方の環境のバックアップ/スナップショットを作成することも重要です。

**データベースサーバー**

- システムバージョンを同期/更新する（例：パッケージ）
- 本番データベースサーバーからダンプファイルを作成する
- テストデータベースサーバーにダンプファイルをインポートする
- 必要に応じて、ログイン権限、ロール、データベース権限、データベースへのオープン接続などを同期する

**Web/Appサーバー**

- システムバージョンを同期/更新する（例：パッケージ）
- 必要に応じて、カーネルパラメーター、ファイアウォールルールなどを更新する
- 実行中のすべての重要なサービスの設定ファイルを同期/更新する
- ユーザーアカウント（例：権限）とそのホームディレクトリを同期/更新する
- git/svnリポジトリからプロジェクトをデプロイする
- プロジェクト内の重要なディレクトリ（例：**static**、**asset** など）を同期/更新する
- プロジェクトディレクトリの権限を同期/更新する
- すべてのWebhookを削除/更新する
- cronジョブを更新する

**その他の作業**

- テストドメインおよび特定のURLのためにロードバランサーの設定を更新する
- キュー、セッション、およびストレージインスタンスの設定を更新する

役立つリソース：

- [テストサーバー環境と本番サーバー環境をクリーンで同期し、一貫性を保つ方法](https://stackoverflow.com/questions/639668/keeping-testing-and-production-server-environments-clean-in-sync-and-consisten)

</details>

###### Network Questions (24)

<details>
<summary><b>ワークステーションで仮想インターフェースを設定します。 ***</b></summary><br>

完了予定です。

</details>

<details>
<summary><b>HTTPモニターによると、ウェブサイトがダウンしています。ポートにはtelnetできるので、どうやって解決しますか？</b></summary><br>

ポートにtelnetできる場合、ポートでリスニングしているサービスは実行中で、接続できることを意味します（ネットワークの問題ではありません）。ドメインが解決されるIPアドレスを確認し、同じドメインを使用して接続テストを行うことが良いです。

まず、他の場所からサイトがオンラインかどうかを確認します。これにより、サイトがどこでもダウンしているのか、それとも自分のネットワークだけで表示できないのかが分かります。また、ウェブブラウザが返すものを確認するのも良いアイデアです。

**IP接続だけが動作する場合**

- `whois` を使用して、どのDNSサーバーがホスト名を提供しているかを確認します： `whois www.example.com`
- `dig` や `host` などのツールを使ってDNSをテストし、ホスト名が解決されているかを確認します： `host www.example.org dns.example.org`
- グローバルパブリックDNSサーバーも確認します： `host www.example.com 9.9.9.9`

ドメインが解決されない場合、DNSサーバーに問題がある可能性があります。

**ドメインが適切に解決されている場合**

- ログファイルを調査し、ログに基づいて問題を解決します。これが問題を示す最良の方法です。
- HTTPステータスコードを確認します。通常、5xx のレスポンスが返される場合、サーバーが過負荷になっている可能性があります。クライアントが多くの接続を行っているか、特定のURLに対する要求が多すぎるかもしれません。キャッシュのルールが適切に機能していない可能性もあります。
- ウェブ/プロキシサーバーの設定（例： `nginx -t -c </path/to/nginx.conf>`）を確認します。他のシステム管理者がドメイン設定に変更を加えた可能性があります。
- サーバーで何かがクラッシュしているかもしれません。スペースが不足しているか、メモリが不足している可能性があります。
- ウェブサイトにプログラミングエラーがあるかもしれません。

</details>

<details>
<summary><b>ロードバランシングはサーバーのパフォーマンスに大きな影響を与える可能性があります。いくつかのロードバランシングメカニズムについて説明してください。 ***</b></summary><br>

完了予定です。

</details>

<details>
<summary><b>DNSの問題によって性能が低下するネットワークトラブルシューティングツールの例をリストしてください。 ***</b></summary><br>

完了予定です。

</details>

<details>
<summary><b>HTTP 1.1 と HTTP 2.0 の違いを説明してください。</b></summary><br>

<b>HTTP/2</b> は、クエリの多重化、ヘッダーの圧縮、優先順位付け、よりインテリジェントなパケットストリーミング管理をサポートします。これにより、レイテンシーが削減され、現代のウェブページでのコンテンツのダウンロードが加速します。

**HTTP/1.1** との主な違い：

- テキスト形式ではなく、バイナリ形式である
- 順序通りでブロックされる代わりに、完全に多重化されている
- したがって、並行処理のために1つの接続を使用できる
- オーバーヘッドを減らすためにヘッダー圧縮を使用する
- サーバーがクライアントキャッシュに対して「プッシュ」レスポンスを積極的に送信できる

役立つリソース：

- [HTTP/2 とは - 完全ガイド](https://kinsta.com/learn/what-is-http2/)

</details>

<details>
<summary><b>開発チームからエラー報告があります：<code>POST http://ws.int/api/v1/Submit/ 結果 413 Request Entity Too Large</code>。何が問題ですか？</b></summary><br>

**NGINX 設定ファイルの修正**

`client_max_body_size` 変数の値を正しく設定します：

```bash
client_max_body_size 20M;
```

Nginx を再起動して変更を適用します。

**php.ini ファイルのアップロード制限の修正**

すべての設定で必要ではありませんが、PHPのアップロード設定も修正して、PHPの設定で制限を超えないようにする必要があるかもしれません。

次に、以下のディレクティブを1つずつ見つけてください：

```bash
upload_max_filesize
post_max_size
```

制限を 20M に増やします。デフォルトでは 8M と 2M です：

```bash
upload_max_filesize = 20M
post_max_size = 20M
```

最後に保存して PHP を再起動します。

役立つリソース：

- [NGINX で client_max_body_size を設定して 413 Request Entity Too Large エラーを解決する方法](https://serverfault.com/questions/814767/413-request-entity-too-large-in-nginx-with-client-max-body-size-set)

</details>

<details>
<summary><b>ハンドシェイクメカニズムとは何ですか？なぜ3ウェイハンドシェイクが必要なのですか？</b></summary><br>

**ハンドシェイキング** は、一つのデバイスが別のデバイスに対して通信チャネルを確立したい旨のメッセージを送信することで始まります。その後、二つのデバイスは数回メッセージをやり取りし、通信プロトコルについて合意します。

**3ウェイハンドシェイク** は、TCP/IPネットワークでローカルホスト/クライアントとサーバーの間に接続を作成するために使用される方法です。これは3段階のプロセスで、クライアントとサーバーが `SYN` と `ACK`（`SYN`、`SYN-ACK`、`ACK`）パケットを交換する必要があります。その後、実際のデータ通信が始まります。

役立つリソース：

- [なぜ3ウェイハンドシェイクが必要なのか？2ウェイではダメなのか？](https://networkengineering.stackexchange.com/questions/24068/why-do-we-need-a-3-way-handshake-why-not-just-2-way)

</details>

<details>
<summary><b>なぜUDPはTCPよりも速いのですか？</b></summary><br>

**UDP** は **TCP** よりも速いです。その理由は、UDPには確認パケット（`ACK`）が存在しないため、継続的なパケットストリームを許可するからです。一方、TCPはパケットのセットを確認し、TCPウィンドウサイズとラウンドトリップタイム（`RTT`）を使用して計算します。

役立つリソース：

- [UDP と TCP、どれくらい速いのか？](https://stackoverflow.com/questions/47903/udp-vs-tcp-how-much-faster-is-it)

</details>

<details>
<summary><b>セキュリティを向上させるための最も重要な OpenSSH パラメータを5つ挙げてください。 ***</b></summary><br>

完了予定です。

役立つリソース：

- [OpenSSH のセキュリティとハードニング](https://linux-audit.com/audit-and-harden-your-ssh-configuration/)

</details>

<details>
<summary><b>NATとは何ですか？何に使われるのですか？</b></summary><br>

NAT（ネットワークアドレス変換）は、登録されていないIPアドレスを使用するプライベートIPネットワークがインターネットに接続できるようにします。**NAT** は通常、二つのネットワークを接続するルーター上で動作し、内部ネットワークのプライベート（グローバルにユニークでない）アドレスを合法的なアドレスに変換します。その後、パケットが別のネットワークに転送されます。

ネットワーク外部の特別なアクセスが必要なワークステーションや他のコンピュータには、**NAT** を使用して特定の外部IPを割り当てることができ、ユニークな公開IPアドレスを必要とするコンピュータやアプリケーションと通信できます。**NAT** はファイアウォールのセキュリティの重要な側面でもあります。

役立つリソース：

- [ネットワークアドレス変換（NAT）の概念](http://www.firewall.cx/networking-topics/network-address-translation-nat/227-nat-concepts.html)

</details>

<details>
<summary><b>スパニングツリーの目的は何ですか？</b></summary><br>

このプロトコルはOSIモデルのレイヤー2で動作し、ネットワーク上のループを防ぐことを目的としています。**STP（スパニングツリー・プロトコル）** がなければ、冗長なスイッチの展開がブロードキャストストームを引き起こし、最も堅牢なネットワークでさえも機能不全に陥る可能性があります。元のIEEE 802.1D標準に基づくいくつかのバージョンがあり、それぞれがわずかに異なる方法で動作しますが、主に同じループフリーの目標を達成します。

</details>

<details>
<summary><b>Linuxサーバーでリスニングしているポートを確認するにはどうすればよいですか？</b></summary><br>

以下のコマンドを使用します：

- `lsof -i`
- `ss -l`
- `netstat -atn` - TCP用
- `netstat -aun` - UDP用
- `netstat -tulapn`

</details>

<details>
<summary><b>リモートホストに接続するときに `<code>Host key verification failed</code>` とはどういう意味ですか？自動的に受け入れますか？</b></summary><br>

`Host key verification failed` は、リモートホストのホストキーが変更されたことを意味します。これは、ホストキーが `/etc/ssh` にあるコンピュータが、アップグレード中に古いホストキーをコピーせずにアップグレードされた場合に簡単に発生します。ここでのホストキーは、最初にアクセスしたときと同じコンピュータに再接続する際の証明です。

SSHを介してサーバーに接続するたびに、そのサーバーの公開鍵が自分のホームディレクトリ（またはMacやWindowsデスクトップを使用している場合はローカルアカウント設定）にある**known_hosts**というファイルに保存されます。再接続時にSSH接続は、現在の公開鍵が**known_hosts**ファイルに保存されているものと一致するかどうかを確認します。サーバーの鍵が前回接続したときから変更されている場合、上記のエラーが表示されます。

一部の人が推奨するように、全体の**known_hosts**ファイルを削除しないでください。これは警告の意味を完全に無効にします。これは、中間者攻撃が発生しているかもしれないという警告のセキュリティ機能です。

新しいホストキーを受け入れる前に、確認のためにシステム管理者に連絡してください。

役立つリソース：

- [Gitエラー：「Host Key Verification Failed」でリモートリポジトリに接続する際の対処法](https://stackoverflow.com/questions/13363553/git-error-host-key-verification-failed-when-connecting-to-remote-repository)

</details>

<details>
<summary><b><code>telnet</code>を使用してHTTPリクエストを送信するにはどうすればよいですか？</b></summary><br>

例えば：

```bash
telnet example.com 80
Trying 192.168.252.10...
Connected to example.com.
Escape character is '^]'.
GET /questions HTTP/1.0
Host: example.com

HTTP/1.1 200 OK
Content-Type: text/html; charset=utf-8
...
```

</details>

<details>
<summary><b>Linuxでポート80を使用しているプログラムを終了するにはどうすればよいですか？</b></summary><br>

ポート80をリスニングしているプロセスをリストするには：

```bash
# with lsof
lsof -i:80

# with fuser
fuser 80/tcp
```

ポート80をリスニングしているプロセスをkillするには:

```bash
kill $(lsof -t -i:80)
```

もしくは雑に:

```bash
kill -9 $(lsof -t -i:80)
```

それか`fuser`コマンドで:

```bash
fuser -k 80/tcp
```

有用なリソース:

- [Linuxで特定のポートで実行されているプロセスを終了する方法](https://stackoverflow.com/questions/11583562/how-to-kill-a-process-running-on-particular-port-in-linux/32592965)
- [特定のポートを使用しているプロセスのPIDを見つける方法](https://unix.stackexchange.com/questions/106561/finding-the-pid-of-the-process-using-a-specific-port)

</details>

<details>
<summary><b><code>curl: (56) TCP connection reset by peer</code>というエラーが発生しました。問題を解決するためにどのような手順を取りますか？</b></summary><br>

- URLが正しいか確認してください。`www`を追加する必要があるか、`Host:`ヘッダーを正しく設定する必要があるかもしれません。また、スキーム（httpまたはhttps）も確認してください。
- ドメインが正しいIPアドレスに解決されているか確認してください。
- `--trace-ascii curl.dump`でデバッグトレースを有効にします。`Recv failure`は非常に一般的なエラーで、詳細情報を得るのが難しいです。
- 外部IPからのデバッグ接続のために`--proxy`を使用して外部プロキシを利用します。
- ネットワークスニファー（例: `tcpdump`）を使用してTCP/IP層でのデバッグ接続を行います。
- プロダクション環境やネットワークの出口ポイントでファイアウォールルールを確認し、NATルールも確認してください。
- ネットワークを通過するパケットのMTUサイズを確認してください。
- httpsプロトコルに接続している場合、SSL/TLSの`curl`パラメータでSSLバージョンを確認します。
- クライアント側に問題があるかもしれません。例えば、netfilterがあなたのIPアドレスからドメインへの接続をドロップまたは制限している可能性があります。

有用なリソース:

- [CURL ERROR: Recv failure: Connection reset by peer - PHP Curl](https://stackoverflow.com/questions/10285700/curl-error-recv-failure-connection-reset-by-peer-php-curl)

</details>

<details>
<summary><b>iptablesで特定のIPへの/からのトラフィックを許可するにはどうすればよいですか？</b></summary><br>

例えば：

```bash
/sbin/iptables -A INPUT -p tcp -s XXX.XXX.XXX.XXX -j ACCEPT
/sbin/iptables -A OUTPUT -p tcp -d  XXX.XXX.XXX.XXX -j ACCEPT
```

</details>

<details>
<summary><b>OpenBSDで<code>pf</code>を使用して悪質なIPアドレスをブロックするにはどうすればよいですか？</b></summary><br>

これを実現する最良の方法は、テーブルを定義し、`pf.conf`でホストをブロックするルールを作成することです：

```bash
table <badhosts> persist
block on fxp0 from <badhosts> to any
```

その後、IPアドレスを動的に追加/削除するには：

```bash
pfctl -t badhosts -T add 1.2.3.4
pfctl -t badhosts -T delete 1.2.3.4
```

</details>

<details>
<summary><b>ApacheやNginxのようなWebサーバーは、リクエストを処理する前と後のどちらでログファイルに情報を書き込みますか？</b></summary><br>

両方のサーバーは非常に包括的で柔軟なログ機能を提供しています。これにより、サーバーで発生するすべての出来事を記録することができます。初期リクエストから、URLマッピングプロセスを経て、最終的な接続の解決まで、プロセス中に発生したエラーも含まれます。

**Apache**

Apacheサーバーのアクセスログは、サーバーが処理したすべてのリクエストを記録します（リクエストが完了した後に記録されます）。

**Nginx**

NGINXは、リクエストが処理された直後にアクセスログにクライアントリクエストに関する情報を書き込みます。

有用なリソース:

- [Apacheがアクセスログに書き込むタイミング - リクエストを処理する前か後か？](https://webmasters.stackexchange.com/questions/65566/when-does-apache-log-to-access-log-before-or-after-serving-the-request)
- [Nginxがリクエストを処理する前にログを記録する方法](https://serverfault.com/questions/693049/nginx-log-request-before-processing)

</details>

<details>
<summary><b>Webサーバーログを分析し、<code>5xx</code> HTTPコードのみを表示するには、どの外部ツールを使用しますか？</b></summary><br>

  ```bash
tail -n 100 -f /path/to/logfile | grep "HTTP/[1-2].[0-1]\" [5]"
```

http/httpsログ管理ツールの例:

- **goaccess** - オープンソースのリアルタイムWebログアナライザーで、*nixシステムのターミナルまたはブラウザを通じてインタラクティブに表示します。
- **graylog** - 無料でオープンソースのログ管理プラットフォームで、詳細なログ収集と分析をサポートしています。

有用なリソース:

- [ベストログ管理ツール: ログ管理、監視、分析などのための51の便利なツール](https://stackify.com/best-log-management-tools/)

</details>

<details>
<summary><b>開発者がサーバー上でアプリをデプロイするために、SSHを使ってプライベートキーを使用しています。なぜこれは不適切な行動であり、こういった状況でのより良い（しかし理想的ではない）解決策は何ですか？</b></summary><br>

プライベートキーは個人のアカウントのためのものです。サーバーはあなたの公開鍵が必要で、それにより、あなたが使用しようとしているアカウントのプライベートキーが認証されていることを確認できます。

プライベートキーの全目的は、それが「プライベート」であることです。つまり、あなただけがプライベートキーを持っているということです。もし誰かがあなたのプライベートキーを手に入れると、その人物はいつでもあなたになりすますことができるようになります。

より良い解決策は、SSHキー転送を使用することです。本質的には、`~/.ssh/config`ファイルを作成する必要があります。存在しない場合は、新しく作成します。そして、ホスト（ドメイン名またはIPアドレス）をファイルに追加し、`ForwardAgent yes`を設定します。例：

```bash
Host git.example.com
    User john
    PreferredAuthentications publickey
    IdentityFile ~/.ssh/id_rsa.git.example.com
    ForwardAgent yes
```

リモートサーバーはSSHエージェント転送を受け入れる必要があり、ローカルの`ssh-agent`が実行されている必要があります。

SSHエージェントの転送にはセキュリティリスクがあります。リモートマシン上の誰かが転送されたSSHエージェント接続にアクセスできる場合、その人はあなたの鍵を使用することができます。ただし、これはリモートマシンに鍵を保存するよりも良い方法です。攻撃者はSSHエージェント接続のみを使用でき、鍵自体にはアクセスできません。したがって、リモートマシンにログインしている間だけ、攻撃者は何かを行うことができます。リモートマシンに鍵を保存すると、攻撃者はそれをコピーしていつでも使用できるようになります。

SSH鍵を使用する場合は、鍵が偶発的に漏洩するリスクを減らすためにパスフレーズの使用を強くお勧めします。

有用なリソース:

- [SSHセッションでローカル鍵ペアを転送する方法](https://stackoverflow.com/questions/12257968/how-to-forward-local-keypair-in-a-ssh-session)
- [SSHエージェント転送の使用](https://developer.github.com/v3/guides/using-ssh-agent-forwarding/)
- [SSHエージェント転送は危険とみなされる](https://heipei.github.io/2015/02/26/SSH-Agent-Forwarding-considered-harmful/)
- [ssh-agent使用時のセキュリティ考慮事項](https://www.commandprompt.com/blog/security_considerations_while_using_ssh-agent/)

</details>

<details>
<summary><b>CORSとCSPsの違いは何ですか？</b></summary><br>

**CORS**（Cross-Origin Resource Sharing）は、ドメインに対して**同一オリジンポリシー**を緩和することを許可します。

例えば、通常ユーザーが`example.com`と`example.org`の両方にログインしている場合、同一オリジンポリシーは`example.com`が`example.org/current_user/full_user_details`へのAJAXリクエストを行い、その応答にアクセスすることを防ぎます。

これはウェブのデフォルトのポリシーで、同時に複数のサイトにログインしているときにユーザーのデータが漏洩するのを防ぎます。

**CORS**を使用すると、`example.org`はポリシーを設定して、`https://example.com`というオリジンがAJAXによって行われた応答を読み取ることを許可することができます。これは、`example.com`と`example.org`が同じ会社によって運営されていて、オリジン間でデータ共有が許可される場合に行います。これはクライアント側にのみ影響を与え、サーバー側には影響を与えません。

一方で、**CSPs**（Content Security Policies）は、現在のサイトで実行できるコンテンツのポリシーを設定します。例えば、JavaScriptがインラインで実行できるか、どのドメインから`.js`ファイルが読み込まれるかなどです。これは、攻撃者がHTMLページにスクリプトを挿入しようとする**XSS**攻撃に対して、別の防御線として役立ちます。通常、出力はエンコードされますが、開発者が出力フィールドの1つだけを忘れてしまった場合、ポリシーがインラインスクリプトの実行を防ぐため、攻撃が阻止されます。

有用なリソース:

- [CORSとCSPsの違いは何ですか？（原文）](https://stackoverflow.com/questions/39488241/what-is-the-difference-between-cors-and-csps)
- [CSP、SRI、およびCORS](https://colorblindprogramming.com/csp-sri-and-cors)

</details>

<details>
<summary><b><code>tcpdump</code>は何をしますか？インターフェースへの受信トラフィックのみをキャプチャするにはどうすればよいですか？</b></summary><br>

`tcpdump` は、最も強力で広く使用されているコマンドラインのパケットスニファーまたはパッケージアナライザーツールで、特定のインターフェースで受信または転送されたTCP/IPパケットをキャプチャまたはフィルタリングするために使用されます。

`tcpdump` はネットワークカードをプロミスキャスモードに設定します。これは、受信するすべてのパケットを受け入れるように指示するもので、ユーザーはネットワーク上で通過するすべてのトラフィックを確認できます。Wiresharkはパケットキャプチャにpcapを使用します。

インターフェースに到着するパケットのみを表示したい場合は、次のようにします：

- `-Q in` - Linux `tcpdump` バージョン用
- `-D in` - BSD `tcpdump` バージョン用

これらのパラメータは、どのパケットをキャプチャするかの送信/受信方向を設定します。

```bash
tcpdump -nei eth0 -Q in host 192.168.252.125 and port 8080
```

</details>

###### Devops Questions (7)

<details>
<summary><b>主要なDevOpsツールはどれですか？どのツールを使ったことがありますか？</b></summary><br>

最も人気のあるDevOpsツールは以下の通りです：

- **Git** : バージョン管理システムツール
- **Jenkins** : 継続的インテグレーションツール
- **Selenium** : 継続的テストツール
- **Puppet**, **Chef**, **Ansible** : 構成管理とデプロイメントツール
- **Nagios** : 継続的監視ツール
- **Docker** : コンテナ化ツール

</details>

<details>
<summary><b>これらのツールはどのように連携して動作しますか？</b></summary><br>

最も人気のあるDevOpsツールの連携の流れは以下の通りです：

- 開発者がコードを開発し、そのソースコードはGitなどのバージョン管理システムツールで管理されます。
- 開発者はこのコードをGitリポジトリに送信し、コードの変更はこのリポジトリにコミットされます。
- JenkinsはGitプラグインを使用してリポジトリからコードを取得し、AntやMavenなどのツールを使用してビルドします。
- Puppetのような構成管理ツールがテスト環境をデプロイおよびプロビジョニングし、Jenkinsがテスト環境にコードをリリースします。このテスト環境ではSeleniumなどのツールを使用してテストが行われます。
- コードがテストされた後、Jenkinsはそれを本番サーバーにデプロイします（本番サーバーもPuppetなどのツールでプロビジョニングおよび管理されます）。
- デプロイ後はNagiosのようなツールで継続的に監視されます。
- Dockerコンテナはビルド機能をテストするためのテスト環境を提供します。

</details>

<details>
<summary><b>Ansibleのプレイブックとは何ですか？</b></summary><br>

プレイブックは、Ansibleの構成、デプロイメント、およびオーケストレーション言語です。

プレイブックは、リモートシステムに強制したいポリシーや、一般的なITプロセスの一連の手順を記述することができます。プレイブックは人間が読みやすいように設計されており、基本的なテキスト言語で開発されます。

基本的なレベルでは、プレイブックはリモートマシンの構成やデプロイメントを管理するために使用できます。

</details>

<details>
<summary><b>NRPE（Nagios Remote Plugin Executor）とは何ですか？</b></summary><br>

**NRPE**アドオンは、リモートLinux/UnixマシンでNagiosプラグインを実行するために設計されています。これを行う主な理由は、Nagiosがリモートマシンの「ローカル」リソース（CPU負荷、メモリ使用量など）を監視できるようにするためです。

これらのパブリックリソースは通常外部マシンには公開されていないため、**NRPE**のようなエージェントをリモートLinux/Unixマシンにインストールする必要があります。

</details>

<details>
<summary><b>Nagiosにおけるアクティブチェックとパッシブチェックの違いは何ですか？</b></summary><br>

アクティブチェックとパッシブチェックの主要な違いは、アクティブチェックはNagiosによって開始され実行されるのに対し、パッシブチェックは外部アプリケーションによって実行される点です。

パッシブチェックは以下のようなサービスの監視に便利です：

- 非同期的な性質を持ち、定期的にそのステータスをポーリングして監視するのが効果的でないサービス。
- ファイアウォールの背後にあり、監視ホストからアクティブにチェックできないサービス。

アクティブチェックの主な特徴は以下の通りです：

- アクティブチェックはNagiosプロセスによって開始されます。
- アクティブチェックは定期的に実行されます。

</details>

<details>
<summary><b>サブモジュールを含めて<code>git clone</code>する方法は？</b></summary><br>

例えば:

```bash
# With -j8 - performance optimization
git clone --recurse-submodules -j8 git://github.com/foo/bar.git

# For already cloned repos or older Git versions
git clone git://github.com/foo/bar.git
cd bar
git submodule update --init --recursive
```

</details>

<details>
<summary><b>Redisを使用する利点は何ですか？<code>redis-cli</code>とは何ですか？</b></summary><br>

- 高速で動作する（他のものよりも非常に速い）
- サーバーサイドロッキングをサポート
- 多くのクライアントライブラリがある
- コマンドレベルでのアトミック操作（トランザクション操作）をサポート
- ハッシュ、セット、ビットマップなどの豊富なデータ型をサポート

`redis-cli`は**Redis**のコマンドラインインターフェースで、**Redis**にコマンドを送信し、サーバーから送られる返信を直接ターミナルで読み取ることができるシンプルなプログラムです。

役立つリソース:

- [Redisの10の利点](https://dzone.com/articles/10-traits-of-redis)

</details>

###### Cyber Security Questions (4)

<details>
<summary><b>XSSとは何か、どうやって対策しますか？</b></summary><br>

**クロスサイトスクリプティング (XSS)** とは、ウェブアプリケーションにおけるJavaScriptの脆弱性のことです。最も簡単に説明すると、ユーザーがクライアントサイドの入力フィールドにスクリプトを入力し、その入力が検証されずに処理されるケースです。これにより、信頼されていないデータが保存され、クライアントサイドで実行されてしまいます。

XSSへの対策としては、入力検証、CSP（コンテンツセキュリティポリシー）の実装などがあります。

</details>

<details>
<summary><b>HIDSとNIDSの違いは何ですか？どちらが優れていますか？</b></summary><br>

**HIDS**はホスト型侵入検知システムで、**NIDS**はネットワーク型侵入検知システムです。両者は似たような仕組みで動作しますが、配置場所が異なります。**HIDS**は各ホストに配置され、**NIDS**はネットワークに配置されます。エンタープライズ環境では**NIDS**が好まれます。なぜなら、**HIDS**は管理が難しく、ホストの処理能力を消費するためです。

</details>

<details>
<summary><b>コンプライアンスとは何ですか？</b></summary><br>

政府や独立機関、組織などによって定められた基準に従うことを指します。例えば、支払いに関連する情報を保存、処理、送信する業界は、PCI DSS（Payment Card Industry Data Security Standard）に準拠する必要があります。その他のコンプライアンスの例としては、組織が自社のポリシーに準拠することが挙げられます。

</details>

<details>
<summary><b>WAFとは何か、その種類は何ですか？</b></summary><br>

**WAF**はウェブアプリケーションファイアウォールの略です。これは、正当なトラフィックを悪意のあるトラフィックから分離して、アプリケーションを保護するために使用されます。**WAF**には、ボックスタイプとクラウドベースの2種類があります。

</details>

### :diamond_shape_with_a_dot_inside: <a name="senior-sysadmin">シニアシステム管理者</a>

###### システムに関する質問（61）

<details>
<summary><b>あなたが現在担当しているアーキテクチャを説明し、そのスケーラビリティやフォールトトレランスについて指摘してください。***</b></summary><br>

記入予定。

</details>

<details>
<summary><b>現在のプロダクション環境でコードがどのようにデプロイされているか教えてください。***</b></summary><br>

記入予定。

</details>

<details>
<summary><b>カーネルの種類とその違いを説明してください。</b></summary><br>

**モノリシックカーネル**

従来のこのタイプのカーネルアーキテクチャでは、プロセス管理やメモリ管理、割り込み処理などの基本的なシステムサービスがカーネル空間内の単一モジュールにまとめられていました。このアーキテクチャには、以下のような深刻な欠点がありました：

- カーネルのサイズが非常に大きい
- メンテナンス性が低く、新しい機能を追加したりバグ修正を行うたびに、カーネル全体を再コンパイルする必要があり、数時間かかることもある

現代のモノリシックアーキテクチャでは、カーネルは動的にロードおよびアンロードできる複数のモジュールで構成されています。このモジュラーアプローチにより、OSの機能を簡単に拡張できるようになり、特定のモジュールに変更やバグ修正があった場合、関連するモジュールだけをロードおよびアンロードするだけで済むため、カーネルのメンテナンスが非常に簡単になりました。

Linuxはモノリシックモジュラーアプローチを採用しています。

**マイクロカーネル**

このアーキテクチャは、モノリシックアプローチで制御できなかったカーネルコードの増大に対応するために開発されました。このアーキテクチャでは、デバイスドライバの管理、プロトコルスタック、ファイルシステムなどの基本的なサービスがユーザー空間で実行されます。

このアーキテクチャでは、OSの基本サービスがユーザー空間の一部となり、システム内の他のプログラムがこれらのサービスを利用する際に、プロセス間通信（IPC）を介してサーバーとして実行されます。

例: デバイスドライバ、ネットワークプロトコルスタック、ファイルシステム、グラフィックスなどにサーバーがあります。マイクロカーネルのサーバーは、他のプログラムと同様にデーモンプログラムですが、一部のサーバーには物理メモリの一部にアクセスできる特権が与えられています。

**ハイブリッドカーネル（モジュラーカーネル）**

これは上記の2つの組み合わせであり、OSサービスがカーネル空間に存在し、メッセージパッシングやパフォーマンスオーバーヘッドがなく、ユーザー空間でサービスを実行することによる信頼性の向上もありません。

これは、MicrosoftのNTカーネル（最新のWindowsバージョンまで）で使用されています。

役立つリソース:

- [カーネルの紹介: コンピューティングデバイスの心臓部（オリジナル）](https://keetmalin.wixsite.com/keetmalin/single-post/2017/08/24/An-Introduction-to-Kernels-The-Heart-of-Computing-Devices)

</details>

<details>
<summary><b>プログラムがライブラリの欠落エラーを返します。動的リンク可能なライブラリを提供するにはどうすればよいですか？</b></summary><br>

環境変数`LD_LIBRARY_PATH`は、ライブラリが最初に検索されるディレクトリのコロンで区切られたセットであり、標準のディレクトリセットの前に検索されます。これは、新しいライブラリのデバッグや特定の目的で非標準ライブラリを使用する場合に便利です。

`LD_LIBRARY_PATH`を使用する最良の方法は、コマンドラインまたはスクリプトでプログラムを実行する直前に設定することです。これにより、新しい`LD_LIBRARY_PATH`がシステムの他の部分から分離されます。

使用例:

```bash
export LD_LIBRARY_PATH="/list/of/library/paths:/another/path" ./program
```

役立つリソース:

- [LD_LIBRARY_PATHの正しい使用方法](http://wiredrevolution.com/system-administration/how-to-correctly-use-ld_library_path)

</details>

<details>
<summary><b>初心者の管理者がroot権限を安全に使用するための最も重要なルールを記述してください。 ***</b></summary><br>

未完了。

</details>

<details>
<summary><b>複数のシステム間でUID/GIDを同期する利点は何ですか？</b></summary><br>

ネットワーク全体でユーザー/UIDとグループ/GIDの管理を調整する主な理由はいくつかあります。

まず、比較的明白な理由は、ユーザーと管理者の便宜性に関係しています。

ネットワーク全体で各ユーザーがほぼ均等なアクセス権を持つことが期待される場合、ユーザーはそれぞれのシステムで同じユーザー名とパスワードが機能することを期待します。パスワードを変更した場合、その変更が全システムに適用されることを期待します。

また、UnixやLinuxの名前やグループ名とも関連しています。これらは数値形式（UIDとGID）にマッピングされます。すべてのファイル所有権（inode）やプロセスは、カーネルやドライバー全体でアクセスやアイデンティティの決定にこれらの数値を使用します。これらの数値は、情報を表示または処理するユーティリティによって対応するシンボリックな表現（名前）に逆マッピングされます。

UIDが再利用されないようにするポリシーを採用することも推奨されます。ユーザーが組織を退職する際には、そのUIDを「引退」させる（passwdを無効化し、グループマップから削除し、「シェル」を `/bin/denied` バイナリに設定し、ホームディレクトリをセキュアな _graveyard_ に設定する - 私のシステムでは `/home/.graveyard` を使用しています）。

これが明白でないかもしれませんが、数年間（または無期限に）アーカイブバックアップを維持する場合は、復元されたファイルが新しいユーザーの所有であることによる曖昧さや混乱を避けるためにUIDを再利用しないようにすることが望ましいです。

有用なリソース:

- [UID/GID Synchronization and Management (original)](https://linuxgazette.net/issue31/tag_uidgid.html)
- [What's the advantage of synchronizing UID/GID across Linux machines?](https://serverfault.com/questions/603987/whats-the-advantage-of-synchronizing-uid-gid-across-linux-machines)
- [How can I keep user accounts consistent across multiple machines?](https://unix.stackexchange.com/questions/141023/how-can-i-keep-user-acccounts-consistent-accross-multiple-machines)

</details>

<details>
<summary><b>システムのパフォーマンスチューニングに成功するための原則は何ですか？ ***</b></summary><br>

未完了。

有用なリソース:

- [An Introduction to Performance Tuning](https://www.oreilly.com/library/view/system-performance-tuning/059600284X/ch01.html)

</details>

<details>
<summary><b>BSDシステムにおける起動構成ファイルとディレクトリについて説明してください。</b></summary><br>

BSDでは、主要な起動構成ファイルは `/etc/defaults/rc.conf` です。システム起動スクリプト（例えば `/etc/rc` や `/etc/rc.d`）は、このファイルを含みます。

他のプログラムをシステム起動に追加したい場合は、`/etc/defaults/rc.conf` ではなく、`/etc/rc.conf` ファイルを変更する必要があります。

</details>

<details>
<summary><b>CPUがIO操作の完了に最も多くの時間を費やしている。どのツールを使用して、どのプロセスが具体的にIO待ちをしているか診断しますか？IO待ち時間を最小限にするにはどうすればよいですか？ ***</b></summary><br>

未完了。

有用なリソース:

- [Can anyone explain precisely what IOWait is?](https://serverfault.com/questions/12679/can-anyone-explain-precisely-what-iowait-is)

</details>

<details>
<summary><b>ジュニア開発者が誤って本番データベースを破壊しました。どのようにしてそのような状況を防ぐことができますか？</b></summary><br>

**災害復旧計画を作成する**

災害復旧と業務継続計画は、組織のリスク管理全体の重要な部分です。ビジネスITインフラを回復し保護するための文書化されたプロセスまたは手順のセットです。

回復ソリューションがない場合、復元の努力は、失われたものを再構築するための取り組みとなります。

実際に発生し得るデータ災害シナリオを使用して、バックアップが危機的な状況で何をするか、何をしないかをシミュレートするべきです。

**災害復旧センターを作成する**

結果として、主要な場所で計画外の中断が発生した場合、サービスとすべての運用活動がバックアップセンターに切り替えられ、サービスの停止が絶対的に最小限に抑えられます。

施設には、主要な災害時にスケールして増加した負荷に対処するための十分な帯域幅のオプションと電力がありますか？フェイルオーバーを定期的にテストするためのリソースはありますか？

**定期的なバックアップを作成し、テストする！**

バックアップはデータへの投資を保護する方法です。データの複数のコピーがあれば、一つが破損しても、失われたデータの復元コストだけで済みます。

データを失うと、確実なことは一つだけです：ダウンタイム。

バックアップの有効性と整合性を確保するためには、定期的な復元テストを実施することが重要です。理想的には、バックアップが完了するたびにテストを行い、データが正常に保護され回復できることを確認するべきですが、リソースの不足や時間の制約から、これが実践的でないことがよくあります。

仮想マシン全体や重要なコンポーネントのバックアップを作成します。

**スナップショットを作成する：vm、ディスク、またはlvm**

スナップショットは、サーバーを以前の状態に回復したい場合に最適ですが、「クイックメソッド」に過ぎず、多くの項目が変更された後にはシステムを復元できません。

本番環境で変更を行う前に常に作成してください（それだけでなく）。

ディスクスナップショットは、ディスク全体のスナップショットを生成するために使用されます。これらのスナップショットは、個々のデータのチャンク（例：失われたユーザーアカウント）を復元するのは簡単ではありませんが、可能です。主な目的は、ディスク障害が発生した場合にディスク全体を復元することです。

LVMスナップショットは、主に本番環境からステージング環境へのデータコピーに使用されます。

覚えておいてください：スナップショットはバックアップではありません！

**開発およびテスト環境**

本番環境は、会社やクライアントが使用するアプリケーションとそのデータベースの実際のインスタンスです。本番データベースにはすべての実際のデータが含まれています。

開発環境を本番データベースに直接基づいて設定するのではなく、バックアップを使用して（上記の必要性を排除します）。エンジニアがアクセスできる開発およびテスト環境と、承認された変更に従って更新をプッシュできる本番環境を作成します。

本番、開発、テストのすべての環境には、1つの主要な違いがあります：サービスのための認証データです。例えば、テスト環境のPostgreSQLデータベースインスタンスは、本番データベースと一貫性があるべきですが、データベース名やログイン、パスワードの認証エラーを排除するために異なるべきです。

**単一障害点**

単一障害点を避けるための一般的な方法は、必要なリソースの各コンポーネントに冗長性を提供することであり、これによりコンポーネントが故障してもサービスを継続できるようにします。

**データベースの同期および複製プロセス**

複製手順は非常に脆弱でエラーが発生しやすいです。

データ複製の遅延を少し長めに設定するのも良い考えです（例：DRC用）。レプリカでは、データ変更が通常数分以内に複製されるため、データが失われると、レプリカデータベースにもそのデータは存在しないことになります。

**ユーザー、ロール、権限を持つデータベースモデルを作成し、異なる保護方法を使用する**

非常に高度な開発者だけがDB管理者アクセス権を持っています。他の開発者はデータベースをクローンするための書き込みアクセス権を必要としません。その一方で、本番環境に対しては開発者に書き込みアクセス権を与えないでください。

本番データベースは、プロダクションアプリケーションを実行しているサーバーやPC以外のいかなるサーバーやPCからの接続も拒否するべきです。たとえ有効なユーザー名やパスワードを提供してもです。

開発マシンが本番データベースにアクセスできる理由は？データベースにアクセスする必要のあるサーバーだけにアクセスを許可するシンプルなファイアウォールルールを設定するのはどうですか？

**障害後のサマリー/ポストモーテム文書を作成する**

ポストモーテムの聴衆には、顧客、直属の部下、同僚、会社の経営陣、そしてしばしば投資家が含まれます。

障害の原因をタイムラインで説明します。すべてのインシデントは、特定の時間に特定のトリガーから始まり、通常は予期しない動作を引き起こします。例えば、サーバーが再起動され、期待通りに戻ることを期待していたが、そうならなかった場合です。

さらに、すべてのインシデントには根本原因があります：再起動自体がトリガーでしたが、ドライバーのバグが実際の障害を引き起こしました。最後に、すべてのインシデントには結果があります。最も明らかな結果は、サイトがダウンすることです。

ポストモーテムは、障害を防ぐために何ができたかという最も重要な質問に答えます。

障害がどれほど辛いものであったとしても、最悪のことはそれを隠し、明確で透明な方法でインシデントを適切に閉じないことです。

**もしあなたも大きなミスをした場合…**

  > "*人間はただのコンピュータを持った類人猿だ。" - african_cheetah (Reddit)
  >
  > "*絶対に必要でないものにアクセスできないことを感謝するようになった。" - warm_vanilla_sugar (Reddit)
  >
  > 何が起こったかをどこかに文書化してください。セットアップガイドを書いてください。失敗は教育的です。

有用なリソース:

- [Accidentally destroyed production database on first day of a job...](https://www.reddit.com/r/cscareerquestions/comments/6ez8ag/accidentally_destroyed_production_database_on/)
- [Postmortem of database outage of January 31](https://about.gitlab.com/2017/02/10/postmortem-of-database-outage-of-january-31/)
- [How to write an Incident Report/Postmortem](https://sysadmincasts.com/episodes/20-how-to-write-an-incident-report-postmortem)

</details>

<details>
<summary><b>Linuxサーバーで再起動せずに新しいディスクを追加する方法は？どのようにリスキャンしてLVMに追加しますか？</b></summary><br>

未完了。

有用なリソース:

- [How to Add New Disk in Linux CentOS 7 Without Rebooting](https://linoxide.com/linux-how-to/add-new-disk-centos-7-without-rebooting/)

</details>

<details>
<summary><b>プロセス管理のためにLinuxで使用される各システムコールについて説明してください。</b></summary><br>

プロセス管理のためのシステムコールはいくつかあります。これらは次の通りです：

- `fork()`: 新しいプロセスを作成するために使用されます。
- `exec()`: 新しいプロセスを実行するために使用されます。
- `wait()`: プロセスが待機するために使用されます。
- `exit()`: プロセスを終了または終了させるために使用されます。
- `getpid()`: 一意のプロセスIDを取得するために使用されます。
- `getppid()`: 親プロセスIDを確認するために使用されます。
- `nice()`: 現在実行中のプロセスの属性にバイアスをかけるために使用されます。

有用なリソース:

- [System Calls](http://faculty.salina.k-state.edu/tim/ossg/Introduction/sys_calls.html)

</details>

<details>
<summary><b>ルートファイルシステムをマウントできません。なぜですか？ ***</b></summary><br>

未完了。

有用なリソース:

- [What does "mounting a root file system" mean exactly?](https://superuser.com/questions/193918/what-does-mounting-a-root-file-system-mean-exactly)
- [How does a kernel mount the root partition?](https://unix.stackexchange.com/questions/9944/how-does-a-kernel-mount-the-root-partition)

</details>

<details>
<summary><b>100GBのファイルを削除する必要があります。どの方法が最も最適ですか？ ***</b></summary><br>

未完了。

有用なリソース:

- [Linuxで100GBのファイルを削除する際にIO/負荷を過剰にかけずに済む方法はありますか？](https://serverfault.com/questions/336917/is-there-a-way-to-delete-100gb-file-on-linux-without-thrashing-io-load)
- [数百万のファイルを持つディレクトリでのrmコマンド](https://serverfault.com/questions/183821/rm-on-a-directory-with-millions-of-files)

</details>

<details>
<summary><b>Linuxにおける割り込みと割り込みハンドラーについて説明してください。</b></summary><br>

以下は低レベル処理の高レベルな概要です。ここでは簡単な典型的なアーキテクチャについて説明していますが、実際のアーキテクチャはより複雑であったり、詳細レベルで異なる場合があります。

**割り込み**が発生すると、プロセッサは割り込みがマスクされているかどうかを確認します。マスクされている場合、割り込みが解除されるまで何も起こりません。割り込みが解除されると、もし保留中の割り込みがあれば、プロセッサはその中から一つを選びます。

次に、プロセッサは割り込みを実行するために、メモリ内の特定のアドレスに分岐します。そのアドレスにあるコードを**割り込みハンドラー**と呼びます。プロセッサがそこに分岐すると、割り込みをマスクし（割り込みハンドラーが排他的に制御できるようにし）、一部のレジスタの内容をどこかに保存します（通常は他のレジスタ）。

割り込みハンドラーは必要な処理を行います。通常は、割り込みを引き起こした周辺機器と通信してデータの送受信を行います。もし割り込みがタイマーによって引き起こされた場合、ハンドラーはOSスケジューラーをトリガーして異なるスレッドに切り替えるかもしれません。ハンドラーが実行を終えると、保存されたレジスタを復元し、割り込みを解除する特別な割り込みから戻る命令を実行します。

割り込みハンドラーは迅速に実行する必要があります。なぜなら、他の割り込みが実行されるのを防いでいるからです。Linuxカーネルでは、割り込み処理は2つの部分に分かれています：

- 「上半分（top half）」は割り込みハンドラーです。最小限の処理を行い、通常はハードウェアとの通信やカーネルメモリ内のフラグ設定を行います。
- 「下半分（bottom half）」はその他の必要な処理を行います。例えば、データをプロセスメモリにコピーしたり、カーネルデータ構造を更新するなどです。これは時間がかかってもよく、他のシステムの一部が待機することもできます（割り込みが有効な状態で実行されるため）。

有用なリソース:

- [Linuxでの割り込み処理方法 (原文)](https://unix.stackexchange.com/questions/5788/how-is-an-interrupt-handled-in-linux)
- [割り込みと割り込みハンドラー](https://notes.shichao.io/lkd/ch7/)

</details>

<details>
<summary><b>高可用性アプリケーションを設計する際に考慮すべき点は、アーキテクチャレベルとアプリケーションレベルの両方でどのようなものがありますか？ ***</b></summary><br>

未完了。

</details>

<details>
<summary><b>inodeに格納されているフィールドはどれですか？</b></summary><br>

POSIXシステム内では、ファイルには次の属性があり、`stat` システムコールによって取得できます：

- **デバイスID**（これはファイルを含むデバイスを識別します。つまり、シリアル番号の一意性の範囲です。）

- **ファイルモード**（ファイルの種類と、ファイルの所有者、そのグループ、および他のユーザーがファイルにどのようにアクセスできるかを決定します）
- **リンクカウント**（inodeを指すハードリンクの数を示します）
- ファイルの**ユーザーID**
- ファイルの**グループID**
- ファイルがデバイスファイルの場合、その**デバイスID**
- ファイルの**サイズ**（バイト単位）
- **タイムスタンプ**（inode自体が最後に変更された時刻（ctime、inode変更時間）、ファイル内容が最後に変更された時刻（mtime、修正時間）、最後にアクセスされた時刻（atime、アクセス時間））
- 推奨される**I/Oブロックサイズ**
- このファイルに割り当てられた**ブロックの数**

有用なリソース:

- [Inodes - 入門](http://www.grymoire.com/Unix/Inodes.html)

</details>

<details>
<summary><b>一般ユーザーは <code>/etc/passwd</code> を読むことができます。これはセキュリティホールですか？他のパスワードシャドウイングスキームをご存知ですか？</b></summary><br>

通常、ハッシュ化されたパスワードは、ほとんどのLinuxシステムで `/etc/shadow` に保存されます：

```bash
-rw-r----- 1 root shadow 1349 2016-07-03 03:54 /etc/shadow
```

BSDシステムでは、`/etc/master.passwd` に保存されます。

認証を実行する必要があるプログラムは、引き続き `root` 権限で実行する必要があります：

```bash
-rwsr-xr-x 1 root root 42792 2016-02-14 14:13 /usr/bin/passwd
```

`setuid root` プログラムやシステム上のすべてのハッシュ化されたパスワードを含む単一のファイルが気に入らない場合は、**Openwall TCB PAM モジュール**を使用できます。これにより、各ユーザーに自分専用のファイルが提供され、ハッシュ化されたパスワードを保存することができます。その結果、システム上の `setuid root` プログラムの数を大幅に削減することができます。

有用なリソース:

- [一般ユーザーが /etc/passwd を読むことができるのはセキュリティホールですか？ (原文)](https://serverfault.com/questions/286654/ordinary-users-are-able-to-read-etc-passwd-is-this-a-security-hole/286657#286657)
- [tcb - /etc/shadow の代替](https://www.openwall.com/tcb/)
- [なぜパスワードファイルをシャドウ化するのか？](https://www.tldp.org/HOWTO/Shadow-Password-HOWTO-2.html)

</details>

<details>
<summary><b>systemdをSysV initの代わりに使用する主な利点は何ですか？ ***</b></summary><br>

未完了。

</details>

<details>
<summary><b>ファイルが変更されるたびにコマンドを実行する方法は？</b></summary><br>

例えば：

```bash
while inotifywait -e close_write filename ; do

  echo "changed" >> /var/log/changed

done
```

</details>

<details>
<summary><b>大量のデータをコピーする必要があります。最も効果的な方法を説明してください。 ***</b></summary><br>

未完了。

有用なリソース:

- [大量のディレクトリツリーをローカルでコピーする場合、cpとrsyncのどちらを使用するか？](https://serverfault.com/questions/43014/copying-a-large-directory-tree-locally-cp-or-rsync)

</details>

<details>
<summary><b>LVMの危険性と注意点について教えてください。</b></summary><br>

**LVMのリスク**

- SSDやVMハイパーバイザーでの書き込みキャッシュ問題に脆弱
- ディスク上の構造が複雑なため、データの回復が困難
- ファイルシステムのサイズ変更が難しい
- スナップショットの使用が難しく、遅く、バグが多い
- これらの問題に対処するために、正しく設定するには一定のスキルが必要

有用なリソース:

- [LVMの危険性と注意点 (原文)](https://serverfault.com/questions/279571/lvm-dangers-and-caveats)

</details>

<details>
<summary><b>会社のPython開発チームがuwsgiとgunicornのどちらを選ぶかで悩んでいます。管理者の視点からそれぞれのソリューションの利点と欠点は何ですか？ ***</b></summary><br>

未完了。

有用なリソース:

- [uWSGI vs. Gunicorn、またはPythonをNodeよりも速くする方法](https://blog.kgriffs.com/2012/12/18/uwsgi-vs-gunicorn-vs-node-benchmarks.html)

</details>

<details>
<summary><b>もし <code>kill -9</code> が機能しない場合、どうしますか？ SIGKILLの使用が不十分な例外について説明してください。</b></summary><br>

`kill -9`（`SIGKILL`）は、プロセスを終了させるための権限がある限り、常に機能します。基本的には、プロセスはあなたによって開始され、setuidまたはsetgidでない限り、またはあなたがrootである必要があります。一つの例外があります：rootであってもPID 1（initプロセス）には致命的なシグナルを送信できません。

しかし、`kill -9` が即座に機能する保証はありません。すべてのシグナル、`SIGKILL`を含む、は非同期的に配信されます：カーネルがシグナルを配信するのに時間がかかることがあります。通常、シグナルの配信は数マイクロ秒以内に完了し、ターゲットがタイムスライスを取得するのにかかる時間だけです。しかし、ターゲットがシグナルをブロックしている場合、シグナルはターゲットが解除するまでキューに格納されます。

通常、プロセスは`SIGKILL`をブロックすることはできません。しかし、カーネルコードは可能であり、プロセスはシステムコールを呼び出すとカーネルコードを実行します。

システムコールでブロックされたプロセスは、非割り込みスリープ状態です。`ps`や`top`コマンドは、（ほとんどのUnix系システムで）**D** 状態で表示されます。

**D** 状態のプロセスを削除するには、プロセスが非割り込み状態であるため、自動的にシステムによって処理されない限り、マシンを再起動することで問題を解決できます。

通常、プロセスが長時間**D** 状態になる可能性は非常に低いです。もしそうなる場合、システムで何かが適切に処理されていないことがあります。これは潜在的なバグである可能性もあります。

長時間の非割り込みスリープの古典的なケースは、サーバーが応答しないときにNFS経由でファイルにアクセスしているプロセスです。現代の実装では、非割り込みスリープを課さない傾向があります（例：Linuxでは、`intr`マウントオプションにより、NFSファイルアクセスを中断できるようになります）。

`ps`や`top`の出力に**Z**（またはLinuxでは**H**）とマークされたエントリを時々見ることがあります。これらは技術的にはプロセスではなく、ゾンビプロセスであり、プロセステーブルのエントリに過ぎません。親プロセスが子プロセスの終了を通知されるまで保持されます。親プロセスがそれに注意を払うと（または終了すると）消えます。

要約の例外:

- ゾンビプロセスは、すでに死亡しており、親プロセスがそれを処理するのを待っているため、終了することはできません
- ブロック状態のプロセスは、再び目覚めるまで死にません
- initプロセスは特別です：処理したくないシグナルを受け取らないため、**SIGKILL**を無視することができます。この例外の例外は、Linuxでinitがptracedされているときです
- 非割り込みスリープ状態のプロセスは、**SIGKILL**が送信されても終了しない可能性があります。これは、Unixシステムが一時的なソフトウェア問題を解決するために再起動する必要がある数少ないケースの1つです

有用なリソース:

- [kill -9 が機能しない場合はどうするか？ (原文)](https://unix.stackexchange.com/questions/5642/what-if-kill-9-does-not-work)
- [kill -9 が効果がない場合にプロセスを終了させる方法](https://serverfault.com/questions/458261/how-to-kill-a-process-in-linux-if-kill-9-has-no-effect)
- [プロセスをkill -9 で終了させるべきではない場合](https://unix.stackexchange.com/questions/8916/when-should-i-not-kill-9-a-process)
- [SIGTERM vs. SIGKILL](https://major.io/2010/03/18/sigterm-vs-sigkill/)

</details>

<details>
<summary><b><code>nohup</code>、<code>disown</code>、<code>&</code> の違い。すべてを一緒に使用した場合にどうなりますか？</b></summary><br>

- `&` はジョブをバックグラウンドで実行し、入力の読み込みをブロックし、シェルがジョブの完了を待たないようにします
- `disown` はプロセスをシェルのジョブ制御から削除しますが、ターミナルへの接続は維持されます。これにより、シェルはプロセスに**SIGHUP**を送信しなくなります。明らかに、これはバックグラウンドジョブにのみ適用されるため、フォアグラウンドジョブが実行中にこの操作を行うことはできません
- `nohup` はプロセスをターミナルから切り離し、その出力を `nohup.out` にリダイレクトし、**SIGHUP** から保護します。効果の1つ（名前に関連するもの）は、プロセスが送信された**SIGHUP**を受け取らなくなることです。ジョブ制御とは完全に独立しており、原理的にはフォアグラウンドジョブにも使用できます（ただし、あまり便利ではありません）

これらをすべて一緒に使用すると、プロセスはバックグラウンドで実行され、シェルのジョブ制御から削除され、ターミナルから効果的に切り離されます。

有用なリソース:

- [nohup、disown、& の違い (原文)](https://unix.stackexchange.com/questions/3886/difference-between-nohup-disown-and)

</details>

<details>
<summary><b><code>chroot</code> の主な利点は何ですか？いつ、なぜ使用しますか？chroot 環境での mount dev、proc、sys の目的は何ですか？</b></summary><br>

chroot環境の利点は、ファイルシステムが物理ホストから完全に隔離されることです。`chroot` はファイルシステム内に別のファイルシステムを持ちますが、その違いは新しく作成されたルート（/）をルートディレクトリとして使用する点です。

chroot監獄は、プロセスとその子プロセスをシステムの残りから隔離する方法です。rootでないプロセスにのみ使用すべきであり、rootユーザーは監獄から簡単に抜け出すことができます。

アイデアは、プロセスが実行するのに必要なすべてのシステムファイルをコピーまたはリンクして、ディレクトリツリーを作成することです。その後、`chroot()` システムコールを使用して、この新しいツリーの基部にルートディレクトリを変更し、そのchroot環境内でプロセスを実行します。実際には修正されたルートの外部のパスを参照できないため、これらの場所で悪意のある操作（読み取り/書き込みなど）を行うことはできません。

Linuxでは、バインドマウントを使用してchrootツリーを補完するのが素晴らしい方法です。これを使用すると、例えば `/usr` を引っ張らずに `/lib` や `/usr/lib` のようなフォルダを取り込むことができます。必要なディレクトリツリーを監獄ディレクトリ内に作成したディレクトリにバインドしてください。

chroot環境は以下の目的に有用です:

- ブートローダーの再インストール
- 忘れたパスワードのリセット
- カーネルのアップグレード（またはダウングレード）
- initramdiskの再構築
- **/etc/fstab** の修正
- パッケージマネージャーを使用したパッケージの再インストール
- その他

chroot環境で作業する際には、すべてのプログラムが適切に動作するようにいくつかの特別なファイルシステムをマウントする必要があります。

制限として、`/dev`、`/sys`、および `/proc` はデフォルトではマウントされておらず、多くのタスクには必要です。

有用なリソース:

- [Chrootについて](https://medium.com/@itseranga/chroot-316dc3c89584)
- [UNIX chroot() 操作のベストプラクティス](http://www.unixwiz.net/techtips/chroot-practices.html)
- [バインドマウントよりも簡単なchroot方法はありますか？](https://askubuntu.com/questions/32418/is-there-an-easier-way-to-chroot-than-bind-mounting)
- [壊れたLinuxインストールを回復するためにchrootを準備する適切な方法は？](https://superuser.com/questions/111152/whats-the-proper-way-to-prepare-chroot-to-recover-a-broken-linux-installation)

</details>

<details>
<summary><b>セグメンテーション違反（セグフォルト）とは何ですか？それが発生する原因を特定する方法は？</b></summary><br>

**セグメンテーション違反**（通称 _セグフォルト_）は、プログラムがクラッシュする一般的な状態です。セグフォルトは、プログラムが不正なメモリ位置を読み書きしようとすることによって引き起こされます。

プログラムのメモリは、異なるセグメントに分かれています：

- プログラム命令のためのテキストセグメント
- コンパイル時に定義された変数や配列のためのデータセグメント
- サブルーチンや関数で定義された一時的（または自動的）変数のためのスタックセグメント
- `malloc`（C言語の関数）など、実行時に関数によって割り当てられた変数のためのヒープセグメント

実際には、セグフォルトはほぼ常に存在しない配列要素を読み書きしようとしたり、ポインタを使用する前に適切に定義していなかったり、（Cプログラムでは）変数の値をアドレスとして誤って使用することが原因です。したがって、プロセスAがメモリ位置0x877を読み取ると、プロセスBが自分の0x877を読み取るときとは異なる物理RAM位置の情報が読み取られます。

すべての現代的なオペレーティングシステムはセグメンテーションをサポートしており、セグメンテーション違反を発生させる可能性があります。

セグメンテーション違反が発生する状況には以下が含まれます：

- バグのあるプログラム/コマンドで、パッチを適用することで修正可能
- Cプログラミングで配列の終端を超えてアクセスしようとした場合
- chrootされた環境内で、重要な共有ライブラリ、設定ファイル、または `/dev/` エントリが欠けている場合
- ハードウェアや不良メモリ、ドライバの問題も原因になることがある
- コンピュータ機器の推奨環境を維持する（過熱も問題を引き起こす可能性がある）

このようなエラーをデバッグするには、以下の技術のいずれかまたはすべてを試してみてください：

- コアファイルを有効にする： `$ ulimit -c unlimited`
- クラッシュを再現する： `$ ./<program>`
- gdbでクラッシュをデバッグする： `$ gdb <program> [core file]`
- または `LD_PRELOAD=...path-to.../libSegFault.so <program>` を実行して、バックトレース、ロードされたライブラリなどのレポートを取得する

また：

- 正しいハードウェアがインストールされ、設定されていることを確認する
- すべてのパッチを適用し、システムを最新の状態に保つ
- ジェイル内にすべての依存関係がインストールされていることを確認する
- Apacheなどのサポートされているサービスでコアダンプを有効にする
- `strace` を使用することは、診断、教育、デバッグに役立つツールです

時には、セグメンテーション違反はプログラムのバグではなく、システムメモリ制限が低すぎることが原因です。通常、このような問題を引き起こすのはスタックサイズの制限です（スタックオーバーフロー）。メモリ制限を確認するには、bashで `ulimit` コマンドを使用してください。

有用なリソース：

- [セグメンテーション違反（セグフォルト）とは何ですか？それが発生する原因を特定する方法は？（原文）](https://kb.iu.edu/d/aqsj)
- [Linuxでのセグメンテーション違反とは？](https://stackoverflow.com/questions/3200526/what-is-a-segmentation-fault-on-linux)
- [再帰的なbash関数を呼び出すときのセグメンテーション違反](https://unix.stackexchange.com/questions/296641/segmentation-fault-when-calling-a-recursive-bash-function)
- [セグメンテーション違反/エラーのトラブルシューティング](http://web.mit.edu/10.001/Web/Tips/tips_on_segmentation.html)
- [SIGABRTのバックトレースを取得するためにlibSegFault.soを使用できますか？](https://stackoverflow.com/questions/18706496/can-one-use-libsegfault-so-to-get-backtraces-for-sigabrt)

</details>

<details>
<summary><b>あるプロセスが遅いです。どのようにして実行時間を確認し、どのツールを使用しますか？</b></summary><br>

未完了。

有用なリソース：

- [プロセスの実行時間を確認する方法](https://unix.stackexchange.com/questions/7870/how-to-check-how-long-a-process-has-been-running)
- [Linuxでプロセスの実行時間を確認する方法](https://www.cyberciti.biz/faq/how-to-check-how-long-a-process-has-been-running/)
- [現在の時間にプロセスによって実行されているシステムコールを見る方法](https://stackoverflow.com/questions/42677724/how-to-see-system-call-that-executed-in-current-time-by-process)

</details>

<details>
<summary><b>Linuxのファイルディスクリプタとは何ですか？</b></summary><br>

Unixおよび関連するコンピュータオペレーティングシステムでは、ファイルディスクリプタ（FD、まれに fildes）は、ファイルやパイプ、ネットワークソケットなどの他の入力/出力リソースにアクセスするために使用される抽象的なインジケータ（ハンドル）です。ファイルディスクリプタは、POSIXアプリケーションプログラミングインターフェースの一部を形成します。

</details>

<details>
<summary><b>ランダムなエントロピープールを追加で供給する方法としてどれをお勧めしますか？それを改善する方法は？</b></summary><br>

`/dev/random` ではなく、`/dev/urandom` を使用するべきです。`/dev/random` と `/dev/urandom` の違いは以下の通りです：

- `/dev/random` は理論的には情報理論的に安全なアルゴリズムの文脈ではより良いかもしれません。これは今日の技術だけでなく、明日の技術、エイリアンが使う技術、そして神自身のiPadに対しても安全なアルゴリズムです。

- `/dev/urandom` はブロックしませんが、`/dev/random` はブロックする可能性があります。`/dev/random` は「どれだけのエントロピーが残っているか」をカウントしており、そのカウントが失われたエントロピービットとして扱われます。ブロックは非常に現実的な問題を引き起こす可能性があり、たとえば、SSHサーバーのキー作成でスタックするために自動インストール後にサーバーがブートしないことがあります。

したがって、`/dev/urandom` を使用して、このエントロピーの問題を心配しないでください。

トリックは、`/dev/urandom` は決してブロックしないことです。たとえブロックすべきであっても、`/dev/urandom` は最後のブートから十分な「初期エントロピー」バイト（32ランダムバイトが十分）を受け取っている限り安全です。通常のLinuxインストールでは、インストール時にランダムシード（`/dev/random` から）を作成し、ディスクに保存します。各再起動時に、シードが読み取られ、`/dev/urandom` に供給され、新しいシードが直ちに生成されて置き換えられます（`/dev/urandom` から）。これにより、`/dev/urandom` は常に暗号的に強いランダムデータを生成するのに十分な初期エントロピーを持つことが保証され、パスワード生成などの一般的な暗号作業に完全に十分です。

これらのデーモンのいずれかが、すべての利用可能なエントロピーが枯渇した場合にランダム性を必要とする場合、それらはより多くのエントロピーを待つために一時停止することがあり、これがアプリケーションに過度の遅延を引き起こす可能性があります。さらに悪いことに、ほとんどの現代のアプリケーションは、プログラムの初期化時に作成された独自のランダムシードを使用するか、`/dev/urandom` を使用してブロックを回避します。その結果、アプリケーションは低品質のランダムデータに悩まされ、セキュアな通信の整合性に影響を与える可能性があり、プライベートデータに対する暗号解析の可能性が高くなります。

現在のエントロピーのバイト数を確認するには、以下を使用します：

```bash
cat /proc/sys/kernel/random/entropy_avail
```

**rng-tools**

Fedora/Rh/Centos系: `sudo yum install rng-tools`。

Deb系: `sudo apt-get install rng-tools` でセットアップします。

その後、鍵生成前に `sudo rngd -r /dev/urandom` を実行します。

**haveged**

Fedora/Rh/Centos系: `sudo yum install haveged` し、`/etc/rc.local` に `/usr/local/sbin/haveged -w 1024` を追加します。

Deb系: `sudo apt-get install haveged` し、`/etc/default/haveged` に `DAEMON_ARGS="-w 1024"` を追加してセットアップします。

その後、鍵生成前に `sudo rngd -r /dev/urandom` を実行します。

有用なリソース：

- [/dev/random エントロピープールへの供給方法は？（原文）](https://security.stackexchange.com/questions/89/feeding-dev-random-entropy-pool)
- [GPGに十分なエントロピーがない](https://serverfault.com/questions/214605/gpg-does-not-have-enough-entropy)

</details>

<details>
<summary><b><code>/sbin/nologin</code>、<code>/bin/false</code>、および <code>/bin/true</code> の違いは何ですか？</b></summary><br>

`/sbin/nologin` がシェルとして設定されていると、そのシェルを持つユーザーがログインしようとした際に「このアカウントは現在利用できません」という丁寧なメッセージが表示されます。

`/bin/false` は、呼び出されるとすぐに終了し、false を返すバイナリです。したがって、false をシェルとして持つユーザーがログインすると、false が終了する際に即座にログアウトします。`/bin/true` をシェルとして設定するのもログインを許可しないという同じ効果がありますが、false の方がシェルがないことを伝えるのに適しているため、true よりも一般的に使用されます。

`/bin/nologin` はよりユーザーフレンドリーなオプションで、ログインを試みるユーザーにカスタマイズ可能なメッセージが表示されます。理論的にはこれを使用したいですが、nologin と false のどちらも、ユーザーがシェルを持たず、ssh でログインできないという最終的な結果は同じです。

有用なリソース：

- [/sbin/nologin と /bin/false の違いは？](https://unix.stackexchange.com/questions/10852/whats-the-difference-between-sbin-nologin-and-bin-false)
- [なぜ一部のシステムユーザーはシェルとして /usr/bin/false を持っているのか？](https://superuser.com/questions/1183311/why-do-some-system-users-have-usr-bin-false-as-their-shell)

</details>

<details>
<summary><b>ディスクのボトルネックに悩まされているかもしれない症状は何ですか？ ***</b></summary><br>

未完了。

</details>

<details>
<summary><b>FreeBSD におけるエラー <code>maxproc limit exceeded by uid %i ...</code> の意味は何ですか？</b></summary><br>

FreeBSD のカーネルは、一度に存在できるプロセスの数に制限があります。この数値は **kern.maxusers** 変数に基づいています。

**kern.maxusers** はネットワークバッファなど、カーネル内のさまざまな制限にも影響します。マシンが重負荷である場合は、**kern.maxusers** を増やしてください。これにより、プロセスの最大数に加えて、これらの他のシステム制限も増加します。

**kern.maxusers** の値を調整するには、ハンドブックのファイル/プロセス制限セクションを参照してください。そのセクションはオープンファイルに言及していますが、プロセスにも同じ制限が適用されます。

マシンが軽負荷であるが非常に多くのプロセスを実行している場合は、`/boot/loader.conf` で **kern.maxproc** のチューニングパラメータを定義して調整してください。

</details>

<details>
<summary><b>ファイルを1行ずつ読み込み、値を変数に代入する方法は？</b></summary><br>

例えば：

```bash
while IFS='' read -r line || [[ -n "$line" ]] ; do
  echo "Text read from file: $line"
done < "/path/to/filename"
```

説明：

- `IFS=''`（または `IFS=`）は、前後の空白がトリムされるのを防ぎます。
- `-r` はバックスラッシュエスケープの解釈を防ぎます。
- `|| [[ -n $line ]]` は、最後の行が `\n` で終わっていない場合でも無視されないようにします（`read` が EOF に遭遇すると非ゼロの終了コードを返すため）。

有用なリソース：

- [ファイルを1行ずつ読み込み、値を変数に代入する方法](https://stackoverflow.com/questions/10929453/read-a-file-line-by-line-assigning-the-value-to-a-variable)

</details>

<details>
<summary><b>クライアントがサイトのスコアがssllabsスキャナーでBだったと報告しています。SSL構成のベストプラクティスのチェックリストを準備してください。 ***</b></summary><br>

有用なリソース：

- [完璧なSSL Labsスコアを取得する方法](https://michael.lustfield.net/nginx/getting-a-perfect-ssl-labs-score)
- [ssllabs.com/ssltest/を改善するための17の小さな提案](https://community.qualys.com/thread/14023)
- [Let's EncryptとNginxを使用してSSL Labsテストですべてのカテゴリで100点を取得し、A+をスコアする方法は？](https://stackoverflow.com/questions/41930060/how-do-you-score-a-with-100-on-all-categories-on-ssl-labs-test-with-lets-encry)

</details>

<details>
<summary><b>「CPUジャンプ」とは何を意味しますか？</b></summary><br>

OSは非常に忙しいもので、何かをしているとき（そして何もしていないときも）特にそうです。アクティブな企業環境では、常に何かが進行しています。

この活動のほとんどは「バースティー（burst）」であり、プロセスは通常は静止していて、短い期間の激しい活動があります。これはネットワークベースの活動（例えばPHPリクエストの処理）にも当てはまりますが、OSのメンテナンス（例えばファイルシステムのメンテナンス、ページの回収、ディスクI/Oリクエスト）にも当てはまります。

多くのバースティーなプロセスがある状況では、非常に不規則でスパイキーなCPU使用率のプロットが得られます。

`500 - Internal Server Error` で示されるように、高い数のコンテキストスイッチは状況をさらに悪化させるでしょう。

有用なリソース：

- [「CPUジャンプ」とは何を意味しますか？（原文）](https://stackoverflow.com/questions/32185607/what-does-cpu-jumps-mean)

</details>

<details>
<summary><b>Linuxでシステムコールをトレースする方法は？考えられる方法を説明してください。</b></summary><br>

**SystemTap**

これは最も強力な方法です。コールの引数も表示できます：

使用方法：

```bash
sudo apt-get install systemtap
sudo stap -e 'probe syscall.mkdir { printf("%s[%d] -> %s(%s)\n", execname(), pid(), name, argstr) }'
```

そして他のターミナルで:

```bash
sudo rm -rf /tmp/a /tmp/b
mkdir /tmp/a
mkdir /tmp/b
```

出力例:

```bash
mkdir[4590] -> mkdir("/tmp/a", 0777)
mkdir[4593] -> mkdir("/tmp/b", 0777)
```

**`strace`コマンドを`-f|-ff`パラメータ付きで**

このように`-f`や`-ff`オプションをつけることができます:

```bash
strace -f -e trace=process bash -c 'ls; :
```

- `-f` : 現在トレースされているプロセスによって `fork(2)` システムコールの結果として作成された子プロセスもトレースします。

- `-ff` : `-o` ファイル名オプションが有効な場合、各プロセスのトレースは `filename.pid` に書き込まれます。ここで `pid` は各プロセスの数値プロセスIDです。これは `-c` と互換性がなく、プロセスごとのカウントが保持されないためです。

**`ltrace -S` はシステムコールとライブラリコールの両方を表示します**

この素晴らしいツールは、実行ファイルが何をしているのかさらに詳しく見ることができます。

**`ftrace` の最小限の実行可能な例**

以下は最小限の実行可能な例です。`sudo` を使って実行してください。

```bash
#!/bin/sh
set -eux

d=debug/tracing

mkdir -p debug
if ! mountpoint -q debug; then
  mount -t debugfs nodev debug
fi

# トレイシングをやめる
echo 0 > "${d}/tracing_on"

# 前回のトレイシングを消去
echo > "${d}/trace"

# とレイザー名を探す
cat "${d}/available_tracers"

# トレイシング機能を無効化し、システムコールイベントだけ表示する
echo nop > "${d}/current_tracer"

# イベント名とともに表示
grep mkdir "${d}/available_events"

# mkdirのトレースを有効にする:
# 以下の2つの文はは全く同じことをする
# ただインターフェースが違うだけ
# https://www.kernel.org/static/html/v4.18/trace/events.html
echo sys_enter_mkdir > "${d}/set_event"
# echo 1 > "${d}/events/syscalls/sys_enter_mkdir/enable"

# トレイシングを開始する
echo 1 > "${d}/tracing_on"

# 2つの異なるプロセスによる2つのmkdirコールの生成
rm -rf /tmp/a /tmp/b
mkdir /tmp/a
mkdir /tmp/b

# トレイスの表示
cat "${d}/trace"

# トレイスの停止
echo 0 > "${d}/tracing_on"

umount debug
```

出力のサンプル:

```bash
# tracer: nop
#
#                              _-----=> irqs-off https://sourceware.org/systemtap/documentation.html
#                             / _----=> need-resched
#                            | / _---=> hardirq/softirq
#                            || / _--=> preempt-depth
#                            ||| /     delay
#           TASK-PID   CPU#  ||||    TIMESTAMP  FUNCTION
#              | |       |   ||||       |         |
            mkdir-5619  [005] .... 10249.262531: sys_mkdir(pathname: 7fff93cbfcb0, mode: 1ff)
            mkdir-5620  [003] .... 10249.264613: sys_mkdir(pathname: 7ffcdc91ecb0, mode: 1ff)
```

この方法の一つのクールな点は、システム上のすべてのプロセスの関数呼び出しを一度に表示できることです。ただし、`set_ftrace_pid` を使って興味のある PID をフィルタリングすることもできます。

有用なリソース:

- [Linuxでシステムコールをトレースする方法は？（原文）](https://stackoverflow.com/questions/29840213/how-do-i-trace-a-system-call-in-linux)
- [ftraceはLinuxカーネルに対するシステムコールの引数をキャプチャできますか、それとも関数名だけですか？](https://stackoverflow.com/questions/27608752/does-ftrace-allow-capture-of-system-call-arguments-to-the-linux-kernel-or-only)
- [ftraceでシステムコールイベントだけをトレースし、Linuxカーネルの他の関数を表示しない方法は？](https://stackoverflow.com/questions/52764544/how-to-trace-just-system-call-events-with-ftrace-without-showing-any-other-funct)
- [Linuxでライブラリをロードするために使用されるシステムコールは何ですか？](https://unix.stackexchange.com/questions/226524/what-system-call-is-used-to-load-libraries-in-linux)

</details>

<details>
<summary><b>ディレクトリから一部を除くすべてのファイルを削除するには？</b></summary><br>

解決策1 - `extglob`をつける:

```bash
shopt -s extglob
rm !(textfile.txt|backup.tar.gz|script.php|database.sql|info.txt)
```

解決策2 -`find`をつける:

```bash
find . -type f -not -name '*txt' -print0 | xargs -0 rm --
```

</details>

<details>
<summary><b>文字列にサブ文字列が含まれているかをBashで確認するにはどうすればよいですか？</b></summary><br>

`*`（ワイルドカード）を使って、case文の外でも確認することができます。ただし、ダブルブラケットを使用する必要があります。

```bash
string='some text'
if [[ $string = *"My long"* ]] ; then
  true
fi
```

</details>

<details>
<summary><b><code>2>&-</code>、<code>2>/dev/null</code>、<code>|&</code>、<code>&>/dev/null</code>、および <code>>/dev/null 2>&1</code> の違いを説明してください。</b></summary><br>

- **番号 1** = 標準出力（`STDOUT`）
- **番号 2** = 標準エラー（`STDERR`）
- 明示的に番号が指定されていない場合、シェル（bash）はデフォルトで**番号 1**を使用します。

これらの機能について説明します。

`2>&-`

一般的な形式は `M>&-` で、ここで **"M"** はファイルディスクリプタ番号です。これは、指定されたファイルディスクリプタ **"M"** の出力を閉じます。

`2>/dev/null`

一般的な形式は `M>/dev/null` で、ここで **"M"** はファイルディスクリプタ番号です。これは、ファイルディスクリプタ **"M"** の出力を `/dev/null` にリダイレクトします。

`2>&1`

一般的な形式は `M>&N` で、ここで **"M"** と **"N"** はファイルディスクリプタ番号です。これは、ファイルディスクリプタ **"M"** と **"N"** の出力を単一のストリームに結合します。

`|&`

これは `2>&1 |` の省略形です。Bash 4 で追加されました。

`&>/dev/null`

これは `>/dev/null 2>&1` の省略形です。ファイルディスクリプタ 2（`STDERR`）とファイルディスクリプタ 1（`STDOUT`）の出力を `/dev/null` にリダイレクトします。

`>/dev/null`

これは `1>/dev/null` の省略形です。ファイルディスクリプタ 1（`STDOUT`）の出力を `/dev/null` にリダイレクトします。

有用なリソース：

- [2>&-、2>/dev/null、|&、&>/dev/null、および >/dev/null 2>&1 の違い](https://unix.stackexchange.com/questions/70963/difference-between-2-2-dev-null-dev-null-and-dev-null-21)
- [第20章 I/O リダイレクション](http://www.tldp.org/LDP/abs/html/io-redirection.html)

</details>

<details>
<summary><b>標準エラーと標準出力を同じ行で異なるファイルにリダイレクトするにはどうすればよいですか？</b></summary><br>

1行で指定するには、`command 2>> error 1>> output` のようにします。

ただし、`>>` はファイルに既にデータがある場合に追加書き込みを行います。一方、`>` はファイルの既存のデータを上書きします。

したがって、追加書き込みを行いたくない場合は、`command 2> error 1> output` を使用します。

完全性のために、`1>` は `>` として書くことができます。デフォルトのファイルディスクリプタは出力なので、`1>` と `>` は同じ意味です。

したがって、`command 2> error 1> output` は `command 2> error > output` になります。

</details>

<details>
<summary><b>24コアのサーバーでロードアベレージが30を超えているが、CPUのアイドル率が約70％です。この状態の一般的な原因は何ですか？また、どのようにデバッグして修正しますか？</b></summary><br>

ディスクI/Oを伴うリクエストは、CPUがディスクの読み書きを待つ必要がある場合、パフォーマンスが大幅に低下する可能性があります。I/O待機時間（I/O Wait）は、CPUがディスクでの操作を待つ時間の割合です。

以下の端末コマンドラインツール（`top`、`atop`、`iotop`）を使用して、ディスクI/Oがアプリケーションのパフォーマンスを低下させているかどうかを確認できます。

デバッグの例：

- I/Oがシステムの遅延を引き起こしているかどうかを確認する
- どのディスクが書き込まれているかを特定する
- 高いI/Oを引き起こしているプロセスを見つける
- プロセスリストの**状態**を確認する
- 過剰に書き込まれているファイルを特定する
- コピー処理が**D**状態でI/O作業がpdflushによって行われるのを待っているか確認する
- ディスクでの重い同期書き込みアクティビティを確認する

また：

- `top` コマンドを使用してロードアベレージと待機時間（wa）を確認する
- `atop` コマンドを使用してディスク（DSK）I/Oの統計を監視する
- `iotop` コマンドを使用してディスクの読み書きのリアルタイムの洞察を得る

パフォーマンス改善のために：

- ドライブアレイの構成を確認する
- ディスクのキューイングアルゴリズムを確認し、調整する
- 一般的なブロックI/Oパラメータを調整する
- I/Oパフォーマンスを向上させるために仮想メモリ管理を調整する
- マウントオプションやファイルシステムのパラメータを確認し、調整する（キャッシュにも影響があります）

有用なリソース：

- [Linuxサーバーのパフォーマンス: ディスクI/Oがアプリケーションを遅くしているか？](https://haydenjames.io/linux-server-performance-disk-io-slowing-application/)
- [Linuxでの高いI/O待機時間のトラブルシューティング](https://bencane.com/2012/08/06/troubleshooting-high-io-wait-in-linux/)
- [LinuxのI/O待機時間のデバッグ](https://superuser.com/questions/396696/debugging-linux-i-o-latency)
- [pdflush、kjournald、swapdなどはどのように相互作用するのか？](https://unix.stackexchange.com/questions/76970/how-do-pdflush-kjournald-swapd-etc-interoperate)
- [LinuxでHDDの速度を改善する5つの方法](https://thecodeartist.blogspot.com/2012/06/improving-hdd-performance-linux.html)

</details>

<details>
<summary><b>SSHで認証方法を強制するにはどうすればよいですか？どのような状況で役立ちますか？</b></summary><br>

パスワードでのログインを強制する：

```bash
ssh -o PreferredAuthentications=password -o PubkeyAuthentication=no user@remote_host
```

キーを使用してログインを強制する：

```bash
ssh -o PreferredAuthentications=publickey -o PubkeyAuthentication=yes -i id_rsa user@remote_host
```

役立つリソース:

- [SSHクライアントにパスワード認証のみを使用させるにはどうすればよいですか？](https://unix.stackexchange.com/questions/15138/how-to-force-ssh-client-to-use-only-password-auth)

</details>

<details>
<summary><b>Postgresで「Too many Open files」エラーが発生しています。どう解決すればよいですか？</b></summary><br>

`max_files_per_process` をデフォルトの1000から200に減らすことで問題を解決しました。このパラメータは `postgresql.conf` ファイルにあり、各サーバーサブプロセスに許可される同時に開かれているファイルの最大数を設定します。

通常、人々は `/etc/security/limits.conf` ファイルを編集し始めますが、このファイルはPAMシステムを通じてアクティブにログインしているユーザーにのみ適用されることを忘れがちです。

</details>

<details>
<summary><b>`df`と`du`が利用可能なディスクスペースについて意見が異なるのはどのような状況ですか？どのように解決しますか？</b></summary><br>

`du` はディレクトリの使用状況を確認しますが、`df` は解放されたインデックスノードを確認します。ファイルが削除された後でも開いたままの状態でスペースを占有し続けることがあります。

**解決策 1**

マウントポイントの下にあるファイルを確認します。たとえば、ディレクトリ（例えば sambafs）をすでにファイルやディレクトリが存在するファイルシステムにマウントすると、これらのファイルを見ることができなくなりますが、基盤となるディスク上ではまだスペースを消費しています。

シングルユーザーモードでファイルコピーを行うと、他のディレクトリシステムが上にマウントされているため、通常のモードでは見えないディレクトリにファイルがダンプされることがあります。

**解決策 2**

一方、`df -h` と `du -sh` がハードディスクサイズの約50％で不一致になることがあります。これは例えば、Apache（httpd）がディスクから削除されたがメモリに保持されている大きなログファイルを保持しているためです。

この問題は、`lsof | grep "/var" | grep deleted` を実行することで追跡されました。ここで `/var` はクリーンアップが必要なパーティションです。

出力には次のような行が表示されました：

```
httpd     32617    nobody  106w      REG        9,4 1835222944     688166 /var/log/apache/awstats_log (deleted)
```

状況はApacheを再起動することで解決されました（`service httpd restart`）。これにより、削除されたファイルのロックがクリアされ、ディスクスペースが解放されました。

有用なリソース：

- [Why du and df display different values in Linux and Unix](https://linuxshellaccount.blogspot.com/2008/12/why-du-and-df-display-different-values.html)

</details>

<details>
<summary><b>暗号化とハッシュ化の違いは何ですか？</b></summary><br>

**ハッシュ化**：ハッシュ化は暗号化とは異なる暗号セキュリティの形式です。**暗号化**はメッセージをまず暗号化し、その後復号化するための二段階プロセスですが、**ハッシュ化**はメッセージを不可逆的な固定長の値（またはハッシュ）に凝縮します。

</details>

<details>
<summary><b>ルート証明書はサーバーに配置すべきですか？</b></summary><br>

**自己署名のルート証明書**は、ウェブサーバーの設定に含める必要はありません。これらは目的がなく（クライアントは常に無視します）、SSLハンドシェイクのサイズが大きくなるため、わずかなパフォーマンス（レイテンシー）のペナルティが発生します。

クライアントが信頼ストアにルート証明書を持っていない場合、そのウェブサイトを信頼しません。この問題を回避する方法はありません。ウェブサーバーがルート証明書を送信しても役に立ちません - ルート証明書は信頼できる第三者（ほとんどの場合、ブラウザベンダー）から提供される必要があります。

有用なリソース：

- [SSL root certificate optional?](https://security.stackexchange.com/questions/65332/ssl-root-certificate-optional)

</details>

<details>
<summary><b>プロダクションサーバーでルートによって実行されたすべてのコマンドをログに記録するには？</b></summary><br>

`auditd`がこの作業には適切なツールです：

1. `/etc/audit/audit.rules` に以下の2行を追加します：

```bash
-a exit,always -F arch=b64 -F euid=0 -S execve
-a exit,always -F arch=b32 -F euid=0 -S execve
```

これにより、ルート（euid=0）によって実行されたすべてのコマンドが追跡されます。なぜ2つのルールが必要なのか？`execve` システムコールは、32ビットおよび64ビットの両方のコードで追跡する必要があります。

2. ログに `auid=4294967295` メッセージを表示させないようにするには、カーネルのコマンドラインに `audit=1` を追加します（`/etc/default/grub` を編集）。

3. 以下の

```bash
session  required                pam_loginuid.so
```

を、ログインに関連するすべてのPAM設定ファイル（`/etc/pam.d/{login,kdm,sshd}`）に追加しますが、`su` または `sudo` に関連するファイルには追加しません。これにより、`sudo` または `su` を呼び出すときに、`auditd` が呼び出し元ユーザーのUIDを正しく取得できるようになります。

システムを再起動してください。

ログインしてコマンドを実行してみましょう：

```bash
$ id -u
1000
$ sudo ls /
bin  boot  data  dev  etc  home  initrd.img  initrd.img.old  lib  lib32  lib64  lost+found  media  mnt  opt  proc  root  run  sbin  scratch  seLinux  srv  sys  tmp  usr  var  vmlinuz  vmlinuz.old
$ sudo su -
# ls /etc
[...]
```

現在、`/var/log/audit/auditd.log` を読み取って、どのコマンドがログに記録されたかを確認してください。

有用なリソース:

- [管理者によって実行されたすべてのコマンドをログに記録する方法](https://serverfault.com/questions/470755/log-all-commands-run-by-admins-on-production-servers)

</details>

<details>
<summary><b>`dd` コマンドがシステムをフリーズさせないようにするには？</b></summary><br>

`ionice` を使ってみてください：

```bash
ionice -c3 dd if=/dev/zero of=file
```

これにより、`dd` プロセスが「アイドル」IO優先度で開始されます。これは、他のプロセスがディスクIOを使用していないときだけ、ディスク時間が割り当てられるという意味です。

もちろん、これでもバッファキャッシュがフラッドし、システムがキャッシュをディスクにフラッシュする間にフリーズが発生する可能性があります。これに影響を与えるためのチューニングパラメータが `/proc/sys/vm/` にあります。特に `dirty_*` エントリが関係しています。

</details>

<details>
<summary><b>プロセスがCPU使用率をX%を超えないように制限する方法は？</b></summary><br>

**nice/renice**

`nice` は、システムの「一時的な」調整に適したツールです。

```bash
nice COMMAND
```

**cpulimit**

`cpulimit` は、CPU集中的なジョブを実行する必要があり、システムの応答性にとって十分なCPU時間が重要な場合に使用します。

```bash
cpulimit -l 50 COMMAND
```

**cgroups**

`cgroups` は、単一のプロセスではなく、一連のプロセスに制限を適用します。

```bash
cgcreate -g cpu:/cpulimited
cgset -r cpu.shares=512 cpulimited
cgexec -g cpu:cpulimited COMMAND_1
cgexec -g cpu:cpulimited COMMAND_2
cgexec -g cpu:cpulimited COMMAND_3
```

</details>

<details>
<summary><b>一時的なRAMパーティションのマウント方法は？</b></summary><br>

```bash
# -t - filesystem type
# -o - mount options
mount -t tmpfs tmpfs /mnt -o size=64M
```

</details>

<details>
<summary><b>ファイルをロックしているプロセスを停止させるには？</b></summary><br>

```bash
fuser -k filename
```

</details>

<details>
<summary><b>サーバーをデバッグしようとしている他の管理者が誤って入力してしまった：<code>chmod -x /bin/chmod</code>。パーミッションをデフォルトに戻すには？</b></summary><br>

```bash
# 1:
cp /bin/ls chmod.01
cp /bin/chmod chmod.01
./chmod.01 700 file

# 2:
/bin/busybox chmod 0700 /bin/chmod

# 3:
setfacl --set u::rwx,g::---,o::--- /bin/chmod

# 4:
/usr/lib/ld*.so /bin/chmod 0700 /bin/chmod
```

役に立つリソース:

- [What can you do when you can't chmod chmod?](https://www.networkworld.com/article/3002286/operating-systems/what-can-you-do-when-you-cant-chmod-chmod.html)

</details>

<details>
<summary><b><code>grub></code> と <code>grub-rescue></code> の違いについて説明してください。</b></summary><br>

- `grub>` - これは、システムを実行するために必要なものが見つかり、設定ファイルも含まれている場合に切り替わるモードです。このモードでは、ほとんどすべてのモジュールやコマンドにアクセスできます。このモードには、メニューから 'c' キーを押すことでアクセスできます。
- `grub-rescue` - これは、自身のディレクトリ（特にモジュールや追加コマンドが含まれているディレクトリ、例えば `/boot/grub/i386-pc`）が見つからない場合、内容が損傷している場合、または正常なモジュールが見つからない場合に切り替わるモードです。このモードには基本的なコマンドしか含まれていません。

</details>

<details>
<summary><b>プライベートキーと証明書が一致するかどうかを確認する方法は？</b></summary><br>

```bash
(openssl rsa -noout -modulus -in private.key | openssl md5 ; openssl x509 -noout -modulus -in certificate.crt | openssl md5) | uniq
```

</details>

<details>
<summary><b><code>useradd</code> または <code>adduser</code> コマンドを使わずに新しいユーザーを追加する方法は？</b></summary><br>

1. `vipw` コマンドを使って、<code>/etc/passwd</code> にユーザーの詳細を追加します：

```bash
# username:password:UID:GID:Comments:Home_Directory:Login Shell
user:x:501:501:test user:/home/user:/bin/bash
```

   > 構文には注意してください。直接エディタで編集しないでください。`vipw` はファイルをロックするため、他のコマンドが同時にファイルを更新しようとすることはありません。

2. 同じ名前のグループを <code>/etc/group</code> に `vigr` で作成する必要があります（`vipw` と似たツールです）。

```bash
user:x:501:
```

3. ユーザーにパスワードを与えます:

```bash
passwd user
```

4. `mkdir` コマンドを使ってユーザーのホームディレクトリを作成します：

```bash
mkdir -m 0700 /home/user
```

5. `/etc/skel` から新しいホームディレクトリにファイルをコピーします：

```bash
rsync -av --delete /etc/skel/ /home/user
```

6. `chown` と `chmod` を使って所有権と権限を修正します：

```bash
chown -R user:user /home/user
chmod -R go-rwx /home/user
```

役に立つリソース:

- [What steps to add a user to a system without using useradd/adduser?](https://unix.stackexchange.com/questions/153225/what-steps-to-add-a-user-to-a-system-without-using-useradd-adduser)

</details>

<details>
<summary><b><code>mktemp</code> コマンドはなぜ必要ですか？ 使用例を示してください。</b></summary><br>

<code>mktemp</code> コマンドは名前をランダム化します。これはセキュリティの観点から非常に重要です。

例えば、次のようなことをする場合を想像してみてください：

```bash
echo "random_string" > /tmp/temp-file
```

このスクリプトを実行しているユーザーが誰かがスクリプトを読んで、次のような操作を行ったとします：

```bash
ln -s /etc/passwd /tmp/temp-file
```

この状況では、<code>mktemp</code> コマンドが役立ちます：

```bash
TEMP=$(mktemp /tmp/temp-file.XXXXXXXX)
echo "random_string" > ${TEMP}
```

これで、<code>ln /etc/passwd</code> 攻撃は機能しなくなります。

</details>

<details>
<summary><b>稼働中のプロセスに対して <code>strace</code> をアタッチするのは安全ですか？その結果は何ですか？</b></summary><br>

`strace` は Linux のシステムコールトレーサーです。現在、`strace` は `ptrace()`（プロセストレース）デバッグインターフェースを使用しています。これは暴力的な方法で動作します。具体的には、デバッガが状態を読み取るために、**対象プロセスを各システムコールで一時停止**させるという方法です。この処理はシステムコールが開始されるときと終了するときの二回行われます。

つまり、`strace` は各システムコールでアプリケーションを二回一時停止させ、アプリケーションと `strace` の間でコンテキストスイッチを行います。これは、アプリケーションに交通信号のメーターを取り付けるようなものです。

デメリット：

- 重大かつ時には非常に大きなパフォーマンスオーバーヘッドを引き起こす可能性があります。最悪の場合、ターゲットアプリケーションのパフォーマンスを 100 倍以上も遅くすることがあります。これにより、プロダクション環境での使用には適さなくなり、タイミング情報が歪んで誤解を招く可能性もあります。
- 複数のプロセスを同時にトレースできません（追跡する子プロセスを除く）。
- システムコールインターフェースに対する可視性が制限されます。

有用なリソース：

- [strace Wow Much Syscall (原文)](http://www.brendangregg.com/blog/2014-05-11/strace-wow-much-syscall.html)

</details>

<details>
<summary><b><code>-rf</code> ディレクトリエントリを削除する最も簡単で安全で移植性のある方法は何ですか？</b></summary><br>

これらは効果的ですが、最適な移植性はありません：

- <code>rm -- -fr</code>
- <code>perl -le 'unlink("-fr");'</code>

シェルコマンドラインのクォーティングや文字エスケープに関して語る人々は、ファイル名に問題がある理由を認識しない人々と同じくらい危険です。

最も移植性のある解決策：

```bash
rm ./-fr
```

</details>

<details>
<summary><b>システムのバックアップと復元を行うシンプルな bash スクリプト（またはスクリプトペア）を作成してください。 ***</b></summary><br>

未完了。

</details>

<details>
<summary><b>ソルト付きハッシュとは何ですか？ <code>/etc/shadow</code> ファイルのためにソルト付きパスワードを生成してください。</b></summary><br>

**ソルト**は基本的にはランダムなデータです。適切に保護されたパスワードシステムが新しいパスワードを受け取ると、そのパスワードのハッシュ値を作成し、新しいランダムなソルト値を生成して、その結合値をデータベースに保存します。これにより、辞書攻撃や既知のハッシュ攻撃から守る助けとなります。

例えば、ユーザーが2つの異なるシステムで同じパスワードを使用した場合、同じハッシュアルゴリズムを使用していれば、同じハッシュ値が生成される可能性があります。しかし、どちらかのシステムがソルトを使用していれば、ハッシュ値は異なります。

`/etc/shadow` ファイルに保存されている暗号化されたパスワードは、以下の形式で保存されます：

```bash
$ID$SALT$ENCRYPTED
```

ここで、`$ID` は暗号化の種類を示し、`$SALT` はランダムな（最大16文字）文字列、`$ENCRYPTED` はパスワードのハッシュです。

<table style="width:100%">
  <tr>
    <th>ハッシュタイプ</th>
    <th>ID</th>
    <th>ハッシュ長</th>
  </tr>
  <tr>
    <td>MD5</td>
    <td>$1</td>
    <td>22文字</td>
  </tr>
  <tr>
    <td>SHA-256</td>
    <td>$5</td>
    <td>43文字</td>
  </tr>
  <tr>
    <td>SHA-512</td>
    <td>$6</td>
    <td>86文字</td>
  </tr>
</table>

以下のコマンドを Linux シェルで使用して、ランダムなソルト付きのハッシュパスワードを `/etc/shadow` 用に生成します：

- **MD5** パスワードハッシュの生成

```bash
python -c "import random,string,crypt; randomsalt = ''.join(random.sample(string.ascii_letters,8)); print crypt.crypt('MySecretPassword', '\$1\$%s\$' % randomsalt)"
```

- **SHA-256** パスワードハッシュの生成

```bash
python -c "import random,string,crypt; randomsalt = ''.join(random.sample(string.ascii_letters,8)); print crypt.crypt('MySecretPassword', '\$5\$%s\$' % randomsalt)"
```

- **SHA-512** パスワードハッシュの生成

```bash
python -c "import random,string,crypt; randomsalt = ''.join(random.sample(string.ascii_letters,8)); print crypt.crypt('MySecretPassword', '\$6\$%s\$' % randomsalt)"
```

</details>

###### Network Questions (27)

<details>
<summary><b>スパムを制御するためにサイトに SPF レコードを作成する方法。</b></summary><br>

* SPF バージョンから始めます。この部分はレコードを SPF として定義します。SPF レコードは常にバージョン番号 v=spf1 (バージョン 1) で始めるべきです。このタグはレコードを SPF として定義します。以前は SPF の第二版 (SenderID と呼ばれる) がありましたが、これは廃止されました。

* v=spf1 SPF バージョンタグを含めた後、次にあなたの代わりにメールを送信する権限があるすべての IP アドレスを続けて記述するべきです。例: <code>v=spf1 ip4:34.243.61.237 ip6:2a05:d018:e3:8c00:bb71:dea8:8b83:851e</code>

* 次に、あなたの代わりにメールを送信するために使用されるすべてのサードパーティー組織のために include タグを含めることができます。例: <code>include:thirdpartydomain.com.</code> このタグは、特定のサードパーティーがあなたのドメインの代わりにメールを送信する権限があることを示します。‘include’ ステートメントに使用するドメインについてはサードパーティーと相談する必要があります。

* すべての IP アドレスと include タグを実装した後は、レコードを <code>~all</code> または <code>-all</code> タグで終わるべきです。all タグは SPF レコードの重要な部分で、ISP があなたの SPF レコードにリストされていないサーバーを検出したときに適用されるポリシーを示します。もし認可されていないサーバーがあなたのドメインの代わりにメールを送信した場合、公開されたポリシーに従ってアクションが取られます（例: メールを拒否する、またはスパムとしてマークする）。これらのタグの違いは何ですか？メールをどれだけ厳しく扱うべきかを指示する必要があります。<code>~all</code> タグはソフトフェイルを示し、<code>-all</code> タグはハードフェイルを示します。all タグには以下の基本的なマーカーがあります:<br><br>
`-all` – SPF レコードにリストされていないサーバーはメールを送信する権限がない (準拠しないメールは拒否されます)<br>
`~all` – リストにないサーバーからメールを受信した場合、メールはソフトフェイルとしてマークされます (メールは受け入れられますがマークされます)<br>
`+all` – このオプションの使用は強く推奨しません。このタグは任意のサーバーがあなたのドメインからメールを送信することを許可します<br>

* SPF レコードを定義した後、レコードは次のようになるかもしれません:
<code>v=spf1 ip4:34.243.61.237 ip6:2a05:d018:e3:8c00:bb71:dea8:8b83:851e include:thirdpartydomain.com -all</code>

有用なリソース:

- [SPF レコードチェッカー](https://www.dmarcanalyzer.com/spf/checker/)
- [SPF 構文](https://www.spf-record.com/syntax)


</details>

<details>
<summary><b>DNS クエリに対する権威ある回答と非権威ある回答の違いは何ですか？</b></summary><br>

権威ある DNS クエリの回答は、クエリされたドメインのゾーンファイルを含むサーバーから来ます。これはドメイン管理者が DNS レコードを設定したネームサーバーです。非権威ある回答は、ドメインゾーンファイルをホストしていないネームサーバーから来ます（例えば、Google の 8.8.8.8 や OpenDNS の 208.67.222.222 などのよく使われるネームサーバーがキャッシュされた回答を持っている場合など）。

</details>

<details>
<summary><b>ホスト名を解決しようとすると <code>host</code> コマンドで <code>NXDOMAIN</code> を取得します。<code>resolv.conf</code> には 2 つのネームサーバーが保存されていますが、そのうちの 2 番目だけがこのドメイン名を保存しています。なぜローカルリゾルバーは 2 番目のネームサーバーをチェックしなかったのですか？</b></summary><br>

**NXDOMAIN** は存在しないインターネットまたはイントラネットのドメイン名です。ドメイン名が DNS を使用して解決できない場合、**NXDOMAIN** という状態が発生します。

`resolv.conf` と `resolver` のデフォルトの動作は、リストされた順序でサーバーを試すことです。リゾルバーは、最初のネームサーバーがタイムアウトした場合にのみ、次のネームサーバーを試します。

使用されるアルゴリズムは、ネームサーバーを試し、クエリがタイムアウトすると次を試す、ネームサーバーがなくなるまで繰り返し、最大再試行回数に達するまで再試行します。

ネームサーバーが **SERVFAIL** で応答した場合や参照 (**nofail**) またはクエリの終了 (**fail**) があった場合も、最初の DNS サーバーのみが使用されます。

例:

```
nameserver 192.168.250.20   # it's not a dns
nameserver 8.8.8.8          # not store gate.test.int
nameserver 127.0.0.1        # store gate.test.int
```

確認するためには:

```
host -v -t a gate.test.int
Trying "gate.test.int"                        # trying first dns (192.168.250.20) but response is time out, so try the next nameserver
Host gate.test.int not found: 3(NXDOMAIN)     # ok but response is NXDOMAIN (not found this domain name)
Received 88 bytes from 8.8.8.8#53 in 43 ms
Received 88 bytes from 8.8.8.8#53 in 43 ms
                                              # so the last server in the list was not asked
```

この問題を避けるためには、例えば `nslookup` コマンドを使用できます。このコマンドは、最初のネームサーバーから **SERVFAIL** を受け取った場合に、2 番目のネームサーバーを使用します。

有用なリソース:

- [Second nameserver in /etc/resolv.conf not picked up by wget](https://serverfault.com/questions/398837/second-nameserver-in-etc-resolv-conf-not-picked-up-by-wget)

</details>

<details>
<summary><b>サイトで現在の MTA 構成を調査してください。使用されている MTA の特別な機能にはどのようなものがありますか？ ***</b></summary><br>

未完成です。

</details>

<details>
<summary><b>IP アドレスに基づいてドメインを見つける方法は？どのような技術やツールを使用できますか？ ***</b></summary><br>

未完成です。

</details>

<details>
<summary><b>IP アドレスに対して SSL 証明書を取得することは可能ですか？ドメイン名ではなく IP アドレスに対してです。</b></summary><br>

可能ですが（あまり一般的ではありません）、公開 IP アドレスである限り可能です。

SSL 証明書は通常、`https://www.domain.com` のような完全修飾ドメイン名 (FQDN) に発行されます。ただし、一部の組織では、公開 IP アドレスに発行された SSL 証明書が必要です。このオプションを使用すると、証明書署名要求 (CSR) の Common Name に公開 IP アドレスを指定できます。発行された証明書は、公開 IP アドレス (`https://1.1.1.1` など) で直接接続を保護するために使用できます。

CA Browser フォーラムによると、IP アドレスの証明書には互換性の問題がある場合があります。特に、IP アドレスが commonName と subjectAltName フィールドの両方に含まれていない場合です。これは、RFC 5280 に沿っていない古い SSL 実装、特に Windows 10 以前の Windows OS に起因しています。

有用なリソース:

- [Are SSL certificates bound to the servers ip address?](https://stackoverflow.com/questions/1095780/are-ssl-certificates-bound-to-the-servers-ip-address)
- [SSL certificate for a public IP address?](https://serverfault.com/questions/193775/ssl-certificate-for-a-public-ip-address)

</details>

<details>
<summary><b>ウェブサイトの負荷テストとキャパシティプランニングをどのように行いますか？ ***</b></summary><br>

未完成です。

有用なリソース:

- [How do you do load testing and capacity planning for web sites? (original)](https://serverfault.com/questions/350454/how-do-you-do-load-testing-and-capacity-planning-for-web-sites)
- [Can you help me with my capacity planning?](https://serverfault.com/questions/384686/can-you-help-me-with-my-capacity-planning)
- [How do you do load testing and capacity planning for databases?](https://serverfault.com/questions/350458/how-do-you-do-load-testing-and-capacity-planning-for-databases)

</details>

<details>
<summary><b>開発者がリモートサービスへの接続に問題があると報告しています。トラブルシューティングのために <code>/dev</code> を使用してください。</b></summary><br>

```bash
# <host> - set remote host
# <port> - set destination port

# 1
timeout 1 bash -c "</dev/tcp/<host>/<port>" >/dev/null 2>&1 ; echo $?

# 2
timeout 1 bash -c 'cat < /dev/null > </dev/tcp/<host>/<port>' ; echo $?

# 2
&> echo > "</dev/tcp/<host>/<port>"
```

有用なリソース:

- [Advanced Bash-Scripting Guide - /dev](http://www.tldp.org/LDP/abs/html/devref1.html#DEVTCP)
- [/dev/tcp as a weapon](https://securityreliks.wordpress.com/2010/08/20/devtcp-as-a-weapon/)
- [Test from shell script if remote TCP port is open](https://stackoverflow.com/questions/4922943/test-from-shell-script-if-remote-tcp-port-is-open)

</details>

<details>
<summary><b>リクエストとレスポンスタイムを一度に <code>curl</code> で測定するにはどうすればよいですか？</b></summary><br>

`curl` はリクエストの詳細に対するフォーマット出力をサポートしています（詳細は `curl` のマニュアルページの `-w| -write-out 'format'` を参照）。ここでは、提供されるタイミングの詳細に焦点を当てます。

1. 新しいファイル `curl-format.txt` を作成し、以下を貼り付けます：

```bash
    time_namelookup:  %{time_namelookup}\n
       time_connect:  %{time_connect}\n
    time_appconnect:  %{time_appconnect}\n
   time_pretransfer:  %{time_pretransfer}\n
      time_redirect:  %{time_redirect}\n
 time_starttransfer:  %{time_starttransfer}\n
                    ----------\n
         time_total:  %{time_total}\n
```

2. リクエストの作成:

```bash
curl -w "@curl-format.txt" -o /dev/null -s "http://example.com/"
```

これが行うこと:

- `-w "@curl-format.txt"` - cURL にフォーマットファイルを使用するよう指示します
- `-o /dev/null` - リクエストの出力を /dev/null にリダイレクトします
- `-s` - cURL に進行状況メーターを表示しないよう指示します
`http://example.com/` はリクエストするURLです。URLに "&" クエリ文字列パラメータが含まれている場合は、特に引用符を使用してください

</details>

<details>
<summary><b>ext4ジャーナルを別のディスク/パーティションに移動する必要がある理由は何ですか？</b></summary><br>

未完成です。

有用なリソース:

- [ext4: 外部ジャーナルを使用してパフォーマンスを最適化する](https://raid6.com.au/posts/fs_ext4_external_journal/)
- [ext4ジャーナルを移動する方法](https://unix.stackexchange.com/questions/278998/how-to-move-an-ext4-journal)

</details>

<details>
<summary><b>ウェブサイト/アプリケーションの前に Varnish を配置すると、負荷分散や冗長性について心配する必要がなくなりますか？</b></summary><br>

それは場合によります。Varnish はキャッシュサーバーであり、その目的はコンテンツをキャッシュし、リバースプロキシとして機能してデータの取得を高速化し、ウェブサーバーへの負荷を軽減することです。  
Varnish は複数のウェブサーバー用のロードバランサーとしても構成できますが、1台の Varnish サーバーのみを使用する場合、これがインフラストラクチャの単一障害点になります。

負荷分散や冗長性を確保するためには、少なくとも2台の Varnish インスタンスから成るクラスター（アクティブ-アクティブモードまたはアクティブ-パッシブモード）がより良い解決策となります。

</details>

<details>
<summary><b>Varnish Cache におけるヒット、ミス、ヒットフォーパスとは何ですか？</b></summary><br>

**ヒット**とは、キャッシュから正常に提供されたリクエストのことです。**ミス**とは、キャッシュを通過したが空のキャッシュが見つかり、したがってオリジンサーバーから取得しなければならないリクエストのことです。**ヒットフォーパス**は、Varnish Cache がリクエストしたオブジェクトの一つがキャッシュできないと判断し、パス（直接オリジンサーバーから取得）となる場合に発生します。

有用なリソース:

- [ヒットに関する VCL ルール](https://book.varnish-software.com/4.0/chapters/VCL_Subroutines.html#vcl-vcl-hit)
- [ヒットフォーパスに関する VCL ルール](https://book.varnish-software.com/4.0/chapters/VCL_Subroutines.html#hit-for-pass)
- [使用例](https://book.varnish-software.com/4.0/chapters/VCL_Basics.html#vcl-backend-response)

</details>

<details>
<summary><b>以下のパラメータを考慮して、キャッシュされたコンテンツに対する合理的な TTL はどのくらいですか？</b></summary><br>

未完成です。

</details>

<details>
<summary><b>開発者が「<i><code>htaccess</code> は魔法がいっぱいで、使用すべきだ</i>」と言っています。<code>htaccess</code> ファイルの使用についてどう思いますか？これがウェブアプリケーションに与える影響は何ですか？</b></summary><br>

`.htaccess` ファイルは、共有ホスティングが一般的だった時代に生まれました：

- システム管理者は、複数のクライアントが異なるアカウントでサーバーにアクセスし、異なるウェブサイトの構成を持つ方法を必要としました。

`.htaccess` ファイルは、Apache の設定全体にアクセスすることなく、Apache の動作を変更することを可能にしました。これらのファイルは、ウェブサイトのディレクトリツリーの任意のディレクトリに存在し、そのディレクトリおよびその中のファイルやフォルダに機能を提供します。

**パフォーマンスに悪影響**

`.htaccess` が機能するためには、Apache がリクエストされたパスのすべてのディレクトリで `.htaccess` ファイルの存在を確認し、存在する場合はすべての `.htaccess` ファイルを読み込み、解析する必要があります。これがすべてのリクエストで行われます。ファイルを変更すると、その変更が即座に適用されます。これは Apache が毎回ファイルを読み込むためです。

すべてのリクエスト（たとえ最も単純な `.png` や `.css` ファイルのリクエストであっても）が Apache に次の処理をさせます：

- 現在のリクエストのディレクトリで `.htaccess` ファイルを探す
- そこからサーバーのルートまで、すべてのディレクトリで `.htaccess` ファイルを探す
- これらの `.htaccess` ファイルを統合する
- 新しい設定でウェブサーバーを再構成する
- 最後に、ファイルを提供する

すべてのウェブページは数十のリクエストを生成する可能性があります。これは不要なオーバーヘッドであり、さらに言えば、完全に不要です。

**セキュリティと権限の喪失**

個々のユーザーに `.htaccess` を使用してサーバーの設定を変更させると、適切に管理されない場合にセキュリティ上の懸念が生じる可能性があります。`.htaccess` ファイルにディレクティブを追加すると、それが Apache の設定ファイルに追加されたと見なされます。

これにより、非管理者がこれらのファイルを書き込むことができる可能性があり、あなたのセキュリティ設定を「取り消す」ことができてしまいます。もし一時的な変更が必要な場合は `.htaccess` が適していますが、より恒久的な変更が必要な場合は、`/etc/apache/sites-available/site.conf`（または `httpd.conf` など、サーバーが呼ぶもの）に設定を追加してください。

**まとめ**

もし httpd メインサーバーの設定ファイルにアクセスできる場合は、`.htaccess` ファイルの使用を完全に避けるべきです。`.htaccess` で動作したものは、仮想ホストの `.conf` ファイルでも動作します。

もし `.htaccess` ファイルを使用せざるを得ない場合は、以下のルールに従うべきです：

- `.htaccess` ファイルはできるだけ少なく、または1つだけ使用する
- `.htaccess` ファイルはサイトのルートディレクトリに配置する
- `.htaccess` ファイルは短くシンプルに保つ

有用なリソース:

- [Apache のような: .htaccess](https://www.nginx.com/resources/wiki/start/topics/examples/likeapache-htaccess/)
- [必要な場合以外は .htaccess を使用しない](https://www.danielmorell.com/guides/htaccess-seo/basics/dont-use-htaccess-unless-you-must)

</details>

<details>
<summary><b>本番環境で SNI SSL を使用するのは安全ですか？それを使用した接続と使用しない接続をテストする方法は？どのような場合に役立ちますか？</b></summary><br>

<b>OpenSSL</b> を使用する場合：

```bash
# SNI サポートありでリモートホストへの接続をテストする
echo | openssl s_client -showcerts -servername google.com -connect google.com:443
# SNI サポートなしでリモートホストへの接続をテストする
echo | openssl s_client -connect google.com:443 -showcerts
```

<b>GnuTLS</b> を使用する場合：

```bash
# SNI サポートありでリモートホストへの接続をテストする
gnutls-cli -p 443 google.com
# SNI サポートなしでリモートホストへの接続をテストする
gnutls-cli --disable-sni -p 443 google.com
```

</details>

<details>
<summary><b>クッキーは HTTP プロトコルでどのように渡されますか？</b></summary><br>

サーバーはクッキーを設定するために以下をレスポンスヘッダーに送信します：

`Set-Cookie:name=value`

クッキーが設定されている場合、ブラウザは以下をリクエストヘッダーに送信します：

`Cookie:name=value`

</details>

<details>
<summary><b>未定義のサーバー名でのリクエスト処理を防ぐにはどうすればよいですか？定義されていないデフォルトのサーバー名ルールがセキュリティ問題になる可能性がありますか？***</b></summary><br>

未完了。

</details>

<details>
<summary><b>POST リクエストを外部 API にペイロード付きで書き換える必要がありますが、POST リクエストは URL に渡されたパラメータを失います。この問題を修正する方法（例：Nginx）とこの動作の理由は何ですか？</b></summary><br>

問題は、外部リダイレクトが **POST** データを再送信しないことです。これは HTTP スペックに記載されています（`3xx` セクションを参照）。これを行うクライアントはスペックに違反しています。

**POST** データはリクエストのボディに渡され、標準のリダイレクトを行うとこのデータは失われます。

これを見てください:

```
   +------------------------------------+-----------+-----------+
   |                                    | 永続的     | 一時的     |
   +------------------------------------+-----------+-----------+
   | リクエストメソッドを POST から GET に　 | 301       | 302       |
   | 変更することを許可する                                         |
   | リクエストメソッドを POST から GET に   | 308       | 307       |
   | 変更することを許可しない                                       |
   +------------------------------------+-----------+-----------+
```

HTTP ステータスコード **307** を試してみてください。RFC に準拠したブラウザは POST リクエストを再送信するはずです。Nginx でステータスコード **307** または **308** のリダイレクトルールを作成するだけで済みます。

```bash
location / {
    proxy_pass              http://localhost:80;
    client_max_body_size    10m;
}

location /api {
    # HTTP 307 only for POST method.
    if ($request_method = POST) {
        return 307 https://api.example.com?request_uri;
    }

    # You can keep this for non-POST requests.
    rewrite ^ https://api.example.com?request_uri permanent;

    client_max_body_size    10m;
}
```

HTTP ステータスコード **307** または **308** は、**301** の代わりに使用するべきです。なぜなら、これらはリクエストメソッドを **POST** から **GET** に変更するからです。

役立つリソース:

- [Apache でのリダイレクション（POST パラメータを維持）](https://stackoverflow.com/questions/17295085/redirection-on-apache-maintain-post-params)
- [なぜ HTTP には POST リダイレクトがないのか？](https://softwareengineering.stackexchange.com/questions/99894/why-doesnt-http-have-post-redirect)

</details>

<details>
<summary><b>NFS パフォーマンスをテストする適切な方法は？簡単なチェックリストを準備してください。
</b></summary><br>

最適なベンチマークは常に「通常使用するアプリケーション」です。たとえば、20 人が同時に Linux カーネルをコンパイルしているときの NFS システムの負荷は、複数の人が同時にログインしている場合や、アカウントが「ローカル Web サーバーのホームディレクトリ」として使用されている場合とはまったく異なります。

ただし、これをテストするための優れたツールもあります。

- **boonie** - クラシックなパフォーマンス評価ツールです。主なプログラムは、1 つのファイル（または 1G 以上のストレージをテストしたい場合はファイルセット）へのデータベース型アクセスをテストし、小さなファイルの作成、読み取り、削除をテストして、Squid や INN、Maildir 形式のメールなどのプログラムの使用をシミュレートします。
- **DBench** - 独立した開発者が SAMBA をデバッグおよびテストできるように作成されました。オリジナルの SAMBA ツールに強く影響されています。
- **IOZone** - パフォーマンステストスイートです。POSIX と 64 ビットに準拠しています。これは L.S.E のファイルシステムテストです。主な機能: POSIX 非同期 I/O、Mmap() ファイル I/O、通常のファイル I/O 単一ストリーム測定、複数ストリーム測定、分散ファイルサーバー測定（クラスター）、POSIX pthreads、マルチプロセス測定、fsync、O_SYNC の選択可能な測定、レイテンシプロット。

</details>

<details>
<summary><b>同じサブネットの複数の IP アドレスをブロックする必要があります。システムが iptables ルールセットやブラックホールルートを効率的に処理する最良の方法は何ですか？</b></summary><br>

ルーティングテーブルに何千ものルートが定義されていて、iptables のルールが何もない場合は、iptables ルールを追加する方が効率的な場合があります。

しかし、多くのシステムではルーティングテーブルは比較的小さいため、そのような場合には null ルートを使用する方が実際には効率的です。これは、すでに広範な iptables ルールが存在する場合に特に当てはまります。

ソースアドレスに基づいてブロックしている場合、**raw/PREROUTING** で **DROP** を行うと、ルーティング決定が行われる前にパケットをドロップすることができるため、効果的です。

ただし、iptables のルールは本質的にリンクリストであり、複数のアドレスをブロックする際には最適なパフォーマンスを得るために `ipset` を使用するべきです。

一方、宛先に基づいてブロックする場合、ルーティングテーブルでのブロックと iptables でのブロックの違いはほとんどないでしょう。ただし、ソース IP がスプーフィングされている場合、ブラックホールエントリがルーティングキャッシュリソースを消費する可能性があります。この場合、**raw/PREROUTING** の方が好ましいです。

アウトゴーイングルートは、攻撃者にパケットを戻そうとするまで関係ありません。その時点では、ソケットのセットアップにかかるコストのほとんどが発生しており、カーネルがホストへのルートがないと判断するのを待つスレッドがブロックされることもあります。さらに、サーバープロセスがネットワーク問題を結論付けたときに行うエラーハンドリングもあります。

iptables や他のファイアウォールは、着信トラフィックをブロックし、サーバー上のデーモンプログラムに到達する前に破棄することができます。このユースケースでは、これが明らかに優れています。

```bash
iptables -A INPUT -s 192.168.200.0/24 -j DROP
```

Linux/Unix システムでルートを定義すると、指定された IP アドレスと通信するためには、その特定の場所にネットワーク通信をルーティングする必要があることをシステムに伝えます。

null ルートを定義すると、指定された IP アドレスに対するネットワーク通信を破棄するようにシステムに指示します。つまり、TCP ベースのネットワーク通信は確立できなくなります。サーバーはもはや SYN/ACK 応答を送信できなくなります。一方、UDP ベースのネットワーク通信は受信されますが、システムは発信元 IP への応答を送信しなくなります。

iptables はチェーンに数万のルールを受け入れることができますが、チェーンはパケットごとに一致が見つかるまで順次チェックされます。たくさんのルールがあると、システムがルールをチェックするのに大量の CPU 時間が費やされる可能性があります。

ルーティングルールは iptables よりもはるかに簡単です。iptables では、一致がプロトコル、ソースおよび宛先パケット、さらには現在のパケットより前に送信された他のパケットなど、さまざまな変数に基づいて行われます。

ルーティングでは、リモート IP アドレスがすべてであり、最適化が非常に簡単です。また、多くのシステムには多くのルーティングルールがあります。典型的なシステムでは 5 つまたは 10 つのルールしかないかもしれませんが、BGP ルーターとして機能しているものは数万のルールを持つことがあります。そのため、特定のパケットに対して適切なルートを選択するために長い間広範な最適化が行われてきました。

技術的に言えば、これによりシステムは攻撃者からデータを受信しますが、それに応答しなくなります。

```bash
ip route add blackhole 192.168.200.0/24
```

または

```bash
ip route add 192.168.200.0/24 via 127.0.0.1
```

有用なリソース:

- [iptables DROP と null-routing の違い](https://www.tummy.com/blogs/2006/07/27/the-difference-between-iptables-drop-and-null-routing/)

</details>

<details>
<summary><b>どのようにして <code>scp</code> を使って2つ目のリモートホストでファイルを転送しますか？</b></summary><br>

`ssh` を使う場合:

```bash
ssh user1@remote1 'ssh user2@remote2 "cat file"' > file
```

`tar` を使って圧縮する場合:

```bash
ssh user1@remote1 'ssh user2@remote2 "cd path2; tar cj file"' | tar xj
```

`ssh` とポートフォワーディングトンネルを使う場合:

```bash
# まず、トンネルを開きます
ssh -L 1234:remote2:22 -p 45678 user1@remote1

# 次に、そのトンネルを使って直接 remote2 からファイルをコピーします
scp -P 1234 user2@localhost:file .
```

</details>

<details>
<summary><b>動的ウェブサイトの読み込み時間を短縮するにはどうすればよいですか？</b></summary><br>

- ウェブページの最適化
- キャッシュされたウェブページ
- 高品質なウェブホスティング
- 圧縮されたテキストファイル
- Apache/nginx のチューニング

</details>

<details>
<summary><b>ブラウザで `api.example.com` と入力してリターンを押したときにどのような種類の DNS キャッシュが働いていますか？</b></summary><br>

ブラウザはドメインがキャッシュに存在するか確認します（Chrome の DNS キャッシュを見るには、`chrome://net-internals/#dns` にアクセスします）。このキャッシュが失敗した場合、OS にドメインの解決を要求します。

OS のリゾルバには独自のキャッシュがあり、それを確認します。これも失敗した場合は、OS に設定された DNS サーバーに問い合わせます。

OS に設定された DNS サーバーは通常、ルーターから DHCP によって設定されており、DNS サーバーは一般的にインターネットゲートウェイからルーターへの DHCP によって設定された ISP の DNS サーバーです。

ルーターに独自の DNS サーバーがある場合、それにも独自のキャッシュがあるかもしれません。そうでない場合は、OS のキャッシュが空であると確認されると、通常、直接 ISP の DNS サーバーに誘導されます。

Useful resources:

- [What happens when...](https://github.com/alex/what-happens-when)
- [DNS Explained - How Your Browser Finds Websites](https://scotch.io/tutorials/dns-explained-how-your-browser-finds-websites)
- [Firefox invalidate dns cache](https://stackoverflow.com/questions/13063496/firefox-invalidate-dns-cache)

</details>

<details>
<summary><b><code>Cache-Control: max-age=0</code> と <code>Cache-Control: no-cache</code> の違いは何ですか？</b></summary><br>

**オリジンサーバーから送信された場合**

`max-age=0` は、キャッシュ（およびユーザーエージェント）に対して、レスポンスがすぐに古くなることを示し、したがって、キャッシュされたコピーを使用する前にレスポンスの再検証を行うべきであることを伝えます（例えば、If-Not-Modified ヘッダーを使って）。対照的に、`no-cache` は、キャッシュされたコピーを使用する前に必ず再検証を行わなければならないことを伝えます。

つまり、キャッシュは時には古いレスポンスを使用することを選ぶかもしれません（ただし、その場合は警告ヘッダーを追加する必要があります）。しかし、`no-cache` は、古いレスポンスを使用することは許可されないと明示しています。たとえば、ページにベースボールの統計が生成されるときには `SHOULD-revalidate` の動作が望ましいかもしれませんが、eコマースの購入に対するレスポンスが生成されたときには `MUST-revalidate` の動作が望ましいです。

**ユーザーエージェントから送信された場合**

ユーザーエージェントが `Cache-Control: max-age=0` （別名「エンドツーエンド再検証」）を指定してリクエストを送信すると、経路上の各キャッシュがそのキャッシュエントリを再検証します（例えば、If-Not-Modified ヘッダーを使って）し、オリジンサーバーまで再検証が行われます。もし返信が 304（Not Modified）であれば、キャッシュされたエンティティを使用できます。

一方、`Cache-Control: no-cache` （別名「エンドツーエンド再読み込み」）でリクエストを送信すると、再検証は行われず、サーバーはレスポンス時にキャッシュされたコピーを使用してはなりません。

</details>

<details>
<summary><b><code>Access-Control-Allow-Origin</code> を設定することによるセキュリティリスクは何ですか？</b></summary><br>

<code>Access-Control-Allow-Origin: *</code> で応答することで、要求されたリソースはすべてのオリジンと共有を許可します。これは基本的に、どのサイトでもあなたのサイトに対して XHR リクエストを送信し、サーバーのレスポンスにアクセスできることを意味します。これは、CORS 応答を実装していなかった場合には起こりえないことです。

そのため、どのサイトでも自サイトにリクエストを送信し、そのレスポンスを処理することができます。もしあなたのサイトに認証や認可のスキームが実装されており、これがブラウザによって自動的に提供される何か（クッキー、クッキーに基づくセッションなど）に依存している場合、サードパーティサイトによってトリガーされたリクエストもそれらを使用することになります。

</details>

<details>
<summary><b><code>netcat</code>を使って使い捨ての TCP または UDP プロキシを作成する</b></summary><br>

```bash
### TCP -> TCP
nc -l -p 2000 -c "nc [ip|hostname] 3000"

### TCP -> UDP
nc -l -p 2000 -c "nc -u [ip|hostname] 3000"

### UDP -> UDP
nc -l -u -p 2000 -c "nc -u [ip|hostname] 3000"

### UDP -> TCP
nc -l -u -p 2000 -c "nc [ip|hostname] 3000"
```

</details>

<details>
<summary><b>nmapを使ってファイアウォールを回避するための3つのテクニックを説明してください。</b></summary><br>

**擬似アドレスの使用**

```bash
# ランダムな数の擬似アドレスを生成します。
nmap -D RND:10 [ターゲット]

# 擬似アドレスを手動で指定します。
nmap -D decoy1,decoy2,decoy3
```

このタイプのスキャンでは、Nmapに他のホストからパケットを偽装させることができます。ファイアウォールのログには、私たちのIPアドレスだけでなく、擬似アドレスのIPも記録されるため、どのシステムからスキャンが開始されたかを特定するのが難しくなります。

**ソースポート番号の指定**

```bash
nmap --source-port 53 [ターゲット]
```

多くの管理者がファイアウォールを設定する際に犯す一般的なエラーは、特定のポート番号からのすべての受信トラフィックを許可するルールを設定することです。Nmapの`--source-port`オプションを使って、この誤設定を利用することができます。一般的に使用できるポート番号には、20、53、67があります。

**ランダムデータの追加**

```bash
nmap --data-length 25 [ターゲット]
```

多くのファイアウォールは、パケットのサイズを確認してポートスキャンを特定しています。これは、多くのスキャナーが特定のサイズのパケットを送信するためです。そのような検出を回避するために、`--data-length`コマンドを使用して追加のデータを追加し、デフォルトとは異なるサイズのパケットを送信することができます。

**TCP ACKスキャン**

```bash
nmap -sA [ターゲット]
```

SYNパケットよりもACKパケットを送信する方が良いです。なぜなら、リモートコンピュータでアクティブなファイアウォールがある場合、ACKパケットのためにファイアウォールはログを作成できないからです。ファイアウォールはACKパケットをSYNパケットの応答として扱います。

有用なリソース:

- [Nmap - ファイアウォール回避のテクニック](https://pentestlab.blog/2012/04/02/nmap-techniques-for-avoiding-firewalls/)

</details>

###### Devops Questions (5)

<details>
<summary><b>Nagiosでのフラップ検出の仕組みを説明してください。</b></summary><br>

**フラッピング**は、サービスやホストが頻繁に状態を変更する場合に発生し、多くの問題や復旧通知を引き起こします。

**フラッピング**を定義した後、Nagiosがどのようにして**フラッピング**を検出するかを説明します。Nagiosがホストやサービスの状態をチェックするたびに、それがフラッピングを開始または停止したかどうかを確認します。

Nagiosは以下の手順に従ってこれを行います:

- ホストまたはサービスの最後の21回のチェック結果を保存し、履歴チェック結果を分析して状態の変更/遷移がどこで発生したかを判断します。
- 状態遷移を使用して、ホストまたはサービスの状態変化率（変化の度合い）を決定します。
- その状態変化率を低いフラップ閾値と高いフラップ閾値と比較します。

</details>

<details>
<summary><b>コンテナ化が仮想化に対して提供する利点は何ですか？</b></summary><br>

以下は、仮想化に対するコンテナ化の利点です:

- コンテナはリアルタイムでのプロビジョニングとスケーラビリティを提供しますが、VMはプロビジョニングが遅いです。
- コンテナはVMと比較して軽量です。
- VMはコンテナと比較してパフォーマンスが制限されています。
- コンテナはVMと比較してリソースの利用効率が良いです。

</details>

<details>
<summary><b>Docker HubからのDockerアプリ（例：Apache、MySQL）の配布方法は、本番環境に適していますか？セキュリティ上の問題点と可能な解決策を説明してください。</b></summary><br>

To be completed.

</details>

<details>
<summary><b>LXCとLXDの一般的な使用ケースには、次のような要件があります...説明してください。</b></summary><br>

- ホストマシンを汚染せずに、隔離された開発環境が必要な場合
- 本番サーバー内の隔離と、各サービスを独自のコンテナで実行する可能性
- 同じソフトウェアの複数のバージョンや異なるOS環境でテストする必要がある場合
- GNU/Linuxディストリビューションの異なる新しいリリースを、物理ホストマシンにインストールせずに試すこと
- しばらく試してみて使うかどうか分からないソフトウェアや開発スタックを試すこと
- プライマリ開発マシンや本番サーバーに多種類のソフトウェアをインストールし、それを長期間維持すること
- 本番マシンで実際に実行する前に、インストールやメンテナンス作業の予行演習を行うこと
- 複数のサービスを異なるユーザーやクライアントのために実行し、サーバーリソースをより良く利用し、プロビジョニングすること
- 完全な仮想化のコストをかけずに隔離が必要な高密度の仮想プライベートサーバー（VPS）ホスティング
- 仮想マシンからの複雑なアクセス方法と比較して、コンテナからのホストハードウェアへの容易なアクセス
- 異なるカスタマイズが施された複数のビルド環境

</details>

<details>
<summary><b>Redisクラスタを準備する必要があります。セキュリティをどのように確保しますか？</b></summary><br>

- ファイアウォールを使用して、特定のRedisインスタンスへの外部アクセスを保護する
- ローカルクライアントのみがアクセスする場合は、127.0.0.1にバインドする
- サンドボックス環境を利用する
- **AUTH**を有効にする
- **Protected Mode**を有効にする
- データ暗号化のサポート（例: `spiped`）
- 特定のコマンドの無効化
- ユーザーの**ACLs**（アクセス制御リスト）の設定

参考リソース:

- [Redis Security](https://redis.io/topics/security)
- [A few things about Redis security](http://antirez.com/news/96)

</details>

###### Cyber Security Questions (5)

<details>
<summary><b>OWASPアプリケーションセキュリティ検証標準（ASVS）とは何ですか？簡単に説明してください。</b></summary><br>

後日完成予定。

</details>

<details>
<summary><b>CSRFとは何ですか？</b></summary><br>

**クロスサイトリクエストフォージェリ（CSRF）**は、ウェブアプリケーションの脆弱性の一つで、サーバーがリクエストが信頼できるクライアントから来たかどうかを確認しない場合に発生します。リクエストはそのまま処理されてしまいます。この脆弱性の検出方法、例、および対策についても説明が続くことがあります。

</details>

<details>
<summary><b>ポリシー、プロセス、ガイドラインの違いは何ですか？</b></summary><br>

**セキュリティポリシー**は、組織のセキュリティ目標とセキュリティフレームワークを定義します。**プロセス**は、重要なセキュリティメカニズムを実装するために必要な具体的な手順を示した文書です。**ガイドライン**は、手順作成時にカスタマイズして使用できる推奨事項です。

</details>

<details>
<summary><b>IDSにおけるフォルスポジティブとフォルスネガティブの違いは何ですか？</b></summary><br>

デバイスが実際には起こっていない侵入に対してアラートを生成した場合、これを**フォルスポジティブ**と呼びます。逆に、デバイスがアラートを生成せず、実際に侵入が発生した場合、これが**フォルスネガティブ**のケースです。

</details>

<details>
<summary><b>Webサーバーのハードニングに関する10のポイント。</b></summary><br>

例:

- マシンが新規インストールの場合、OSのインストールとハードニングが完了するまで、敵対的なネットワークトラフィックから保護する
- `/tmp` に `nodev`、`nosuid`、`noexec` オプションを設定して、別のパーティションを作成する
- `/var`、`/var/log`、`/var/log/audit`、および `/home` 用に別のパーティションを作成する
- ランダム化された仮想メモリ領域配置を有効にする
- レガシーサービス（例: `telnet-server`、`rsh`、`rlogin`、`rcp`、`ypserv`、`ypbind`、`tftp`、`tftp-server`、`talk`、`talk-server`）を削除する
- ファイアウォールやその他のアクセス制御技術を使用して、ホスト上で実行されているサービスへの接続を認可されたユーザーに限定する
- ソースルーティングされたパケットの受信を無効にする
- **TCP/SYN** クッキーを有効にする
- SSHのrootログインを無効にする
- **AIDE**をインストールして設定する
- **OSsec HIDS**をインストールして設定する
- **SELinux**を設定する
- 管理者またはrootアクセスはすべてログに記録する必要がある
- システムアカウント、グループメンバーシップ、およびそれに関連する権限の整合性チェックを有効にし、テストする
- パスワード作成要件を設定する（例: PAMを使用）

参考資料:

- [Security Harden CentOS 7](https://highon.coffee/blog/security-harden-centos-7/)
- [CentOS 7 Server Hardening Guide](https://www.lisenet.com/2017/centos-7-server-hardening-guide/)

</details>

## <a name="secret-knowledge">秘密の知識</a>

### :diamond_shape_with_a_dot_inside: <a name="guru-sysadmin">Guru Sysadmin</a>

<details>
<summary><b>イベント駆動アーキテクチャとは何か、またそれがどのようにパフォーマンスを向上させるのか説明してください。</b></summary><br>

記入予定。

</details>

<details>
<summary><b>アプリケーションにパフォーマンスの問題が発生しています。最適化すべきコードを見つける必要があります。Linux環境でアプリをプロファイルする方法は？</b></summary><br>

> 理想的には、プロセスにアタッチして、メモリ使用量、スレッド数、CPU使用率の定期的なスナップショットを記録するアプリが必要です。

1. `top`をバッチモードで使用できます。バッチモードでは、終了するまで、または指定した回数の反復が完了するまで実行されます。

```bash
top -b -p `pidof a.out`
```

または

```bash
top -b -p `pidof a.out` -n 100
```

2. psも使用できます (例えばシェルスクリプトで):

```bash
ps --format pid,pcpu,cputime,etime,size,vsz,cmd -p `pidof a.out`
```

> Linuxマシンでアプリケーションのパフォーマンスを記録する手段が必要です。

1. パフォーマンスデータを記録する:
 
```bash
perf record -p `pidof a.out`
```

または10秒間記録するには:

```bash
perf record -p `pidof a.out` sleep 10
```

または、コールグラフを記録するには:

```bash
perf record -g -p `pidof a.out`
```

2) 記録されたデータを解析する

```bash
perf report --stdio
perf report --stdio --sort=dso -g none
perf report --stdio -g none
perf report --stdio -g
```

**これはテストプログラムのプロファイリングの例です**

1. テストプログラム（C++）を実行します:

```bash
./my_test 100000000
```

2. 実行中のプロセスのパフォーマンスデータを記録します:

```bash
perf record -g  -p `pidof my_test` -o ./my_test.perf.data sleep 30
```

3. 次に、モジュールごとの負荷を分析します:

```bash
perf report --stdio -g none --sort comm,dso -i ./my_test.perf.data

# Overhead  Command                 Shared Object
# ........  .......  ............................
#
    70.06%  my_test  my_test
    28.33%  my_test  libtcmalloc_minimal.so.0.1.0
     1.61%  my_test  [kernel.kallsyms]
```

4. 次に、機能ごとの負荷を分析します:

```bash
perf report --stdio -g none -i ./my_test.perf.data | c++filt

# Overhead  Command                 Shared Object                       Symbol
# ........  .......  ............................  ...........................
#
    29.30%  my_test  my_test                       [.] f2(long)
    29.14%  my_test  my_test                       [.] f1(long)
    15.17%  my_test  libtcmalloc_minimal.so.0.1.0  [.] operator new(unsigned long)
    13.16%  my_test  libtcmalloc_minimal.so.0.1.0  [.] operator delete(void*)
     9.44%  my_test  my_test                       [.] process_request(long)
     1.01%  my_test  my_test                       [.] operator delete(void*)@plt
     0.97%  my_test  my_test                       [.] operator new(unsigned long)@plt
     0.20%  my_test  my_test                       [.] main
     0.19%  my_test  [kernel.kallsyms]             [k] apic_timer_interrupt
     0.16%  my_test  [kernel.kallsyms]             [k] _spin_lock
     0.13%  my_test  [kernel.kallsyms]             [k] native_write_msr_safe

  ...
```

5. 次に、コールチェインを分析します:

```bash
perf report --stdio -g graph -i ./my_test.perf.data | c++filt

# Overhead  Command                 Shared Object                       Symbol
# ........  .......  ............................  ...........................
#
    29.30%  my_test  my_test                       [.] f2(long)
            |
            --- f2(long)
               |
                --29.01%-- process_request(long)
                          main
                          __libc_start_main

    29.14%  my_test  my_test                       [.] f1(long)
            |
            --- f1(long)
               |
               |--15.05%-- process_request(long)
               |          main
               |          __libc_start_main
               |
                --13.79%-- f2(long)
                          process_request(long)
                          main
                          __libc_start_main

  ...
```

この時点で、プログラムがどこに時間を費やしているかがわかります。

また、アプリケーションのプロファイルを作成する簡単な方法は、`pstack`ユーティリティまたは`lsstack`を使用することです。

もう一つのツールはValgrindです。これをお勧めします。まずプログラムを実行します:

```bash
valgrind --tool=callgrind --dump-instr=yes -v --instr-atstart=no ./binary > tmp
```

プログラムが動作しているときに、プロファイリングを開始するには別のウィンドウで以下を実行します:

```bash
callgrind_control -i on
```

これでプロファイリングがオンになります。オフにして全タスクを停止するには次のコマンドを使用します:

```bash
callgrind_control -k
```

これで、現在のディレクトリに`callgrind.out.*`という名前のファイルが生成されます。プロファイリングの結果を確認するには次のコマンドを使用します:

```bash
kcachegrind callgrind.out.*
```

次のウィンドウで**Self**列のヘッダーをクリックすることをお勧めします。そうしないと、`main()`が最も時間を消費しているタスクとして表示されてしまいます。

参考資料:

- [Tracing processes for fun and profit](http://techblog.rosedu.org/tracing-processes-for-fun-and-profit.html)

</details>

<details>
<summary><b>インストールされているパッケージが限られており、telnetが利用できないLinuxシステムで、sysfs仮想ファイルシステムを使用して、すべてのインターフェース（ループバックを除く）で接続をテストする方法</b></summary><br>

例えば：

```bash
#!/usr/bin/bash

for iface in $(ls /sys/class/net/ | grep -v lo) ; do

  if [[ $(cat /sys/class/net/$iface/carrier) = 1 ]] ; then state=1 ; fi

done

if [[ $state -ne 0 ]] ; then echo "not connection" > /dev/stderr ; exit ; fi
```

</details>

<details>
<summary><b>ハッキングされたシステムの影響を減らすための2つの基本ルールを書いてください。</b></summary><br>

1) **最小権限の原則**

サービスを実行するユーザーを、そのサービスのタスクを完了するために必要な最小限の権限しか持たないユーザーに設定するべきです。これにより、システムに侵入された場合でも、ハッカーの活動を制限できます。

例えば、Apacheウェブサーバーサービスのゼロデイ攻撃を使用してシステムに侵入したハッカーは、そのプロセスがアクセスできるシステムメモリとファイルリソースに限られる可能性が高いです。ハッカーはあなたのHTMLやPHPソースファイルをダウンロードし、MySQLデータベースを覗くことはできるかもしれませんが、root権限を得たり、Apacheがアクセス可能なファイルを超えて侵入を拡大することはできないはずです。

多くのデフォルトのApacheウェブサーバーインストールでは、デフォルトで'apache'ユーザーとグループが作成され、そのグループを使用してApacheを実行するようにメインのApache設定ファイル（`httpd.conf`）を簡単に設定できます。

2) **特権の分離の原則**

ウェブサイトがデータベースへの読み取り専用アクセスだけを必要とする場合は、そのデータベースに対してのみ読み取り専用権限を持つアカウントを作成します。

**SELinux**はセキュリティのためのコンテキスト作成に適しており、`app-armor`ももう一つのツールです。**Bastille**はハードニングのための以前の選択肢でした。

攻撃の影響を減らすために、サービスの特権を独自の「ボックス」に分離します。

3) **ホワイトリストを使用し、ブラックリストを使用しない**

ブラックリストアプローチを説明しています。ホワイトリストアプローチの方がずっと安全です。

排他的なクラブは、入場できない人をリストアップしようとはしません。入場できる人をリストアップし、リストにない人を除外します。

同様に、機械にアクセスすべきでないものをリストアップしようとするのは無理があります。アクセスを短いリストのプログラム/IPアドレス/ユーザーに制限する方が効果的です。

もちろん、これにはいくつかのトレードオフがあります。具体的には、ホワイトリストは非常に不便であり、定期的なメンテナンスが必要です。

さらにトレードオフを進めるためには、ネットワークから機械を切り離すことで優れたセキュリティを得ることができます。

**また興味深い点は**:

利用可能なツールを使用してください。セキュリティの専門家ほどうまく対処できる可能性は低いため、彼らの才能を利用して自分を守りましょう。

- 公開鍵暗号化は優れたセキュリティを提供します
- パスワードの複雑さを強制する
- 上記のルールに対する例外の理由を理解し、例外を定期的に見直す
- 失敗に対して責任を持たせることで、注意を払い続ける

Useful resources:

- [ゼロデイ攻撃を防ぐ方法 (原文)](https://serverfault.com/questions/391370/how-to-prevent-zero-day-attacks)

</details>

<details>
<summary><b>セキュリティカンファレンスに参加しています。メンバーがネットワークのコアにOpenBSDファイアウォールを導入するかどうかについて議論しています。壇上に上がり、このソリューションについての意見を述べてください。利点/欠点は何ですか？なぜですか？</b></summary><br>

完成次第記入。

</details>

<details>
<summary><b>Access-Control-Allow-Origin ヘッダーを使って Nginx で複数のクロスドメインを許可する方法はありますか？</b></summary><br>

ドメインとサブドメインのリストに一致させるために、この正規表現を使うとフォント?との作業が楽になります：

```bash
location ~* \.(?:ttf|ttc|otf|eot|woff|woff2)$ {
   if ( $http_origin ~* (https?://(.+\.)?(domain1|domain2|domain3)\.(?:me|co|com)$) ) {
      add_header "Access-Control-Allow-Origin" "$http_origin";
   }
}
```

少し詳細な設定：

```bash
location / {

    if ($http_origin ~* (^https?://([^/]+\.)*(domainone|domaintwo)\.com$)) {
        set $cors "true";
    }

    # Nginx はネストした If 文をサポートしていません。ここが少し面倒な部分です。
    # 使用される HTTP リクエストメソッドを判定
    if ($request_method = 'GET') {
        set $cors "${cors}get";
    }
    if ($request_method = 'POST') {
        set $cors "${cors}post";
    }

    if ($cors = "true") {
        # 処理していないリクエストメソッドに備えてキャッチオール
        add_header 'Access-Control-Allow-Origin' "$http_origin";
    }

    if ($cors = "trueget") {
        add_header 'Access-Control-Allow-Origin' "$http_origin";
        add_header 'Access-Control-Allow-Credentials' 'true';
        add_header 'Access-Control-Allow-Methods' 'GET, POST, OPTIONS';
        add_header 'Access-Control-Allow-Headers' 'DNT,X-CustomHeader,Keep-Alive,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type';
    }

    if ($cors = "truepost") {
        add_header 'Access-Control-Allow-Origin' "$http_origin";
        add_header 'Access-Control-Allow-Credentials' 'true';
        add_header 'Access-Control-Allow-Methods' 'GET, POST, OPTIONS';
        add_header 'Access-Control-Allow-Headers' 'DNT,X-CustomHeader,Keep-Alive,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type';
    }

}
```

</details>

<details>
<summary><b><code>:(){ :|:& };:</code> の説明と、すでにシステムにログインしている場合にこのコードを止める方法</b></summary><br>

これは**フォークボム**です。

- `:()` - これは関数を定義します。`:` が関数名で、空の括弧は引数を受け取らないことを示します。
- `{ }` - これらの文字は関数定義の開始と終了を示します。
- `:|:` - 関数 `:` のコピーをメモリに読み込み、その出力を別のコピーの `:` 関数にパイプで渡します。この別のコピーもメモリに読み込む必要があります。
- `&` - これにより、プロセスがバックグラウンドプロセスとして実行されるため、親プロセスが自動的に終了しても子プロセスは終了しません。
- `:` - 最後の `:` が関数を再度実行し、そのため連鎖反応が始まります。

マルチユーザーシステムを保護する最良の方法は、**PAM** を使用してユーザーが使用できるプロセスの数を制限することです。フォークボムの最大の問題は、多くのプロセスを占有することです。

したがって、すでにシステムにログインしている場合、以下の2つの方法で修正を試みることができます：
- **SIGSTOP** コマンドを実行してプロセスを停止する: `killall -STOP -u user1`
- コマンドラインで実行できない場合は、`exec` を使用して強制的に実行する（すべてのプロセスが使用中の場合）: `exec killall -STOP -u user1`

フォークボムに対して最良の方法は、最初から大きな問題にならないようにすることです。

</details>

<details>
<summary><b>Apache などによって開かれたままの削除されたファイルを復元する方法</b></summary><br>

ファイルが削除されたがまだ開かれている場合、そのファイルはファイルシステムにまだ存在しており（inode がある）、ハードリンクのカウントが 0 になっています。ファイルへのリンクが存在しないため、名前で開くことはできません。また、inode でファイルを開く機能もありません。

Linux では、開かれているファイルが `/proc` の下にある特殊なシンボリックリンクを介して表示されます。これらのリンクは `/proc/12345/fd/42` という形式で、ここで 12345 はプロセスの **PID**、42 はそのプロセス内のファイルディスクリプタの番号です。そのプロセスと同じユーザーで実行されているプログラムは、そのファイルにアクセスできます（ファイルが削除されたときの読み取り/書き込み/実行権限はそのままです）。

ファイルが開かれていたときの名前は、シンボリックリンクのターゲットにまだ表示されています。例えば、ファイルが `/var/log/apache/foo.log` であった場合、リンクのターゲットは `/var/log/apache/foo.log (deleted)` です。

このように、削除されたファイルを開いているプロセスの**PID**と、そのファイルを開いているディスクリプタがあれば、そのファイルの内容を復元することができます：

```bash
recover_open_deleted_file () {
  old_name=$(readlink "$1")
  case "$old_name" in
    *' (deleted)')
      old_name=${old_name%' (deleted)'}
      if [ -e "$old_name" ]; then
        new_name=$(TMPDIR=${old_name%/*} mktemp)
        echo "$oldname has been replaced, recovering content to $new_name"
      else
        new_name="$old_name"
      fi
      cat <"$1" >"$new_name";;
    *) echo "File is not deleted, doing nothing";;
  esac
}
recover_open_deleted_file "/proc/$pid/fd/$fd"
```

プロセスの**ID**だけがわかっていて、ディスクリプタがわからない場合は、以下の方法ですべてのファイルを復元できます：

```bash
for x in /proc/$pid/fd/* ; do
  recover_open_deleted_file "$x"
done
```

プロセスの**ID**もわからない場合は、すべてのプロセスから検索することができます：

```bash
for x in /proc/[1-9]*/fd/* ; do
  case $(readlink "$x") in
    /var/log/apache/*) recover_open_deleted_file "$x";;
  esac
done
```

`lsof`の出力をパースすることでもこのリストを得ることができますが、よりシンプルで信頼性が高く、移植性が高いというわけではありません（いずれにせよ、これはLinux特有のものです）。

</details>

<details>
<summary><b>管理チームがサポートを必要としています。主要なサーバーの1台でリモートからシステムを再インストールする必要があります。管理コンソール（例: iDRAC）へのアクセスはありません。他のLinuxが存在し、動作している状態でディスクにLinuxをインストールするにはどうすれば良いでしょうか？</b></summary><br>

質問は次のように修正する必要があるかもしれません: "_既存の他のシステムのレベルおよび場所からのシステムインストール_"

Debian GNU/Linuxディストリビューションの例を用いて説明します。

1. 作業ディレクトリを作成し、`debootstrap`ツールを使用してシステムをダウンロードします。

```bash
_working_directory="/mnt/system"
mkdir $_working_directory
debootstrap --verbose --arch amd64 {wheezy|jessie} . http://ftp.en.debian.org/debian
```

2. サブシステム `proc`、`sys`、`dev` および `dev/pts` をマウントします。

```bash
for i in proc sys dev dev/pts ; do mount -o bind $i $_working_directory/$i ; done
```

3. システムバックアップをコピーしてリストアします。

```bash
cp system_backup_22012015.tgz $_working_directory/mnt
```

ただし、スペースを無駄にせず、別の方法で行う方が良いです（バックアップが `/mnt/backup` にあると仮定します）：

```bash
_backup_directory="${_working_directory}/mnt/backup"
mkdir $_backup_directory && mount --bind /mnt/backup $_backup_directory
```

4. "新しい" システムに chroot します。

```bash
chroot $_working_directory /bin/bash
```

5. マウントされたデバイスに関する情報を更新します。

```bash
grep -v rootfs /proc/mounts > /etc/mtab
```

6. "新しい" システム内で、"古い" システムが存在するディスクをマウントします（例: `/dev/sda1`）。

```bash
_working_directory="/mnt/old_system"
_backup_directory="/mnt/backup"
mkdir $_working_directory && mount /dev/sda1 $_working_directory
```

7. 古いシステムのすべてのファイルを削除します。

```bash
for i in $(ls | awk '!(/proc/ || /dev/ || /sys/ || /mnt/)') ; do rm -fr $i ; done
```

8. 次のステップは、バックアップからシステムをリストアすることです。

```bash
tar xzvfp $_backup_directory/system_backup_22012015.tgz -C $_working_directory
```

9. 新しい作業ディレクトリに `proc`、`sys`、`dev`、および `dev/pts` をマウントします。

```bash
for i in proc sys dev dev/pts ; do mount -o bind $i $_working_directory/$i ; done
```

10. GRUBの設定をインストールし、更新します。

```bash
chroot $_working_directory /bin/bash -c "grub-install --no-floppy --root-directory=/ /dev/sda"
chroot $_working_directory /bin/bash -c "update-grub"
```

11. `proc`、`sys`、`dev`、および `dev/pts` のファイルシステムをアンマウントします。

```bash
cd
grep $_working_directory /proc/mounts | cut -f2 -d " " | sort -r | xargs umount -n
```

利用可能なコマンド（`halt`、`shutdown`、`reboot`）はどれも機能しません。システム設定を再読み込みする必要があります。そのためには、**カーネルデバッガ**を使用します（`**b**` オプションは使用しません）：

```bash
echo 1 > /proc/sys/kernel/sysrq
echo reisu > /proc/sysrq-trigger
```

もちろん、現在のシステムを完全に読み込むためには、マシンを完全に再起動することをお勧めします。これを行うには：

```bash
sync ; reboot -f
```

</details>

<details>
<summary><b>Rsync が 50 GB の単一ファイルで Linux の OOM キラーを発動させました。OOM キラーはどのプロセスを最初に終了させるかどうやって決めるのですか？これを制御する方法はありますか？</b></summary><br>

主要なディストリビューションのカーネルは、`/proc/sys/vm/overcommit_memory` のデフォルト値をゼロに設定しています。これは、プロセスが現在システムで利用可能なメモリよりも多くのメモリを要求できることを意味します。

もしメモリがプロセスによって使い果たされ、システムの安定性を脅かす可能性がある場合、**OOM キラー** が登場します。

NOTE: **OOM キラー** の仕事は、カーネルが実行しようとしている残りのプロセスがスムーズに機能するために十分なメモリが解放されるまで、プロセスを終了させ続けることです。

**OOM キラー** は最適なプロセスを選択して終了させなければなりません。ここで「最適」とは、終了させたときに最大のメモリを解放し、システムにとって重要度が最も低いプロセスを指します。

主な目標は、最小限のプロセスを終了させて損害を最小限に抑えつつ、解放されるメモリの量を最大化することです。

これを実現するために、カーネルは各プロセスに `oom_score` を維持しています。プロセスの `oom_score` は、`/proc` ファイルシステムの pid ディレクトリで確認できます。

  > OOM キラーのログを分析する際には、何がそれを引き起こしたのかを確認することが重要です。

```bash
cat /proc/10292/oom_score
```

`oom_score` の値が高いほど、そのプロセスが **OOM キラー** によって終了される可能性が高くなります。

**OOM キラー** の注意を最初に受けるべきプロセスのリストを含む特別なコントロールグループを作成したい場合は、`/mnt/oom-killer` の下にディレクトリを作成してそれを表します：

```bash
mkdir lambs
```

`oom.priority` を十分に高い値に設定します：

```bash
echo 256 > /mnt/oom-killer/lambs/oom.priority
```

`oom.priority` は 64 ビットの符号なし整数で、符号なし 64 ビット数が保持できる最大値を持つことができます。プロセスを終了する際、**OOM キラー** は `oom.priority` の値が最も高いプロセスをリストから選択します。

プロセスをタスクのリストに追加するには、その PID を追加します：

```bash
echo <pid> > /mnt/oom-killer/lambs/tasks
```

**OOM キラー** によって終了されないプロセスのリストを作成するには、プロセスを含むディレクトリを作成します：

```bash
mkdir invincibles
```

`oom.priority` をゼロに設定すると、この cgroup 内のすべてのプロセスが終了対象プロセスのリストから除外されます。

```bash
echo 0 > /mnt/oom-killer/invincibles/oom.priority
```

このグループにさらにプロセスを追加するには、タスクの PID を invincible グループのタスクリストに追加します：

```bash
echo <pid> > /mnt/oom-killer/invincibles/tasks
```

役立つリソース：

- [Rsync が 50 GB の単一ファイルで Linux の OOM キラーを発動させた問題](https://serverfault.com/questions/724469/rsync-triggered-linux-oom-killer-on-a-single-50-gb-file)
- [OOM キラーの制御方法](https://lwn.net/Articles/317814/)

</details>

<details>
<summary><b>多くのソケットが <code>TIME_WAIT</code> 状態で待機しています。プロキシの背後にある http サービスが多くの小さな http リクエストを処理しています。<code>TIME_WAIT</code> ソケットを確認し、削減する方法は？ ***</b></summary><br>

完了予定。

役立つリソース：

- [TIME_WAIT 状態のソケットの数を減らす方法](https://serverfault.com/questions/212093/how-to-reduce-number-of-sockets-in-time-wait)

</details>

<details>
<summary><b><code>SO_REUSEADDR</code> と <code>SO_REUSEPORT</code> はどのように異なりますか？すべてのソケット実装について説明してください。 ***</b></summary><br>

完了予定。

</details>
